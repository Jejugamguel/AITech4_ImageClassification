{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cf046c11-3a01-4c6c-99dd-c062e21c7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4bad9118-3244-4b50-bce3-d9f0ca8dc7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 35% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d2f667bb-73d0-494b-843e-f0260f6ac538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  3 06:12:12 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   39C    P0    43W / 250W |  11239MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0b1d65a3-78de-4b01-a862-e6bd4c7ef135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from align_faces import warp_and_crop_face, get_reference_facial_points\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fa8d19de-5a8e-454f-a22b-129e94792395",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 12\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6f69f93c-5675-433f-8a88-7bf8e411d51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>6954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>6955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>6956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>6957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>6959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  gender   race  age                    path  age_range\n",
       "0        1  female  Asian   45  000001_female_Asian_45          1\n",
       "1        2  female  Asian   52  000002_female_Asian_52          1\n",
       "2        4    male  Asian   54    000004_male_Asian_54          1\n",
       "3        5  female  Asian   58  000005_female_Asian_58          1\n",
       "4        6  female  Asian   59  000006_female_Asian_59          1\n",
       "...    ...     ...    ...  ...                     ...        ...\n",
       "2695  6954    male  Asian   19    006954_male_Asian_19          0\n",
       "2696  6955    male  Asian   19    006955_male_Asian_19          0\n",
       "2697  6956    male  Asian   19    006956_male_Asian_19          0\n",
       "2698  6957    male  Asian   20    006957_male_Asian_20          0\n",
       "2699  6959    male  Asian   19    006959_male_Asian_19          0\n",
       "\n",
       "[2700 rows x 6 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir_path = '../input/data/train/'\n",
    "train_image_path = '../input/data/train/images/'\n",
    "\n",
    "dt_train = pd.read_csv(train_dir_path+'train.csv')\n",
    "\n",
    "def get_age_range(age):\n",
    "    if age < 30:\n",
    "        return 0\n",
    "    elif 30 <= age < 60:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "dt_train['age_range'] = dt_train['age'].apply(lambda x : get_age_range(x))\n",
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7c85dff4-5de1-46c5-b06a-a7736c48d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sixty = dt_train.loc[dt_train['age_range']==2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f61d3146-3ccf-4601-91fd-4f9d72bcfcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>39</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>000039_female_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>224</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>000224_female_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>229</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>000229_male_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>237</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>000237_male_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>267</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>000267_male_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>5453</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005453_female_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>5459</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005459_male_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>5461</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005461_female_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>5504</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005504_female_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>5515</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005515_female_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  gender   race  age                    path  age_range\n",
       "31      39  female  Asian   60  000039_female_Asian_60          2\n",
       "65     224  female  Asian   60  000224_female_Asian_60          2\n",
       "70     229    male  Asian   60    000229_male_Asian_60          2\n",
       "75     237    male  Asian   60    000237_male_Asian_60          2\n",
       "94     267    male  Asian   60    000267_male_Asian_60          2\n",
       "...    ...     ...    ...  ...                     ...        ...\n",
       "2168  5453  female  Asian   60  005453_female_Asian_60          2\n",
       "2173  5459    male  Asian   60    005459_male_Asian_60          2\n",
       "2175  5461  female  Asian   60  005461_female_Asian_60          2\n",
       "2209  5504  female  Asian   60  005504_female_Asian_60          2\n",
       "2217  5515  female  Asian   60  005515_female_Asian_60          2\n",
       "\n",
       "[209 rows x 6 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_sixty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b7ec297-8f07-4eb0-953b-e2c706bb84f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:49<00:00,  4.19it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(range(len(over_sixty))):\n",
    "    path = over_sixty.iloc[idx]['path']\n",
    "    if os.path.exists(train_image_path+path+'_1') == False:\n",
    "        os.mkdir(train_image_path+path+'_1')\n",
    "    if os.path.exists(train_image_path+path+'_2') == False:\n",
    "        os.mkdir(train_image_path+path+'_2')\n",
    "        \n",
    "    for file_name in [i for i in os.listdir(train_image_path+path) if i[0] != '.' and i[-3:] != \"npy\"]:\n",
    "        img = Image.open(train_image_path+path+'/'+file_name)\n",
    "        img1 = torchvision.transforms.ColorJitter(brightness=0.5, contrast=0.5)(img)\n",
    "        img2 = torchvision.transforms.GaussianBlur(9, 4)(img)       \n",
    "        img1.save(train_image_path+path+'_1'+'/'+file_name, 'JPEG')      \n",
    "        img2.save(train_image_path+path+'_2'+'/'+file_name, 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0cbc2617-6ea5-4062-939b-0a88c90db3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = []\n",
    "path2 = []\n",
    "for i in range(len(over_sixty)):\n",
    "    path1.append(over_sixty.iloc[i]['path'] + '_1')\n",
    "    path2.append(over_sixty.iloc[i]['path'] + '_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4803bc9a-e504-42f2-8748-f0cc0f23dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sixty_1 = pd.DataFrame({'id':over_sixty['id'] + \"_1\", 'gender':over_sixty['gender'], 'race':over_sixty['race'], 'age' : over_sixty['age'], 'path':path1, 'age_range':over_sixty['age_range']})\n",
    "over_sixty_2 = pd.DataFrame({'id':over_sixty['id'] + \"_2\", 'gender':over_sixty['gender'], 'race':over_sixty['race'], 'age' : over_sixty['age'], 'path':path2, 'age_range':over_sixty['age_range']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7ed44d6e-d1c0-4f61-99f0-c1c09209f600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>5453_2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005453_female_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>5459_2</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005459_male_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>5461_2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005461_female_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>5504_2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005504_female_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>5515_2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005515_female_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3118 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                      path  age_range\n",
       "0          1  female  Asian   45    000001_female_Asian_45          1\n",
       "1          2  female  Asian   52    000002_female_Asian_52          1\n",
       "2          4    male  Asian   54      000004_male_Asian_54          1\n",
       "3          5  female  Asian   58    000005_female_Asian_58          1\n",
       "4          6  female  Asian   59    000006_female_Asian_59          1\n",
       "...      ...     ...    ...  ...                       ...        ...\n",
       "3113  5453_2  female  Asian   60  005453_female_Asian_60_2          2\n",
       "3114  5459_2    male  Asian   60    005459_male_Asian_60_2          2\n",
       "3115  5461_2  female  Asian   60  005461_female_Asian_60_2          2\n",
       "3116  5504_2  female  Asian   60  005504_female_Asian_60_2          2\n",
       "3117  5515_2  female  Asian   60  005515_female_Asian_60_2          2\n",
       "\n",
       "[3118 rows x 6 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train = dt_train.append(over_sixty_1, ignore_index=True)\n",
    "dt_train = dt_train.append(over_sixty_2, ignore_index=True)\n",
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "548f2d29-854a-4465-b0e5-4d96352a8b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "gender       0\n",
       "race         0\n",
       "age          0\n",
       "path         0\n",
       "age_range    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c00c1634-0499-43e7-bf6a-ee14c7657af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train.to_csv('/opt/ml/input/data/train/aug_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "74006b91-4954-41ec-8126-1e5e1f2b66f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>5453_2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005453_female_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>5459_2</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005459_male_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>5461_2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005461_female_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>5504_2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005504_female_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>5515_2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>005515_female_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3118 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                      path  age_range\n",
       "0          1  female  Asian   45    000001_female_Asian_45          1\n",
       "1          2  female  Asian   52    000002_female_Asian_52          1\n",
       "2          4    male  Asian   54      000004_male_Asian_54          1\n",
       "3          5  female  Asian   58    000005_female_Asian_58          1\n",
       "4          6  female  Asian   59    000006_female_Asian_59          1\n",
       "...      ...     ...    ...  ...                       ...        ...\n",
       "3113  5453_2  female  Asian   60  005453_female_Asian_60_2          2\n",
       "3114  5459_2    male  Asian   60    005459_male_Asian_60_2          2\n",
       "3115  5461_2  female  Asian   60  005461_female_Asian_60_2          2\n",
       "3116  5504_2  female  Asian   60  005504_female_Asian_60_2          2\n",
       "3117  5515_2  female  Asian   60  005515_female_Asian_60_2          2\n",
       "\n",
       "[3118 rows x 6 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c92579a9-3de4-463c-9041-53d5b1e403b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>215</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000215_female_Asian_59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>4217</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>004217_female_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>5258</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>22</td>\n",
       "      <td>005258_male_Asian_22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000031_female_Asian_54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>1069</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>001069_female_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>3056</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>003056_female_Asian_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>3023</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>003023_female_Asian_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>3577_2</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>003577_male_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>1482_1</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>001482_female_Asian_60_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>286</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>51</td>\n",
       "      <td>000286_female_Asian_51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2494 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                      path  age_range\n",
       "59       215  female  Asian   59    000215_female_Asian_59          1\n",
       "1771    4217  female  Asian   60    004217_female_Asian_60          2\n",
       "2091    5258    male  Asian   22      005258_male_Asian_22          0\n",
       "25        31  female  Asian   54    000031_female_Asian_54          1\n",
       "449     1069  female  Asian   19    001069_female_Asian_19          0\n",
       "...      ...     ...    ...  ...                       ...        ...\n",
       "1117    3056  female  Asian   20    003056_female_Asian_20          0\n",
       "1090    3023  female  Asian   20    003023_female_Asian_20          0\n",
       "2988  3577_2    male  Asian   60    003577_male_Asian_60_2          2\n",
       "2734  1482_1  female  Asian   60  001482_female_Asian_60_1          2\n",
       "110      286  female  Asian   51    000286_female_Asian_51          1\n",
       "\n",
       "[2494 rows x 6 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, valid_idx = train_test_split(np.arange(len(dt_train)),\n",
    "                                       test_size=0.2,\n",
    "                                       shuffle=True,\n",
    "                                       stratify=dt_train['age_range'])\n",
    "dt_train.iloc[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e79f55f9-ea88-4300-aa7d-83f2e4a0109a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>1047</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>001047_male_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>4339_1</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>004339_female_Asian_60_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>4486</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>004486_male_Asian_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>3015</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>003015_female_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1395</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>001395_male_Asian_59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>5529</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>44</td>\n",
       "      <td>005529_female_Asian_44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>1724</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>22</td>\n",
       "      <td>001724_female_Asian_22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>6522</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006522_female_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>1598_2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>001598_female_Asian_60_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>3164</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>003164_female_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                      path  age_range\n",
       "427     1047    male  Asian   60      001047_male_Asian_60          2\n",
       "2871  4339_1  female  Asian   60  004339_female_Asian_60_1          2\n",
       "1955    4486    male  Asian   20      004486_male_Asian_20          0\n",
       "1084    3015  female  Asian   19    003015_female_Asian_19          0\n",
       "689     1395    male  Asian   59      001395_male_Asian_59          1\n",
       "...      ...     ...    ...  ...                       ...        ...\n",
       "2231    5529  female  Asian   44    005529_female_Asian_44          1\n",
       "937     1724  female  Asian   22    001724_female_Asian_22          0\n",
       "2528    6522  female  Asian   19    006522_female_Asian_19          0\n",
       "2964  1598_2  female  Asian   60  001598_female_Asian_60_2          2\n",
       "1202    3164  female  Asian   19    003164_female_Asian_19          0\n",
       "\n",
       "[624 rows x 6 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train.iloc[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6e8372fa-23ab-4916-8475-df41e2512b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>1593</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>60</td>\n",
       "      <td>001593_female_Asian_60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  gender   race  age                    path  age_range\n",
       "848  1593  female  Asian   60  001593_female_Asian_60          2"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_train[dt_train['id'] == \"1593\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaff489-0375-496f-a9fb-f9c538ab0de7",
   "metadata": {},
   "source": [
    "### aug_train.csv 로 preprocess.py 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "39d8ec63-dd2b-4b8a-bc29-5bad83a3c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_train = pd.read_csv(train_dir_path+'aug_expanded_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "569300eb-4180-45a4-8866-79234024b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_train.drop(columns=['Unnamed: 0', 'Has_Face'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ff3b2424-631e-4dca-89e3-069974a4f31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>Path</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Class</th>\n",
       "      <th>Mask</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>BBoxX1</th>\n",
       "      <th>BBoxY1</th>\n",
       "      <th>BBoxX2</th>\n",
       "      <th>BBoxY2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>146</td>\n",
       "      <td>250</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>160</td>\n",
       "      <td>245</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>127</td>\n",
       "      <td>230</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>143</td>\n",
       "      <td>244</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>125</td>\n",
       "      <td>244</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21821</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>110</td>\n",
       "      <td>284</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21822</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>102</td>\n",
       "      <td>293</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21823</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>288</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21824</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>120</td>\n",
       "      <td>273</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21825</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>107</td>\n",
       "      <td>277</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21826 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PersonID                                               Path  \\\n",
       "0            1  ../input/data/train/images/000001_female_Asian...   \n",
       "1            1  ../input/data/train/images/000001_female_Asian...   \n",
       "2            1  ../input/data/train/images/000001_female_Asian...   \n",
       "3            1  ../input/data/train/images/000001_female_Asian...   \n",
       "4            1  ../input/data/train/images/000001_female_Asian...   \n",
       "...        ...                                                ...   \n",
       "21821     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21822     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21823     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21824     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21825     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "\n",
       "                                                Filename  Class  Mask  Gender  \\\n",
       "0      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "1      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "2      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "3      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "4      ../input/data/train/images/000001_female_Asian...     10     1       1   \n",
       "...                                                  ...    ...   ...     ...   \n",
       "21821  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "21822  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "21823  ../input/data/train/images/005515_female_Asian...     11     1       1   \n",
       "21824  ../input/data/train/images/005515_female_Asian...     17     2       1   \n",
       "21825  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "\n",
       "       Age  Age_Class  BBoxX1  BBoxY1  BBoxX2  BBoxY2  \n",
       "0       45          1     110     146     250     347  \n",
       "1       45          1     112     160     245     334  \n",
       "2       45          1     107     127     230     311  \n",
       "3       45          1     120     143     244     326  \n",
       "4       45          1     122     125     244     316  \n",
       "...    ...        ...     ...     ...     ...     ...  \n",
       "21821   60          2      64     110     284     389  \n",
       "21822   60          2      66     102     293     397  \n",
       "21823   60          2      67      97     288     444  \n",
       "21824   60          2      77     120     273     410  \n",
       "21825   60          2      59     107     277     391  \n",
       "\n",
       "[21826 rows x 12 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6c3462fa-203a-40c4-989f-b702d707847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_train.drop(columns=['Unnamed: 0', 'Has_Face', 'Score', 'LE_X', 'LE_Y', 'RE_X', 'RE_Y', 'N_X', 'N_Y', 'LM_X', 'LM_Y', 'RM_X', 'RM_Y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3c2a0240-b785-4ffa-a64d-e71f2e7278ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_new_path(x):\n",
    "    return x.split(\"images\")[0] + 'new_images2' + x.split(\"images\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "44294a51-bf0c-4c5a-b6a2-e13e8d43aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_train['new_path'] = exp_train['Path'].apply(make_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "52f0cd47-04e5-426f-bb72-531ce8be06da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>Path</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Class</th>\n",
       "      <th>Mask</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>BBoxX1</th>\n",
       "      <th>BBoxY1</th>\n",
       "      <th>BBoxX2</th>\n",
       "      <th>BBoxY2</th>\n",
       "      <th>new_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>146</td>\n",
       "      <td>250</td>\n",
       "      <td>347</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>160</td>\n",
       "      <td>245</td>\n",
       "      <td>334</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>127</td>\n",
       "      <td>230</td>\n",
       "      <td>311</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>143</td>\n",
       "      <td>244</td>\n",
       "      <td>326</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>125</td>\n",
       "      <td>244</td>\n",
       "      <td>316</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21821</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>110</td>\n",
       "      <td>284</td>\n",
       "      <td>389</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21822</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>102</td>\n",
       "      <td>293</td>\n",
       "      <td>397</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21823</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>288</td>\n",
       "      <td>444</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21824</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>120</td>\n",
       "      <td>273</td>\n",
       "      <td>410</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21825</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>107</td>\n",
       "      <td>277</td>\n",
       "      <td>391</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21826 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PersonID                                               Path  \\\n",
       "0            1  ../input/data/train/images/000001_female_Asian...   \n",
       "1            1  ../input/data/train/images/000001_female_Asian...   \n",
       "2            1  ../input/data/train/images/000001_female_Asian...   \n",
       "3            1  ../input/data/train/images/000001_female_Asian...   \n",
       "4            1  ../input/data/train/images/000001_female_Asian...   \n",
       "...        ...                                                ...   \n",
       "21821     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21822     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21823     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21824     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21825     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "\n",
       "                                                Filename  Class  Mask  Gender  \\\n",
       "0      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "1      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "2      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "3      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "4      ../input/data/train/images/000001_female_Asian...     10     1       1   \n",
       "...                                                  ...    ...   ...     ...   \n",
       "21821  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "21822  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "21823  ../input/data/train/images/005515_female_Asian...     11     1       1   \n",
       "21824  ../input/data/train/images/005515_female_Asian...     17     2       1   \n",
       "21825  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "\n",
       "       Age  Age_Class  BBoxX1  BBoxY1  BBoxX2  BBoxY2  \\\n",
       "0       45          1     110     146     250     347   \n",
       "1       45          1     112     160     245     334   \n",
       "2       45          1     107     127     230     311   \n",
       "3       45          1     120     143     244     326   \n",
       "4       45          1     122     125     244     316   \n",
       "...    ...        ...     ...     ...     ...     ...   \n",
       "21821   60          2      64     110     284     389   \n",
       "21822   60          2      66     102     293     397   \n",
       "21823   60          2      67      97     288     444   \n",
       "21824   60          2      77     120     273     410   \n",
       "21825   60          2      59     107     277     391   \n",
       "\n",
       "                                                new_path  \n",
       "0      ../input/data/train/new_images2/000001_female_...  \n",
       "1      ../input/data/train/new_images2/000001_female_...  \n",
       "2      ../input/data/train/new_images2/000001_female_...  \n",
       "3      ../input/data/train/new_images2/000001_female_...  \n",
       "4      ../input/data/train/new_images2/000001_female_...  \n",
       "...                                                  ...  \n",
       "21821  ../input/data/train/new_images2/005515_female_...  \n",
       "21822  ../input/data/train/new_images2/005515_female_...  \n",
       "21823  ../input/data/train/new_images2/005515_female_...  \n",
       "21824  ../input/data/train/new_images2/005515_female_...  \n",
       "21825  ../input/data/train/new_images2/005515_female_...  \n",
       "\n",
       "[21826 rows x 13 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d7cdaaac-b38a-471a-90b9-012521adb5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index size: 2494 == file estimate: 17458 == split size: 17430\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>Path</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Class</th>\n",
       "      <th>Mask</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>BBoxX1</th>\n",
       "      <th>BBoxY1</th>\n",
       "      <th>BBoxX2</th>\n",
       "      <th>BBoxY2</th>\n",
       "      <th>new_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>146</td>\n",
       "      <td>250</td>\n",
       "      <td>347</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>160</td>\n",
       "      <td>245</td>\n",
       "      <td>334</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>127</td>\n",
       "      <td>230</td>\n",
       "      <td>311</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>143</td>\n",
       "      <td>244</td>\n",
       "      <td>326</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>125</td>\n",
       "      <td>244</td>\n",
       "      <td>316</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21821</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>110</td>\n",
       "      <td>284</td>\n",
       "      <td>389</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21822</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>102</td>\n",
       "      <td>293</td>\n",
       "      <td>397</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21823</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>288</td>\n",
       "      <td>444</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21824</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>120</td>\n",
       "      <td>273</td>\n",
       "      <td>410</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21825</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>107</td>\n",
       "      <td>277</td>\n",
       "      <td>391</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17430 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PersonID                                               Path  \\\n",
       "0            1  ../input/data/train/images/000001_female_Asian...   \n",
       "1            1  ../input/data/train/images/000001_female_Asian...   \n",
       "2            1  ../input/data/train/images/000001_female_Asian...   \n",
       "3            1  ../input/data/train/images/000001_female_Asian...   \n",
       "4            1  ../input/data/train/images/000001_female_Asian...   \n",
       "...        ...                                                ...   \n",
       "21821     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21822     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21823     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21824     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21825     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "\n",
       "                                                Filename  Class  Mask  Gender  \\\n",
       "0      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "1      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "2      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "3      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "4      ../input/data/train/images/000001_female_Asian...     10     1       1   \n",
       "...                                                  ...    ...   ...     ...   \n",
       "21821  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "21822  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "21823  ../input/data/train/images/005515_female_Asian...     11     1       1   \n",
       "21824  ../input/data/train/images/005515_female_Asian...     17     2       1   \n",
       "21825  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "\n",
       "       Age  Age_Class  BBoxX1  BBoxY1  BBoxX2  BBoxY2  \\\n",
       "0       45          1     110     146     250     347   \n",
       "1       45          1     112     160     245     334   \n",
       "2       45          1     107     127     230     311   \n",
       "3       45          1     120     143     244     326   \n",
       "4       45          1     122     125     244     316   \n",
       "...    ...        ...     ...     ...     ...     ...   \n",
       "21821   60          2      64     110     284     389   \n",
       "21822   60          2      66     102     293     397   \n",
       "21823   60          2      67      97     288     444   \n",
       "21824   60          2      77     120     273     410   \n",
       "21825   60          2      59     107     277     391   \n",
       "\n",
       "                                                new_path  \n",
       "0      ../input/data/train/new_images2/000001_female_...  \n",
       "1      ../input/data/train/new_images2/000001_female_...  \n",
       "2      ../input/data/train/new_images2/000001_female_...  \n",
       "3      ../input/data/train/new_images2/000001_female_...  \n",
       "4      ../input/data/train/new_images2/000001_female_...  \n",
       "...                                                  ...  \n",
       "21821  ../input/data/train/new_images2/005515_female_...  \n",
       "21822  ../input/data/train/new_images2/005515_female_...  \n",
       "21823  ../input/data/train/new_images2/005515_female_...  \n",
       "21824  ../input/data/train/new_images2/005515_female_...  \n",
       "21825  ../input/data/train/new_images2/005515_female_...  \n",
       "\n",
       "[17430 rows x 13 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_exp_train = exp_train[exp_train['PersonID'].isin(list(dt_train.iloc[train_idx][\"id\"]))]\n",
    "split_exp_valid = exp_train[exp_train['PersonID'].isin(list(dt_train.iloc[valid_idx][\"id\"]))]\n",
    "\n",
    "print(f\"index size: {len(train_idx)} == file estimate: {len(train_idx) * 7} == split size: {len(split_exp_train)}\")\n",
    "split_exp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1e956e0d-312a-47bb-8552-d155b748a16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>Path</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Class</th>\n",
       "      <th>Mask</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>BBoxX1</th>\n",
       "      <th>BBoxY1</th>\n",
       "      <th>BBoxX2</th>\n",
       "      <th>BBoxY2</th>\n",
       "      <th>new_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>../input/data/train/images/000002_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000002_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>146</td>\n",
       "      <td>252</td>\n",
       "      <td>334</td>\n",
       "      <td>../input/data/train/new_images2/000002_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>../input/data/train/images/000002_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000002_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>167</td>\n",
       "      <td>241</td>\n",
       "      <td>347</td>\n",
       "      <td>../input/data/train/new_images2/000002_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>../input/data/train/images/000002_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000002_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>181</td>\n",
       "      <td>254</td>\n",
       "      <td>371</td>\n",
       "      <td>../input/data/train/new_images2/000002_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>../input/data/train/images/000002_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000002_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>172</td>\n",
       "      <td>244</td>\n",
       "      <td>353</td>\n",
       "      <td>../input/data/train/new_images2/000002_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>../input/data/train/images/000002_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000002_female_Asian...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>170</td>\n",
       "      <td>253</td>\n",
       "      <td>365</td>\n",
       "      <td>../input/data/train/new_images2/000002_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21814</th>\n",
       "      <td>5504</td>\n",
       "      <td>../input/data/train/images/005504_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005504_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>134</td>\n",
       "      <td>271</td>\n",
       "      <td>369</td>\n",
       "      <td>../input/data/train/new_images2/005504_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21815</th>\n",
       "      <td>5504</td>\n",
       "      <td>../input/data/train/images/005504_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005504_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>144</td>\n",
       "      <td>257</td>\n",
       "      <td>380</td>\n",
       "      <td>../input/data/train/new_images2/005504_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21816</th>\n",
       "      <td>5504</td>\n",
       "      <td>../input/data/train/images/005504_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005504_female_Asian...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>128</td>\n",
       "      <td>266</td>\n",
       "      <td>379</td>\n",
       "      <td>../input/data/train/new_images2/005504_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21817</th>\n",
       "      <td>5504</td>\n",
       "      <td>../input/data/train/images/005504_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005504_female_Asian...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>134</td>\n",
       "      <td>277</td>\n",
       "      <td>399</td>\n",
       "      <td>../input/data/train/new_images2/005504_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21818</th>\n",
       "      <td>5504</td>\n",
       "      <td>../input/data/train/images/005504_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005504_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>150</td>\n",
       "      <td>263</td>\n",
       "      <td>385</td>\n",
       "      <td>../input/data/train/new_images2/005504_female_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4396 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PersonID                                               Path  \\\n",
       "7            2  ../input/data/train/images/000002_female_Asian...   \n",
       "8            2  ../input/data/train/images/000002_female_Asian...   \n",
       "9            2  ../input/data/train/images/000002_female_Asian...   \n",
       "10           2  ../input/data/train/images/000002_female_Asian...   \n",
       "11           2  ../input/data/train/images/000002_female_Asian...   \n",
       "...        ...                                                ...   \n",
       "21814     5504  ../input/data/train/images/005504_female_Asian...   \n",
       "21815     5504  ../input/data/train/images/005504_female_Asian...   \n",
       "21816     5504  ../input/data/train/images/005504_female_Asian...   \n",
       "21817     5504  ../input/data/train/images/005504_female_Asian...   \n",
       "21818     5504  ../input/data/train/images/005504_female_Asian...   \n",
       "\n",
       "                                                Filename  Class  Mask  Gender  \\\n",
       "7      ../input/data/train/images/000002_female_Asian...      4     0       1   \n",
       "8      ../input/data/train/images/000002_female_Asian...      4     0       1   \n",
       "9      ../input/data/train/images/000002_female_Asian...      4     0       1   \n",
       "10     ../input/data/train/images/000002_female_Asian...      4     0       1   \n",
       "11     ../input/data/train/images/000002_female_Asian...     10     1       1   \n",
       "...                                                  ...    ...   ...     ...   \n",
       "21814  ../input/data/train/images/005504_female_Asian...      5     0       1   \n",
       "21815  ../input/data/train/images/005504_female_Asian...      5     0       1   \n",
       "21816  ../input/data/train/images/005504_female_Asian...     11     1       1   \n",
       "21817  ../input/data/train/images/005504_female_Asian...     17     2       1   \n",
       "21818  ../input/data/train/images/005504_female_Asian...      5     0       1   \n",
       "\n",
       "       Age  Age_Class  BBoxX1  BBoxY1  BBoxX2  BBoxY2  \\\n",
       "7       52          1     103     146     252     334   \n",
       "8       52          1     104     167     241     347   \n",
       "9       52          1     108     181     254     371   \n",
       "10      52          1     103     172     244     353   \n",
       "11      52          1     112     170     253     365   \n",
       "...    ...        ...     ...     ...     ...     ...   \n",
       "21814   60          2      98     134     271     369   \n",
       "21815   60          2      81     144     257     380   \n",
       "21816   60          2      88     128     266     379   \n",
       "21817   60          2      95     134     277     399   \n",
       "21818   60          2      85     150     263     385   \n",
       "\n",
       "                                                new_path  \n",
       "7      ../input/data/train/new_images2/000002_female_...  \n",
       "8      ../input/data/train/new_images2/000002_female_...  \n",
       "9      ../input/data/train/new_images2/000002_female_...  \n",
       "10     ../input/data/train/new_images2/000002_female_...  \n",
       "11     ../input/data/train/new_images2/000002_female_...  \n",
       "...                                                  ...  \n",
       "21814  ../input/data/train/new_images2/005504_female_...  \n",
       "21815  ../input/data/train/new_images2/005504_female_...  \n",
       "21816  ../input/data/train/new_images2/005504_female_...  \n",
       "21817  ../input/data/train/new_images2/005504_female_...  \n",
       "21818  ../input/data/train/new_images2/005504_female_...  \n",
       "\n",
       "[4396 rows x 13 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_exp_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9e5571cf-f222-4c39-b601-f00cf9d35fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(exp_train)):\n",
    "    filename = exp_train.iloc[idx]['Path']\n",
    "    new_filename = exp_train.iloc[idx]['new_path']\n",
    "    parent_dir = '/'.join(new_filename.split(\"/\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9a4c0082-bac5-4199-8dc0-f545acde31ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>Path</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Class</th>\n",
       "      <th>Mask</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>BBoxX1</th>\n",
       "      <th>BBoxY1</th>\n",
       "      <th>BBoxX2</th>\n",
       "      <th>BBoxY2</th>\n",
       "      <th>new_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>146</td>\n",
       "      <td>250</td>\n",
       "      <td>347</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>160</td>\n",
       "      <td>245</td>\n",
       "      <td>334</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>127</td>\n",
       "      <td>230</td>\n",
       "      <td>311</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>143</td>\n",
       "      <td>244</td>\n",
       "      <td>326</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>../input/data/train/images/000001_female_Asian...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>125</td>\n",
       "      <td>244</td>\n",
       "      <td>316</td>\n",
       "      <td>../input/data/train/new_images2/000001_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21821</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>110</td>\n",
       "      <td>284</td>\n",
       "      <td>389</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21822</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>102</td>\n",
       "      <td>293</td>\n",
       "      <td>397</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21823</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>288</td>\n",
       "      <td>444</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21824</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>120</td>\n",
       "      <td>273</td>\n",
       "      <td>410</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21825</th>\n",
       "      <td>5515</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>../input/data/train/images/005515_female_Asian...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>107</td>\n",
       "      <td>277</td>\n",
       "      <td>391</td>\n",
       "      <td>../input/data/train/new_images2/005515_female_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21826 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PersonID                                               Path  \\\n",
       "0            1  ../input/data/train/images/000001_female_Asian...   \n",
       "1            1  ../input/data/train/images/000001_female_Asian...   \n",
       "2            1  ../input/data/train/images/000001_female_Asian...   \n",
       "3            1  ../input/data/train/images/000001_female_Asian...   \n",
       "4            1  ../input/data/train/images/000001_female_Asian...   \n",
       "...        ...                                                ...   \n",
       "21821     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21822     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21823     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21824     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "21825     5515  ../input/data/train/images/005515_female_Asian...   \n",
       "\n",
       "                                                Filename  Class  Mask  Gender  \\\n",
       "0      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "1      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "2      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "3      ../input/data/train/images/000001_female_Asian...      4     0       1   \n",
       "4      ../input/data/train/images/000001_female_Asian...     10     1       1   \n",
       "...                                                  ...    ...   ...     ...   \n",
       "21821  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "21822  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "21823  ../input/data/train/images/005515_female_Asian...     11     1       1   \n",
       "21824  ../input/data/train/images/005515_female_Asian...     17     2       1   \n",
       "21825  ../input/data/train/images/005515_female_Asian...      5     0       1   \n",
       "\n",
       "       Age  Age_Class  BBoxX1  BBoxY1  BBoxX2  BBoxY2  \\\n",
       "0       45          1     110     146     250     347   \n",
       "1       45          1     112     160     245     334   \n",
       "2       45          1     107     127     230     311   \n",
       "3       45          1     120     143     244     326   \n",
       "4       45          1     122     125     244     316   \n",
       "...    ...        ...     ...     ...     ...     ...   \n",
       "21821   60          2      64     110     284     389   \n",
       "21822   60          2      66     102     293     397   \n",
       "21823   60          2      67      97     288     444   \n",
       "21824   60          2      77     120     273     410   \n",
       "21825   60          2      59     107     277     391   \n",
       "\n",
       "                                                new_path  \n",
       "0      ../input/data/train/new_images2/000001_female_...  \n",
       "1      ../input/data/train/new_images2/000001_female_...  \n",
       "2      ../input/data/train/new_images2/000001_female_...  \n",
       "3      ../input/data/train/new_images2/000001_female_...  \n",
       "4      ../input/data/train/new_images2/000001_female_...  \n",
       "...                                                  ...  \n",
       "21821  ../input/data/train/new_images2/005515_female_...  \n",
       "21822  ../input/data/train/new_images2/005515_female_...  \n",
       "21823  ../input/data/train/new_images2/005515_female_...  \n",
       "21824  ../input/data/train/new_images2/005515_female_...  \n",
       "21825  ../input/data/train/new_images2/005515_female_...  \n",
       "\n",
       "[21826 rows x 13 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bfde03-9fef-4aa6-b15b-49a038e76d98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx in range(len(exp_train)):\n",
    "    filename = exp_train.iloc[idx]['Path']\n",
    "    new_filename = exp_train.iloc[idx]['new_path']\n",
    "    parent_dir = '/'.join(new_filename.split(\"/\")[:-1])\n",
    "    \n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    \n",
    "    X = cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB)\n",
    "    x1 = exp_train.iloc[idx]['BBoxX1']\n",
    "    x2 = exp_train.iloc[idx]['BBoxX2']\n",
    "    y1 = exp_train.iloc[idx]['BBoxY1']\n",
    "    y2 = exp_train.iloc[idx]['BBoxY2']\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    w = w // 3\n",
    "    h = h // 3\n",
    "\n",
    "    nx1 = max(0, x1-w)\n",
    "    nx2 = min(384, x2+w)\n",
    "    ny1 = max(0, y1-h)\n",
    "    ny2 = min(512, y2+h)\n",
    "    X = X[ny1:ny2, nx1:nx2]\n",
    "    \n",
    "    \n",
    "    X = cv2.resize(X, (350, 350))\n",
    "    if idx % 3000 == 0:\n",
    "        plt.imshow(X)\n",
    "        plt.show()\n",
    "        \n",
    "    X = cv2.cvtColor(X, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    cv2.imwrite(new_filename, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "304c6a61-ff17-4777-8132-18def61c8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = split_exp_train.loc[:,\"new_path\"]\n",
    "train_label = split_exp_train.loc[:,\"Class\"]\n",
    "\n",
    "valid_image = split_exp_valid.loc[:,\"new_path\"]\n",
    "valid_label = split_exp_valid.loc[:,\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "84ec33c6-5a23-41ec-8980-2c7f0ecd1631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17430\n",
      "4396\n"
     ]
    }
   ],
   "source": [
    "print(len(train_image))\n",
    "print(len(valid_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "694474c7-7175-40e6-b071-e50218629f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.Series(train_image)\n",
    "train_label = pd.Series(train_label)\n",
    "\n",
    "valid_data = pd.Series(valid_image)\n",
    "valid_label = pd.Series(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e2cd7b29-5f03-444e-b781-902ca74f2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize, ToTensor, Normalize, Compose, CenterCrop, ColorJitter\n",
    "from PIL import Image\n",
    "\n",
    "class Dataset_Mask(Dataset):\n",
    "    def __init__(self, data, label, encoding=True, midcrop=True, transform=None, is_train=True):\n",
    "        self.encoding = encoding\n",
    "        self.midcrop = midcrop\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.is_train = is_train\n",
    "        self.label = label.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        y = self.label[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            return self.transform(X), y\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e2a22aff-e634-4f15-877c-752d450d01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train_set = Dataset_Mask(data=train_data, label=train_label, is_train=True, transform=transforms.Compose([\n",
    "                                    ToTensor(),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "caf9fd0a-27a3-4ba1-ab39-fea87ac96227",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_val_set = Dataset_Mask(data=valid_data, label=valid_label, is_train=False, transform = transforms.Compose([\n",
    "                                    ToTensor(),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c3823f79-7f33-4eb7-864e-ab22df6b0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_class_weights(labels, class_num):\n",
    "    print(labels.shape)\n",
    "    print(labels)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    class_weights = np.zeros_like(labels) \n",
    "    \n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    # 각 class가 몇 번 등장하는지 count\n",
    "\n",
    "    print(labels)\n",
    "    print(counts)\n",
    "\n",
    "    for cls in range(class_num):\n",
    "        class_weights = np.where(labels == cls, 1/counts[cls], class_weights)\n",
    "        # label이 class에 해당하면 count의 역수 적용\n",
    "    return class_weights\n",
    "class_num = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "839aa16e-f8cb-4ca1-972a-c2f011727a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17430,)\n",
      "0         4\n",
      "1         4\n",
      "2         4\n",
      "3         4\n",
      "4        10\n",
      "         ..\n",
      "17425     5\n",
      "17426     5\n",
      "17427    11\n",
      "17428    17\n",
      "17429     5\n",
      "Name: Class, Length: 17430, dtype: int64\n",
      "[ 4  4  4 ... 11 17  5]\n",
      "[2265 1586 1140 2860 3251 1350  453  316  228  572  649  270  453  317\n",
      "  228  572  650  270]\n",
      "[0.0003076  0.0003076  0.0003076  ... 0.0037037  0.0037037  0.00074074]\n",
      "17430\n"
     ]
    }
   ],
   "source": [
    "class_weights = make_class_weights(mask_train_set.label, class_num) # np to double tensor\n",
    "\n",
    "print(class_weights)\n",
    "print(len(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "44b7ccc0-91e2-496d-94e7-199df4b8c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = sampler.WeightedRandomSampler(weights=class_weights, num_samples=len(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fa87855a-30bf-45c4-813d-51248be52338",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_image = [mask_train_set[i][1] for i in range(len(mask_train_set))]\n",
    "v_image = [mask_val_set[i][1] for i in range(len(mask_val_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b3ddcf93-a96b-4ad5-afff-a4636ed62841",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.DataFrame(t_image, columns=['counts'])\n",
    "v_df = pd.DataFrame(v_image, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bc9f8b5e-c98b-453a-9faa-6eb6f3ef6d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'valid set labels')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.countplot(x='counts', data=t_df, ax=axes[0])\n",
    "axes[0].set_xlabel(\"train set labels\")\n",
    "sns.countplot(x='counts', data=v_df, ax=axes[1])\n",
    "axes[1].set_xlabel(\"valid set labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4e1579fb-bd5a-4434-bc69-13054835e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size : 17430\n",
      "validation data size : 4396\n"
     ]
    }
   ],
   "source": [
    "print(f'training data size : {len(mask_train_set)}')\n",
    "print(f'validation data size : {len(mask_val_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "37b1ced0-1e34-4d50-b2b2-dcdff8fd33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader_mask = DataLoader(dataset = mask_train_set, batch_size=batch_size, sampler=sampler, num_workers=2)\n",
    "val_dataloader_mask = DataLoader(dataset = mask_val_set, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "af71a4ef-a137-47b0-af94-eebedaa36014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "# print('필요 입력 채널 개수', model.conv1.weight.shape[1])\n",
    "# print('네트워크 출력 채널 개수', model.fc.weight.shape[0])\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "11357fc4-548b-452e-bbd8-e60ef6261308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필요 입력 채널 개수 3\n",
      "네트워크 출력 채널 개수 18\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class_num = 18\n",
    "model.fc = nn.Linear(in_features=2048, out_features=class_num, bias=True)\n",
    "nn.init.xavier_uniform_(model.fc.weight)\n",
    "stdv = 1. / math.sqrt(model.fc.weight.size(1))\n",
    "model.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "print('필요 입력 채널 개수', model.conv1.weight.shape[1])\n",
    "print('네트워크 출력 채널 개수', model.fc.weight.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9a1a2262-f820-4294-8086-3a48a5e5d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")\n",
    "\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCH = 50\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#lr = 1e-3\n",
    "#betas = (0.9, 0.999)\n",
    "#weight_decay = 0.5e-4\n",
    "#eps = 1e-8\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "64a36f92-aad5-4bbb-a920-29d50f0f058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "n_param = 0\n",
    "for p_idx, (param_name, param) in enumerate(model.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        \n",
    "        #if param_name.startswith('module.fc') or param_name.startswith('module.layer4') or param_name.startswith('module.layer3'):\n",
    "        #    param.requires_grad = True  # Train\n",
    "        #else:\n",
    "        #    param.requires_grad = False # Freeze\n",
    "            \n",
    "        param_numpy = param.detach().cpu().numpy()\n",
    "        n_param += len(param_numpy.reshape(-1))\n",
    "#         print (\"[%d] name:[%s] shape:[%s].\"%(p_idx,param_name,param_numpy.shape))\n",
    "#         print (\"    val:%s\"%(param_numpy.reshape(-1)[:5]))\n",
    "#         print(f\"    --[{param.requires_grad}].\")\n",
    "# print (\"Total number of parameters:[%s].\"%(format(n_param,',d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8c067d0e-38c9-4ab8-baba-88cf8dcb8c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:53<00:00,  1.07s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0/50] training loss 0.281, training accuracy 0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.84it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update checkpoint!!!\n",
      "[val] acc : 0.834, loss : 0.590, f1 score: 0.673 -- size(69)\n",
      "best acc : 0.834, best loss : 0.590, best f1 : 0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:50<00:00,  1.06s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1/50] training loss 0.045, training accuracy 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.84it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update checkpoint!!!\n",
      "[val] acc : 0.860, loss : 0.604, f1 score: 0.734 -- size(69)\n",
      "best acc : 0.860, best loss : 0.590, best f1 : 0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:47<00:00,  1.05s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[2/50] training loss 0.027, training accuracy 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.83it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.848, loss : 0.650, f1 score: 0.717 -- size(69)\n",
      "best acc : 0.860, best loss : 0.590, best f1 : 0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:49<00:00,  1.06s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[3/50] training loss 0.019, training accuracy 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.86it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update checkpoint!!!\n",
      "[val] acc : 0.881, loss : 0.602, f1 score: 0.768 -- size(69)\n",
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:51<00:00,  1.07s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[4/50] training loss 0.018, training accuracy 0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.84it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.861, loss : 0.622, f1 score: 0.727 -- size(69)\n",
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:49<00:00,  1.06s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[5/50] training loss 0.015, training accuracy 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.88it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.863, loss : 0.693, f1 score: 0.748 -- size(69)\n",
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:49<00:00,  1.06s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[6/50] training loss 0.018, training accuracy 0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.69it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.864, loss : 0.697, f1 score: 0.741 -- size(69)\n",
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:47<00:00,  1.05s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[7/50] training loss 0.013, training accuracy 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.86it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.873, loss : 0.695, f1 score: 0.756 -- size(69)\n",
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:50<00:00,  1.06s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[8/50] training loss 0.013, training accuracy 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.87it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.846, loss : 0.821, f1 score: 0.672 -- size(69)\n",
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:53<00:00,  1.07s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[9/50] training loss 0.016, training accuracy 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.86it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.876, loss : 0.655, f1 score: 0.756 -- size(69)\n",
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:49<00:00,  1.06s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[10/50] training loss 0.013, training accuracy 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.87it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.854, loss : 0.752, f1 score: 0.721 -- size(69)\n",
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:47<00:00,  1.05s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[11/50] training loss 0.005, training accuracy 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.87it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.858, loss : 0.782, f1 score: 0.723 -- size(69)\n",
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:49<00:00,  1.06s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[12/50] training loss 0.013, training accuracy 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.88it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.872, loss : 0.773, f1 score: 0.743 -- size(69)\n",
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:48<00:00,  1.06s/it]\n",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[13/50] training loss 0.004, training accuracy 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:14<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "patience = 10\n",
    "cur_count = 0\n",
    "\n",
    "f1 = F1Score(num_classes=class_num, average='macro').to(device)\n",
    "best_f1_score = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for train_batch in tqdm(train_dataloader_mask):\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        torch.save(model, '../checkpoint/resnet50_crop_agu_detection/checkpoint_ep_%d.pth'% epoch)\n",
    "        \n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        \n",
    "    train_loss = loss_value / len(train_dataloader_mask)\n",
    "    train_acc = matches / len(mask_train_set)\n",
    "    \n",
    "    print(f\"epoch[{epoch}/{NUM_EPOCH}] training loss {train_loss:.3f}, training accuracy {train_acc:.3f}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        f1_score = 0\n",
    "        \n",
    "        for val_batch in tqdm(val_dataloader_mask):\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            \n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels==preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "            f1_score += f1(outs, labels)\n",
    "            \n",
    "        val_loss = np.sum(val_loss_items) / len(val_dataloader_mask)\n",
    "        val_acc = np.sum(val_acc_items) / len(mask_val_set)\n",
    "\n",
    "        f1_score /= len(val_dataloader_mask)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            \n",
    "        if f1_score > best_f1_score:\n",
    "            best_f1_score = f1_score\n",
    "            cur_count = 0\n",
    "            torch.save(model, '../checkpoint/resnet50_crop_agu_detection/checkpoint_best.pth')\n",
    "            print(\"Update checkpoint!!!\")\n",
    "        \n",
    "        else:\n",
    "            cur_count += 1\n",
    "            if cur_count >= patience:\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "\n",
    "            \n",
    "        print(f\"[val] acc : {val_acc:.3f}, loss : {val_loss:.3f}, f1 score: {f1_score:.3f} -- size({len(val_dataloader_mask)})\")\n",
    "        print(f\"best acc : {best_val_acc:.3f}, best loss : {best_val_loss:.3f}, best f1 : {best_f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "36aba938-2065-4e7f-8ee5-4dee873bbee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best acc : 0.881, best loss : 0.590, best f1 : 0.768\n"
     ]
    }
   ],
   "source": [
    "print(f\"best acc : {best_val_acc:.3f}, best loss : {best_val_loss:.3f}, best f1 : {best_f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2c15c-dbcb-4a3b-a6a7-28f7a45017ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8232b6a-1e46-43f2-8c35-4f4a63b0b478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53605ae4-079a-4f2c-b06b-db356fc7acd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "70295eb5-704c-4e13-8616-c0d859889998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ImageID  ans\n",
       "0  cbc5c6e168e63498590db46022617123f1fe1268.jpg    0\n",
       "1  0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    0\n",
       "2  b549040c49190cedc41327748aeb197c1670f14d.jpg    0\n",
       "3  4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    0\n",
       "4  248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir_path = '/opt/ml/input/data/eval/'\n",
    "test_image_path = '/opt/ml/input/data/new_images2/'\n",
    "\n",
    "model = torch.load('/opt/ml/checkpoint/resnet50_crop_agu_detection/checkpoint_best.pth')\n",
    "submission = pd.read_csv(test_dir_path+'info.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "101ae6c5-6b88-47da-95c3-07c226a6b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [os.path.join(test_image_path, img_id) for img_id in submission.ImageID]\n",
    "test_image = pd.Series(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0f28ee53-ecda-421c-8b09-d3be8a22324f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/ml/input/data/new_images2/cbc5c6e168e63498590db46022617123f1fe1268.jpg'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "94502bcf-b429-4dd9-8da5-d7943bee5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Dataset(Dataset):\n",
    "    def __init__(self, midcrop=True, transform=None):\n",
    "        self.midcrop = midcrop\n",
    "        self.data = test_image\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(test_image)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "263522b6-32ab-4a7d-81ae-2c4b45a232fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "48e83da5-f10c-4a8d-9661-0106dac9927f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Test_Dataset(transform = transforms.Compose([\n",
    "                            transforms.ToTensor()\n",
    "                        ]))\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir_path, 'submission_detection_crop3.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d72715-8549-4db3-aa19-7e0dc5d2c7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
