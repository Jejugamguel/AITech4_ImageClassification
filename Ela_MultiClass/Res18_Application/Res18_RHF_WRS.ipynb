{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchmetrics import F1Score\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import GPUtil\n",
    "import cv2\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  7% |  0% |\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 12\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>006954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>006955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>006956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>006957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                    path\n",
       "0     000001  female  Asian   45  000001_female_Asian_45\n",
       "1     000002  female  Asian   52  000002_female_Asian_52\n",
       "2     000004    male  Asian   54    000004_male_Asian_54\n",
       "3     000005  female  Asian   58  000005_female_Asian_58\n",
       "4     000006  female  Asian   59  000006_female_Asian_59\n",
       "...      ...     ...    ...  ...                     ...\n",
       "2695  006954    male  Asian   19    006954_male_Asian_19\n",
       "2696  006955    male  Asian   19    006955_male_Asian_19\n",
       "2697  006956    male  Asian   19    006956_male_Asian_19\n",
       "2698  006957    male  Asian   20    006957_male_Asian_20\n",
       "2699  006959    male  Asian   19    006959_male_Asian_19\n",
       "\n",
       "[2700 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir_path = '/opt/ml/input/data/train/'\n",
    "train_image_path = '/opt/ml/input/data/train/images/'\n",
    "\n",
    "dt_train = pd.read_csv(train_dir_path+'train.csv')\n",
    "dt_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>006954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>006955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>006956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>006957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                    path  age_range\n",
       "0     000001  female  Asian   45  000001_female_Asian_45          1\n",
       "1     000002  female  Asian   52  000002_female_Asian_52          1\n",
       "2     000004    male  Asian   54    000004_male_Asian_54          1\n",
       "3     000005  female  Asian   58  000005_female_Asian_58          1\n",
       "4     000006  female  Asian   59  000006_female_Asian_59          1\n",
       "...      ...     ...    ...  ...                     ...        ...\n",
       "2695  006954    male  Asian   19    006954_male_Asian_19          0\n",
       "2696  006955    male  Asian   19    006955_male_Asian_19          0\n",
       "2697  006956    male  Asian   19    006956_male_Asian_19          0\n",
       "2698  006957    male  Asian   20    006957_male_Asian_20          0\n",
       "2699  006959    male  Asian   19    006959_male_Asian_19          0\n",
       "\n",
       "[2700 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_age_range(age):\n",
    "    if age < 30:\n",
    "        return 0\n",
    "    elif 30 <= age < 60:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "    \n",
    "dt_train['age_range'] = dt_train['age'].apply(lambda x : get_age_range(x))\n",
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 데이터 증강은 여기서 쓰면 좋을듯?\n",
    "#### 60세 이상 데이터 6배 증강 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, valid_idx = train_test_split(np.arange(len(dt_train)),\n",
    "                                       test_size=0.2,\n",
    "                                       shuffle=True,\n",
    "                                       stratify=dt_train['age_range'])\n",
    "\n",
    "train_image, train_label = [], []\n",
    "valid_image, valid_label = [], []\n",
    "\n",
    "for idx in train_idx:\n",
    "    path = dt_train.iloc[idx]['path']\n",
    "    for file_name in [i for i in os.listdir(train_image_path+path) if i[0] != '.']:\n",
    "        train_image.append(train_image_path+path+'/'+file_name)\n",
    "        train_label.append((path.split('_')[1], path.split('_')[3], file_name.split('.')[0]))  \n",
    "        \n",
    "for idx in valid_idx:\n",
    "    path = dt_train.iloc[idx]['path']\n",
    "    for file_name in [i for i in os.listdir(train_image_path+path) if i[0] != '.']:\n",
    "        valid_image.append(train_image_path+path+'/'+file_name)\n",
    "        valid_label.append((path.split('_')[1], path.split('_')[3], file_name.split('.')[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.Series(train_image)\n",
    "train_label = pd.Series(train_label)\n",
    "\n",
    "valid_data = pd.Series(valid_image)\n",
    "valid_label = pd.Series(valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_enc(x):\n",
    "    def gender(i):\n",
    "        if i == 'male':\n",
    "            return 0\n",
    "        elif i == 'female':\n",
    "            return 3\n",
    "    def age(j):\n",
    "        j = int(j)\n",
    "        if j < 30:\n",
    "            return 0\n",
    "        elif j >= 30 and j < 60:\n",
    "            return 1\n",
    "        elif j >= 60:\n",
    "            return 2\n",
    "    def mask(k):\n",
    "        if k == 'normal':\n",
    "            return 12\n",
    "        elif 'incorrect' in k:\n",
    "            return 6\n",
    "        else:\n",
    "            return 0\n",
    "    return gender(x[0]) + age(x[1]) + mask(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_sepclass(x):\n",
    "    # x 입력형식 : (성별, 나이, 마스크) 튜플\n",
    "    # 출력형식 : (성별인코딩, 나이인코딩, 마스크인코딩)\n",
    "    def gender(i):\n",
    "        if i == 'male':\n",
    "            return 0\n",
    "        elif i == 'female':\n",
    "            return 1\n",
    "    def age(j):\n",
    "        j = int(j)\n",
    "        if j < 30:\n",
    "            return 0\n",
    "        elif j >= 30 and j < 60:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    def mask(k):\n",
    "        if k == 'normal':\n",
    "            return 2\n",
    "        elif 'incorrect' in k:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    return gender(x[0]), age(x[1]), mask(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Mask(Dataset):\n",
    "    def __init__(self, data, label, encoding=True, midcrop=True, transform=None):\n",
    "        self.encoding = encoding\n",
    "        self.midcrop = midcrop\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        \n",
    "        if encoding:\n",
    "            self.label = self.label.apply(enc_sepclass)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        y = self.label[idx]\n",
    "        \n",
    "        if self.midcrop:\n",
    "            X = X[70:420, 17:367]\n",
    "        \n",
    "        if self.transform:\n",
    "            return self.transform(X), y\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train_set = Dataset_Mask(data=train_data, label=train_label, transform = transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor()\n",
    "                            ]))\n",
    "mask_val_set = Dataset_Mask(data=valid_data, label=valid_label, transform = transforms.Compose([\n",
    "                                transforms.ToTensor()\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffae3016640>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def vec2label(x):\n",
    "    return 3*x[0] + x[1] + 6*x[2]\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax2 = plt.subplot(122)\n",
    "\n",
    "t_image = [mask_train_set[i][1] for i in range(len(mask_train_set))]\n",
    "v_image = [mask_val_set[i][1] for i in range(len(mask_val_set))]\n",
    "\n",
    "t_Series = pd.Series(t_image).apply(vec2label).value_counts().sort_index()\n",
    "v_Series = pd.Series(v_image).apply(vec2label).value_counts().sort_index()\n",
    "\n",
    "t_Series.plot(kind='bar', ax = ax1)\n",
    "v_Series.plot(kind='bar', ax = ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size : 15120\n",
      "validation data size : 3780\n"
     ]
    }
   ],
   "source": [
    "print(f'training data size : {len(mask_train_set)}')\n",
    "print(f'validation data size : {len(mask_val_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_srs = pd.Series(t_image)\n",
    "\n",
    "def sampler_weight(srs):\n",
    "    num_per_label = dict(srs.value_counts())\n",
    "    num_data = len(srs)\n",
    "    \n",
    "    return [num_data / num_per_label[i] for i in srs], num_data\n",
    "\n",
    "sampler = WeightedRandomSampler(*sampler_weight(label_srs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataloader_mask = DataLoader(dataset = mask_train_set, batch_size=batch_size, num_workers=2, sampler = sampler)\n",
    "val_dataloader_mask = DataLoader(dataset = mask_val_set, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained된 파라미터 불러오기 + out1, out2, out3 파라미터 추가\n",
    "weight = torchvision.models.ResNet18_Weights.IMAGENET1K_V1.get_state_dict(progress=True)\n",
    "for i in ['out1.weight', 'out1.bias', 'out2.weight', 'out2.bias', 'out3.weight', 'out3.bias']:\n",
    "    if 'bias' in i:\n",
    "        if 'out1' in i:\n",
    "            weight[i] = torch.randn(2)\n",
    "        else:\n",
    "            weight[i] = torch.rand(3)\n",
    "    else:\n",
    "        if 'out1' in i:\n",
    "            weight[i] = torch.randn(2, 512)\n",
    "        else:\n",
    "            weight[i] = torch.randn(3, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R18_MultiClass(torchvision.models.ResNet):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.out1 = nn.Linear(512, 2, bias=True)\n",
    "        self.out2 = nn.Linear(512, 3, bias=True)\n",
    "        self.out3 = nn.Linear(512, 3, bias=True)\n",
    "        \n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # out1 : gender class\n",
    "        # out2 : age class\n",
    "        # out3 : mask class\n",
    "        out1 = self.out1(x)\n",
    "        out2 = self.out2(x)\n",
    "        out3 = self.out3(x)\n",
    "        \n",
    "        return out1, out2, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R18_MultiClass(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  (out1): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (out2): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (out3): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = torchvision.models.resnet.BasicBlock\n",
    "layers = [2, 2, 2, 2]\n",
    "\n",
    "basemodel_resnet18 = R18_MultiClass(block = block, layers = layers)\n",
    "basemodel_resnet18.load_state_dict(weight)\n",
    "print(basemodel_resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0115, -0.0163,  0.0383])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "nn.init.xavier_uniform_(basemodel_resnet18.out1.weight)\n",
    "stdv = 1. / math.sqrt(basemodel_resnet18.out1.weight.size(1))\n",
    "basemodel_resnet18.out1.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "nn.init.xavier_uniform_(basemodel_resnet18.out2.weight)\n",
    "stdv = 1. / math.sqrt(basemodel_resnet18.out2.weight.size(1))\n",
    "basemodel_resnet18.out2.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "nn.init.xavier_uniform_(basemodel_resnet18.out3.weight)\n",
    "stdv = 1. / math.sqrt(basemodel_resnet18.out3.weight.size(1))\n",
    "basemodel_resnet18.out3.bias.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")\n",
    "\n",
    "basemodel_resnet18.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCH = 50\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(basemodel_resnet18.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] name:[conv1.weight] shape:[(64, 3, 7, 7)].\n",
      "    val:[-0.01  -0.006 -0.002  0.075  0.057]\n",
      "[1] name:[bn1.weight] shape:[(64,)].\n",
      "    val:[ 2.349e-01  2.663e-01 -5.110e-08  5.187e-01  3.440e-09]\n",
      "[2] name:[bn1.bias] shape:[(64,)].\n",
      "    val:[ 2.307e-01  2.538e-01 -1.054e-06 -6.644e-01 -1.657e-08]\n",
      "[3] name:[layer1.0.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[ 0.058 -0.095 -0.02  -0.075 -0.799]\n",
      "[4] name:[layer1.0.bn1.weight] shape:[(64,)].\n",
      "    val:[0.309 0.215 0.237 0.426 0.514]\n",
      "[5] name:[layer1.0.bn1.bias] shape:[(64,)].\n",
      "    val:[ 0.166  0.242  0.178 -0.043 -0.205]\n",
      "[6] name:[layer1.0.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[ 0.026 -0.105 -0.005 -0.086 -0.33 ]\n",
      "[7] name:[layer1.0.bn2.weight] shape:[(64,)].\n",
      "    val:[0.25  0.22  0.276 0.607 0.265]\n",
      "[8] name:[layer1.0.bn2.bias] shape:[(64,)].\n",
      "    val:[ 0.228  0.009 -0.067 -0.069  0.36 ]\n",
      "[9] name:[layer1.1.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[ 0.02  -0.005 -0.004 -0.02  -0.012]\n",
      "[10] name:[layer1.1.bn1.weight] shape:[(64,)].\n",
      "    val:[0.391 0.437 0.375 0.399 0.34 ]\n",
      "[11] name:[layer1.1.bn1.bias] shape:[(64,)].\n",
      "    val:[-0.1   -0.476 -0.047 -0.27  -0.083]\n",
      "[12] name:[layer1.1.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.022 -0.005  0.005 -0.008  0.042]\n",
      "[13] name:[layer1.1.bn2.weight] shape:[(64,)].\n",
      "    val:[0.256 0.569 0.404 0.513 0.218]\n",
      "[14] name:[layer1.1.bn2.bias] shape:[(64,)].\n",
      "    val:[-0.178 -0.129  0.035 -0.145  0.186]\n",
      "[15] name:[layer2.0.conv1.weight] shape:[(128, 64, 3, 3)].\n",
      "    val:[-0.072 -0.11  -0.137  0.071 -0.015]\n",
      "[16] name:[layer2.0.bn1.weight] shape:[(128,)].\n",
      "    val:[0.325 0.361 0.296 0.291 0.341]\n",
      "[17] name:[layer2.0.bn1.bias] shape:[(128,)].\n",
      "    val:[-0.059 -0.169 -0.021  0.003 -0.096]\n",
      "[18] name:[layer2.0.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.007 -0.01   0.003 -0.011  0.026]\n",
      "[19] name:[layer2.0.bn2.weight] shape:[(128,)].\n",
      "    val:[0.145 0.327 0.311 0.254 0.409]\n",
      "[20] name:[layer2.0.bn2.bias] shape:[(128,)].\n",
      "    val:[ 0.025  0.059  0.135 -0.109 -0.047]\n",
      "[21] name:[layer2.0.downsample.0.weight] shape:[(128, 64, 1, 1)].\n",
      "    val:[ 0.016 -0.311  0.013  0.009 -0.028]\n",
      "[22] name:[layer2.0.downsample.1.weight] shape:[(128,)].\n",
      "    val:[0.333 0.058 0.071 0.344 0.176]\n",
      "[23] name:[layer2.0.downsample.1.bias] shape:[(128,)].\n",
      "    val:[ 0.025  0.059  0.135 -0.109 -0.047]\n",
      "[24] name:[layer2.1.conv1.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.001 -0.008 -0.008  0.025  0.002]\n",
      "[25] name:[layer2.1.bn1.weight] shape:[(128,)].\n",
      "    val:[0.332 0.291 0.325 0.343 0.301]\n",
      "[26] name:[layer2.1.bn1.bias] shape:[(128,)].\n",
      "    val:[-0.173 -0.234 -0.338 -0.081 -0.192]\n",
      "[27] name:[layer2.1.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.016  0.005 -0.001 -0.009 -0.019]\n",
      "[28] name:[layer2.1.bn2.weight] shape:[(128,)].\n",
      "    val:[0.119 0.162 0.308 0.293 0.296]\n",
      "[29] name:[layer2.1.bn2.bias] shape:[(128,)].\n",
      "    val:[-0.14  -0.089 -0.415 -0.226 -0.074]\n",
      "[30] name:[layer3.0.conv1.weight] shape:[(256, 128, 3, 3)].\n",
      "    val:[-0.016 -0.017 -0.016 -0.005  0.015]\n",
      "[31] name:[layer3.0.bn1.weight] shape:[(256,)].\n",
      "    val:[0.286 0.243 0.303 0.317 0.301]\n",
      "[32] name:[layer3.0.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.092  0.019 -0.123 -0.061 -0.1  ]\n",
      "[33] name:[layer3.0.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.009 -0.034 -0.012 -0.025 -0.08 ]\n",
      "[34] name:[layer3.0.bn2.weight] shape:[(256,)].\n",
      "    val:[0.321 0.212 0.266 0.359 0.278]\n",
      "[35] name:[layer3.0.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.026  0.1   -0.007 -0.088  0.008]\n",
      "[36] name:[layer3.0.downsample.0.weight] shape:[(256, 128, 1, 1)].\n",
      "    val:[ 0.008 -0.019 -0.017  0.014 -0.041]\n",
      "[37] name:[layer3.0.downsample.1.weight] shape:[(256,)].\n",
      "    val:[0.067 0.051 0.038 0.169 0.06 ]\n",
      "[38] name:[layer3.0.downsample.1.bias] shape:[(256,)].\n",
      "    val:[-0.026  0.1   -0.007 -0.088  0.008]\n",
      "[39] name:[layer3.1.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[0.048 0.048 0.038 0.05  0.055]\n",
      "[40] name:[layer3.1.bn1.weight] shape:[(256,)].\n",
      "    val:[0.248 0.197 0.228 0.271 0.33 ]\n",
      "[41] name:[layer3.1.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.133 -0.064 -0.324 -0.239 -0.326]\n",
      "[42] name:[layer3.1.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.043 -0.026 -0.022 -0.017 -0.008]\n",
      "[43] name:[layer3.1.bn2.weight] shape:[(256,)].\n",
      "    val:[0.197 0.177 0.13  0.199 0.184]\n",
      "[44] name:[layer3.1.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.016 -0.203  0.029 -0.17  -0.184]\n",
      "[45] name:[layer4.0.conv1.weight] shape:[(512, 256, 3, 3)].\n",
      "    val:[-0.012 -0.019 -0.022  0.02   0.024]\n",
      "[46] name:[layer4.0.bn1.weight] shape:[(512,)].\n",
      "    val:[0.243 0.223 0.251 0.229 0.207]\n",
      "[47] name:[layer4.0.bn1.bias] shape:[(512,)].\n",
      "    val:[-0.199 -0.159 -0.205 -0.16  -0.127]\n",
      "[48] name:[layer4.0.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[ 0.    -0.015 -0.017 -0.013 -0.033]\n",
      "[49] name:[layer4.0.bn2.weight] shape:[(512,)].\n",
      "    val:[0.447 0.514 0.434 0.342 0.386]\n",
      "[50] name:[layer4.0.bn2.bias] shape:[(512,)].\n",
      "    val:[-0.176 -0.216 -0.205 -0.169 -0.163]\n",
      "[51] name:[layer4.0.downsample.0.weight] shape:[(512, 256, 1, 1)].\n",
      "    val:[0.006 0.002 0.017 0.005 0.01 ]\n",
      "[52] name:[layer4.0.downsample.1.weight] shape:[(512,)].\n",
      "    val:[0.169 0.337 0.299 0.375 0.151]\n",
      "[53] name:[layer4.0.downsample.1.bias] shape:[(512,)].\n",
      "    val:[-0.176 -0.216 -0.205 -0.169 -0.163]\n",
      "[54] name:[layer4.1.conv1.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[-0.008 -0.006  0.006  0.005 -0.007]\n",
      "[55] name:[layer4.1.bn1.weight] shape:[(512,)].\n",
      "    val:[0.259 0.307 0.259 0.322 0.266]\n",
      "[56] name:[layer4.1.bn1.bias] shape:[(512,)].\n",
      "    val:[-0.167 -0.302 -0.219 -0.292 -0.197]\n",
      "[57] name:[layer4.1.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[ 0.     0.004 -0.002  0.     0.002]\n",
      "[58] name:[layer4.1.bn2.weight] shape:[(512,)].\n",
      "    val:[1.842 1.831 1.765 1.829 1.95 ]\n",
      "[59] name:[layer4.1.bn2.bias] shape:[(512,)].\n",
      "    val:[0.237 0.343 0.328 0.464 0.223]\n",
      "[60] name:[fc.weight] shape:[(1000, 512)].\n",
      "    val:[-0.018 -0.07  -0.052 -0.01   0.015]\n",
      "[61] name:[fc.bias] shape:[(1000,)].\n",
      "    val:[-0.003  0.003  0.001 -0.027  0.006]\n",
      "[62] name:[out1.weight] shape:[(2, 512)].\n",
      "    val:[-0.051  0.007  0.099  0.093 -0.042]\n",
      "[63] name:[out1.bias] shape:[(2,)].\n",
      "    val:[0.037 0.008]\n",
      "[64] name:[out2.weight] shape:[(3, 512)].\n",
      "    val:[-0.005  0.097  0.072 -0.095  0.072]\n",
      "[65] name:[out2.bias] shape:[(3,)].\n",
      "    val:[-0.022 -0.023  0.02 ]\n",
      "[66] name:[out3.weight] shape:[(3, 512)].\n",
      "    val:[-0.006  0.056  0.05   0.022 -0.013]\n",
      "[67] name:[out3.bias] shape:[(3,)].\n",
      "    val:[ 0.012 -0.016  0.038]\n",
      "Total number of parameters:[11,693,616].\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "n_param = 0\n",
    "for p_idx, (param_name, param) in enumerate(basemodel_resnet18.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        param_numpy = param.detach().cpu().numpy()\n",
    "        n_param += len(param_numpy.reshape(-1))\n",
    "        print (\"[%d] name:[%s] shape:[%s].\"%(p_idx,param_name,param_numpy.shape))\n",
    "        print (\"    val:%s\"%(param_numpy.reshape(-1)[:5]))\n",
    "print (\"Total number of parameters:[%s].\"%(format(n_param,',d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15910/529955855.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p_gen, p_age, p_msk = F.softmax(p_gen), F.softmax(p_age), F.softmax(p_msk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1/50] training loss 0.515, training accuracy 4.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15910/529955855.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p_gen, p_age, p_msk = F.softmax(p_gen), F.softmax(p_age), F.softmax(p_msk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] acc : 0.794, loss : 1.629\n",
      "best acc : 0.794, best loss : 1.629\n",
      "epoch[2/50] training loss 0.480, training accuracy 5.333\n",
      "[val] acc : 0.882, loss : 1.540\n",
      "best acc : 0.882, best loss : 1.540\n",
      "epoch[3/50] training loss 0.479, training accuracy 5.333\n",
      "[val] acc : 0.887, loss : 1.529\n",
      "best acc : 0.887, best loss : 1.529\n",
      "epoch[4/50] training loss 0.477, training accuracy 5.333\n",
      "[val] acc : 0.887, loss : 1.533\n",
      "best acc : 0.887, best loss : 1.529\n",
      "epoch[5/50] training loss 0.474, training accuracy 5.333\n",
      "[val] acc : 0.888, loss : 1.529\n",
      "best acc : 0.888, best loss : 1.529\n",
      "epoch[6/50] training loss 0.473, training accuracy 5.333\n",
      "[val] acc : 0.887, loss : 1.528\n",
      "best acc : 0.888, best loss : 1.528\n",
      "epoch[7/50] training loss 0.488, training accuracy 5.000\n",
      "[val] acc : 0.891, loss : 1.527\n",
      "best acc : 0.891, best loss : 1.527\n",
      "epoch[8/50] training loss 0.487, training accuracy 5.000\n",
      "[val] acc : 0.868, loss : 1.552\n",
      "best acc : 0.891, best loss : 1.527\n",
      "epoch[9/50] training loss 0.473, training accuracy 5.333\n",
      "[val] acc : 0.879, loss : 1.541\n",
      "best acc : 0.891, best loss : 1.527\n",
      "epoch[10/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.899, loss : 1.520\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[11/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.894, loss : 1.525\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[12/50] training loss 0.479, training accuracy 5.333\n",
      "[val] acc : 0.888, loss : 1.530\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[13/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.882, loss : 1.537\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[14/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.891, loss : 1.525\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[15/50] training loss 0.497, training accuracy 4.667\n",
      "[val] acc : 0.890, loss : 1.526\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[16/50] training loss 0.501, training accuracy 5.000\n",
      "[val] acc : 0.868, loss : 1.553\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[17/50] training loss 0.483, training accuracy 5.333\n",
      "[val] acc : 0.884, loss : 1.534\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[18/50] training loss 0.502, training accuracy 5.000\n",
      "[val] acc : 0.880, loss : 1.536\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[19/50] training loss 0.516, training accuracy 4.667\n",
      "[val] acc : 0.888, loss : 1.529\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[20/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.887, loss : 1.531\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[21/50] training loss 0.475, training accuracy 5.333\n",
      "[val] acc : 0.896, loss : 1.522\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[22/50] training loss 0.477, training accuracy 5.333\n",
      "[val] acc : 0.888, loss : 1.525\n",
      "best acc : 0.899, best loss : 1.520\n",
      "epoch[23/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.907, loss : 1.513\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[24/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.904, loss : 1.514\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[25/50] training loss 0.478, training accuracy 5.333\n",
      "[val] acc : 0.901, loss : 1.516\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[26/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.901, loss : 1.517\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[27/50] training loss 0.482, training accuracy 5.333\n",
      "[val] acc : 0.888, loss : 1.526\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[28/50] training loss 0.474, training accuracy 5.333\n",
      "[val] acc : 0.890, loss : 1.524\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[29/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.892, loss : 1.523\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[30/50] training loss 0.476, training accuracy 5.333\n",
      "[val] acc : 0.893, loss : 1.522\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[31/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.893, loss : 1.526\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[32/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.899, loss : 1.517\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[33/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.899, loss : 1.515\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[34/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.899, loss : 1.515\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[35/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.900, loss : 1.515\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[36/50] training loss 0.475, training accuracy 5.333\n",
      "[val] acc : 0.899, loss : 1.518\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[37/50] training loss 0.474, training accuracy 5.333\n",
      "[val] acc : 0.900, loss : 1.516\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[38/50] training loss 0.476, training accuracy 5.333\n",
      "[val] acc : 0.903, loss : 1.515\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[39/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.902, loss : 1.514\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[40/50] training loss 0.516, training accuracy 5.000\n",
      "[val] acc : 0.892, loss : 1.523\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[41/50] training loss 0.473, training accuracy 5.333\n",
      "[val] acc : 0.880, loss : 1.535\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[42/50] training loss 0.473, training accuracy 5.333\n",
      "[val] acc : 0.892, loss : 1.523\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[43/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.899, loss : 1.520\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[44/50] training loss 0.493, training accuracy 5.000\n",
      "[val] acc : 0.892, loss : 1.523\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[45/50] training loss 0.473, training accuracy 5.333\n",
      "[val] acc : 0.893, loss : 1.523\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[46/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.895, loss : 1.520\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[47/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.898, loss : 1.520\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[48/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.896, loss : 1.522\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[49/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.897, loss : 1.519\n",
      "best acc : 0.907, best loss : 1.513\n",
      "epoch[50/50] training loss 0.472, training accuracy 5.333\n",
      "[val] acc : 0.893, loss : 1.522\n",
      "best acc : 0.907, best loss : 1.513\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "\n",
    "f1 = F1Score(num_classes = 18, average='macro', mdmc_reduce='samplewise').to(device)\n",
    "best_f1_score = 0\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    matches = 0\n",
    "    loss_value = 0\n",
    "    basemodel_resnet18.train()\n",
    "\n",
    "    # 학습 시작!\n",
    "    for inputs, labels in train_dataloader_mask:\n",
    "        inputs = inputs.to(device)\n",
    "        gen, age, msk = labels\n",
    "        gen = gen.to(device)\n",
    "        age = age.to(device)\n",
    "        msk = msk.to(device)\n",
    "        \n",
    "        p_gen, p_age, p_msk = basemodel_resnet18(inputs)\n",
    "        p_gen, p_age, p_msk = F.softmax(p_gen), F.softmax(p_age), F.softmax(p_msk)\n",
    "        loss = criterion(p_gen, gen) + criterion(p_age, age) + criterion(p_msk, msk)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # epoch 5마다 모델 저장\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            torch.save(basemodel_resnet18, '/opt/ml/checkpoint/resnet18_RHF_WRS/checkpoint_ep_{}.pt'.format(epoch+1))\n",
    "\n",
    "        loss_value = loss.item()\n",
    "        matches = ((torch.argmax(p_gen, -1) == gen) & (torch.argmax(p_age, -1) == age) & (torch.argmax(p_msk, -1) == msk)).sum().item()\n",
    "\n",
    "        train_loss = loss_value / len(labels)\n",
    "        train_acc = matches / len(labels)\n",
    "    print(f\"epoch[{epoch+1}/{NUM_EPOCH}] training loss {train_loss:.3f}, training accuracy {train_acc:.3f}\")        \n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        basemodel_resnet18.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        \n",
    "        for inputs, labels in val_dataloader_mask:\n",
    "            inputs = inputs.to(device)\n",
    "            gen, age, msk = labels\n",
    "            gen = gen.to(device)\n",
    "            age = age.to(device)\n",
    "            msk = msk.to(device)\n",
    "            \n",
    "            result = basemodel_resnet18(inputs)\n",
    "            p_gen, p_age, p_msk = result\n",
    "            p_gen, p_age, p_msk = F.softmax(p_gen), F.softmax(p_age), F.softmax(p_msk)\n",
    "            loss = criterion(p_gen, gen) + criterion(p_age, age) + criterion(p_msk, msk)\n",
    "            \n",
    "            loss_item = loss.item()\n",
    "            acc_item = ((torch.argmax(p_gen, -1) == gen) & (torch.argmax(p_age, -1) == age) & (torch.argmax(p_msk, -1) == msk)).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "            \n",
    "        val_loss = np.sum(val_loss_items) / len(val_dataloader_mask)\n",
    "        val_acc = np.sum(val_acc_items) / len(mask_val_set)\n",
    "        \n",
    "        pred_label = torch.vstack((torch.argmax(p_gen, -1), torch.argmax(p_age, -1), torch.argmax(p_gen, -1))).T\n",
    "        real_label = torch.vstack((gen, age, msk)).T\n",
    "        f1_score = f1(pred_label, real_label)\n",
    "            \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "        if f1_score > best_f1_score:\n",
    "            best_f1_score = f1_score\n",
    "            torch.save(basemodel_resnet18, '/opt/ml/checkpoint/resnet18_RHF_WRS/checkpoint_best.pt')\n",
    "        \n",
    "        print(f\"[val] acc : {val_acc:.3f}, loss : {val_loss:.3f}, f1 score: {f1_score:.3f}\")\n",
    "        print(f\"best acc : {best_val_acc:.3f}, best loss : {best_val_loss:.3f}, best f1 : {best_f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'Best f1 score:{best_f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ImageID  ans\n",
       "0  cbc5c6e168e63498590db46022617123f1fe1268.jpg    0\n",
       "1  0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    0\n",
       "2  b549040c49190cedc41327748aeb197c1670f14d.jpg    0\n",
       "3  4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    0\n",
       "4  248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir_path = '/opt/ml/input/data/eval/'\n",
    "test_image_path = '/opt/ml/input/data/eval/images/'\n",
    "\n",
    "#basemodel_resnet18 = torch.load('/opt/ml/checkpoint/resnet18/checkpoint_ep_30.pt')\n",
    "submission = pd.read_csv(test_dir_path+'info.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [os.path.join(test_image_path, img_id) for img_id in submission.ImageID]\n",
    "test_image = pd.Series(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Dataset(Dataset):\n",
    "    def __init__(self, midcrop=True, transform=None):\n",
    "        self.midcrop = midcrop\n",
    "        self.data = test_image\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(test_image)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.midcrop:\n",
    "            img = img[70:420, 17:367]\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Test_Dataset(transform = transforms.Compose([\n",
    "                            transforms.ToTensor()\n",
    "                        ]))\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = basemodel_resnet18.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        p_gen, p_age, p_msk = model(images)\n",
    "        \n",
    "        ar_gen = p_gen.argmax(dim=-1)\n",
    "        ar_age = p_age.argmax(dim=-1)\n",
    "        ar_msk = p_msk.argmax(dim=-1)\n",
    "        \n",
    "        total = ar_gen * 3 + ar_age + ar_msk * 6\n",
    "        \n",
    "        all_predictions.extend(total.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir_path, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.55555555555556"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과비교 (자체, 현재 제출된 것 중 가장 결과가 좋은 것과 비교)\n",
    "# 기준결과의 accuracy가 a%, 비교결과가 b%인 경우\n",
    "#  -> 현재 결과의 accuracy 범위 : a+b-100(%) ~ a-b+100(%)\n",
    "standard = pd.read_csv('~/cv-12/log/standard_1028.csv')['ans']\n",
    "100 * sum(standard == submission['ans']) / len(standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffae1fce5e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test set과의 분포 비교\n",
    "\n",
    "ax11 = plt.subplot(121)\n",
    "ax22 = plt.subplot(122)\n",
    "\n",
    "# 왼쪽 : 평가데이터 결과  /  오른쪽 : 훈련데이터 일부 결과\n",
    "test_Series = submission['ans'].value_counts().sort_index()\n",
    "test_Series.plot(kind = 'bar', ax = ax11)\n",
    "t_Series.plot(kind='bar', ax = ax22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)      538\n",
       "(2, 1)      170\n",
       "(7, 8)      109\n",
       "(13, 14)    101\n",
       "(5, 4)       89\n",
       "(3, 4)       56\n",
       "(4, 5)       52\n",
       "(14, 13)     51\n",
       "(4, 1)       45\n",
       "(0, 1)       45\n",
       "(0, 2)       44\n",
       "(1, 4)       40\n",
       "(3, 0)       37\n",
       "(1, 0)       36\n",
       "(8, 7)       33\n",
       "(16, 17)     30\n",
       "(2, 5)       25\n",
       "(15, 16)     22\n",
       "(0, 4)       20\n",
       "(4, 3)       19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard = pd.read_csv('~/cv-12/log/standard_1028.csv')\n",
    "submission = pd.read_csv('~/input/data/eval/submission.csv')\n",
    "\n",
    "False_idx = (standard['ans'] == submission['ans']) == False\n",
    "pd.Series(list(zip(submission[False_idx]['ans'], standard[False_idx]['ans']))).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18797 18545 18882\n"
     ]
    }
   ],
   "source": [
    "# (자체) 각 class별로 정답개수 확인\n",
    "g_sum = 0\n",
    "a_sum = 0\n",
    "m_sum = 0\n",
    "device = torch.device('cuda')\n",
    "model = basemodel_resnet18.to(device)\n",
    "model.eval()\n",
    "\n",
    "for i in range(len(mask_train_set)):\n",
    "    image, label = mask_train_set[i]\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    \n",
    "    result = model(image)\n",
    "    if torch.argmax(result[0]) == label[0]:\n",
    "        g_sum += 1\n",
    "    if torch.argmax(result[1]) == label[1]:\n",
    "        a_sum += 1\n",
    "    if torch.argmax(result[2]) == label[2]:\n",
    "        m_sum += 1\n",
    "        \n",
    "        \n",
    "for i in range(len(mask_val_set)):\n",
    "    image, label = mask_val_set[i]\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    \n",
    "    result = model(image)\n",
    "    if torch.argmax(result[0]) == label[0]:\n",
    "        g_sum += 1\n",
    "    if torch.argmax(result[1]) == label[1]:\n",
    "        a_sum += 1\n",
    "    if torch.argmax(result[2]) == label[2]:\n",
    "        m_sum += 1\n",
    "        \n",
    "\n",
    "print(g_sum, a_sum , m_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Level1_PJ",
   "language": "python",
   "name": "aistage1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
