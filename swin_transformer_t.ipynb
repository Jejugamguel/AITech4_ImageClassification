{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1531288b-3caa-4cb1-b15c-7334747a5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69bc6ad5-8c6e-47b0-b625-46f66dc71d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b1d65a3-78de-4b01-a862-e6bd4c7ef135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d15beaba-39cc-48da-8165-9f2abc16322a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/ml/input/data'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('input/data')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b3beb99-f9c7-4026-989a-cbaa8de1f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -regex \".*\\.\\_[a-zA-Z0-9._]+\" -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa8d19de-5a8e-454f-a22b-129e94792395",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 12\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f69f93c-5675-433f-8a88-7bf8e411d51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>006954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>006955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>006956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>006957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                    path\n",
       "0     000001  female  Asian   45  000001_female_Asian_45\n",
       "1     000002  female  Asian   52  000002_female_Asian_52\n",
       "2     000004    male  Asian   54    000004_male_Asian_54\n",
       "3     000005  female  Asian   58  000005_female_Asian_58\n",
       "4     000006  female  Asian   59  000006_female_Asian_59\n",
       "...      ...     ...    ...  ...                     ...\n",
       "2695  006954    male  Asian   19    006954_male_Asian_19\n",
       "2696  006955    male  Asian   19    006955_male_Asian_19\n",
       "2697  006956    male  Asian   19    006956_male_Asian_19\n",
       "2698  006957    male  Asian   20    006957_male_Asian_20\n",
       "2699  006959    male  Asian   19    006959_male_Asian_19\n",
       "\n",
       "[2700 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir_path = '/opt/ml/input/data/train/'\n",
    "train_image_path = '/opt/ml/input/data/train/images/'\n",
    "\n",
    "dt_train = pd.read_csv(train_dir_path+'train.csv')\n",
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "304c6a61-ff17-4777-8132-18def61c8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_image_path = []\n",
    "whole_target_label = []\n",
    "\n",
    "for path in dt_train['path']:\n",
    "    for file_name in [i for i in os.listdir(train_image_path+path) if './' not in i]:\n",
    "        whole_image_path.append(train_image_path+path+'/'+file_name)\n",
    "        whole_target_label.append((path.split('_')[1], path.split('_')[3], file_name.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98de1eb4-55d4-41ba-8541-70fff9bb011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_enc(x):\n",
    "    def gender(i):\n",
    "        if i == 'male':\n",
    "            return 0\n",
    "        elif i == 'female':\n",
    "            return 3\n",
    "    def age(j):\n",
    "        j = int(j)\n",
    "        if j < 30:\n",
    "            return 0\n",
    "        elif j >= 30 and j < 60:\n",
    "            return 1\n",
    "        elif j >= 60:\n",
    "            return 2\n",
    "    def mask(k):\n",
    "        if k == 'normal':\n",
    "            return 12\n",
    "        elif 'incorrect' in k:\n",
    "            return 6\n",
    "        else:\n",
    "            return 0\n",
    "    return gender(x[0]) + age(x[1]) + mask(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "694474c7-7175-40e6-b071-e50218629f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_data = pd.Series(whole_image_path)\n",
    "sr_label = pd.Series(whole_target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2cd7b29-5f03-444e-b781-902ca74f2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Mask(Dataset):\n",
    "    def __init__(self, encoding=True, midcrop=True, transform=None):\n",
    "        self.encoding = encoding\n",
    "        self.midcrop = midcrop\n",
    "        self.data = sr_data\n",
    "        self.label = sr_label\n",
    "        self.transform = transform\n",
    "        \n",
    "        if encoding:\n",
    "            self.label = self.label.apply(onehot_enc)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(sr_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        y = self.label[idx]\n",
    "        \n",
    "        if self.midcrop:\n",
    "            X = X[64:448]\n",
    "        \n",
    "        if self.transform:\n",
    "            return self.transform(X), y\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2a22aff-e634-4f15-877c-752d450d01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mask = Dataset_Mask(transform = transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.Resize(224),\n",
    "                                transforms.ToTensor()\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5788c44b-07ac-4820-a22d-b6ffa3fc81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset_mask) * 0.8)\n",
    "val_size = int(len(dataset_mask) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e285cb6-ee37-4a0c-a804-7506dcfebc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size : 15120\n",
      "validation data size : 3780\n"
     ]
    }
   ],
   "source": [
    "mask_train_set, mask_val_set = torch.utils.data.random_split(dataset_mask, [train_size, val_size])\n",
    "print(f'training data size : {len(mask_train_set)}')\n",
    "print(f'validation data size : {len(mask_val_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37b1ced0-1e34-4d50-b2b2-dcdff8fd33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dataloader_mask = DataLoader(dataset = mask_train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_dataloader_mask = DataLoader(dataset = mask_val_set, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af71a4ef-a137-47b0-af94-eebedaa36014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /opt/ml/.cache/torch/hub/SharanSMenon_swin-transformer-hub_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): BasicLayer(\n",
       "      dim=96, input_resolution=(56, 56), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=96, window_size=(7, 7), num_heads=3\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=96, window_size=(7, 7), num_heads=3\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.009)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(56, 56), dim=96\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicLayer(\n",
       "      dim=192, input_resolution=(28, 28), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=192, window_size=(7, 7), num_heads=6\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.018)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=3, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=192, window_size=(7, 7), num_heads=6\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.027)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(28, 28), dim=192\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicLayer(\n",
       "      dim=384, input_resolution=(14, 14), depth=6\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.036)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.045)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.055)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.064)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.073)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=384, window_size=(7, 7), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.082)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(14, 14), dim=384\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): BasicLayer(\n",
       "      dim=768, input_resolution=(7, 7), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=768, window_size=(7, 7), num_heads=24\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            dim=768, window_size=(7, 7), num_heads=24\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.100)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\n",
    "MODEL_NAME = \"swin_tiny_patch4_window7_224\"\n",
    "# check hubconf for more models.\n",
    "model = torch.hub.load(HUB_URL, MODEL_NAME, pretrained=True) # load from torch hub\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66973573-70e8-42e3-ba82-18bf0ab50300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=512, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "n_inputs = model.head.in_features\n",
    "model.head = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 18)\n",
    ")\n",
    "print(model.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92ecee80-caaa-4cbe-ab28-16d16771d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "initialize_weights(model.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "325c7b2e-8f76-468c-8547-1a3d7924c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /opt/conda/lib/python3.8/site-packages (0.6.11)\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.8/site-packages (from timm) (1.7.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from timm) (5.3.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm) (0.8.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.8/site-packages (from timm) (0.10.1)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch>=1.7->timm) (1.19.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (8.1.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (21.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (3.0.12)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (4.51.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->timm) (2.24.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub->timm) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (2022.9.24)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1a2262-f820-4294-8086-3a48a5e5d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCH = 100\n",
    "\n",
    "criterion = LabelSmoothingCrossEntropy()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c067d0e-38c9-4ab8-baba-88cf8dcb8c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0/100] training loss 0.01128, training accuracy 0.04688\n",
      "epoch[0/100] training loss 0.01098, training accuracy 0.26172\n",
      "epoch[0/100] training loss 0.01053, training accuracy 0.21875\n",
      "epoch[0/100] training loss 0.00988, training accuracy 0.24219\n",
      "epoch[0/100] training loss 0.00978, training accuracy 0.17969\n",
      "epoch[0/100] training loss 0.00932, training accuracy 0.24219\n",
      "epoch[0/100] training loss 0.00914, training accuracy 0.25781\n",
      "epoch[0/100] training loss 0.00916, training accuracy 0.30078\n",
      "epoch[0/100] training loss 0.00962, training accuracy 0.32422\n",
      "epoch[0/100] training loss 0.00892, training accuracy 0.23828\n",
      "epoch[0/100] training loss 0.00923, training accuracy 0.23047\n",
      "epoch[0/100] training loss 0.00904, training accuracy 0.20312\n",
      "epoch[0/100] training loss 0.00812, training accuracy 0.40234\n",
      "epoch[0/100] training loss 0.00860, training accuracy 0.32031\n",
      "epoch[0/100] training loss 0.00838, training accuracy 0.43750\n",
      "epoch[0/100] training loss 0.00842, training accuracy 0.39844\n",
      "epoch[0/100] training loss 0.00823, training accuracy 0.35156\n",
      "epoch[0/100] training loss 0.00810, training accuracy 0.37109\n",
      "epoch[0/100] training loss 0.00800, training accuracy 0.39844\n",
      "epoch[0/100] training loss 0.00795, training accuracy 0.45703\n",
      "epoch[0/100] training loss 0.00780, training accuracy 0.43750\n",
      "epoch[0/100] training loss 0.00786, training accuracy 0.43359\n",
      "epoch[0/100] training loss 0.00776, training accuracy 0.45703\n",
      "epoch[0/100] training loss 0.00765, training accuracy 0.50391\n",
      "epoch[0/100] training loss 0.00741, training accuracy 0.54688\n",
      "epoch[0/100] training loss 0.00721, training accuracy 0.55469\n",
      "epoch[0/100] training loss 0.00779, training accuracy 0.46484\n",
      "epoch[0/100] training loss 0.00703, training accuracy 0.53125\n",
      "epoch[0/100] training loss 0.00726, training accuracy 0.51562\n",
      "epoch[0/100] training loss 0.00703, training accuracy 0.56641\n",
      "epoch[0/100] training loss 0.00704, training accuracy 0.55469\n",
      "epoch[0/100] training loss 0.00690, training accuracy 0.57031\n",
      "epoch[0/100] training loss 0.00715, training accuracy 0.50781\n",
      "epoch[0/100] training loss 0.00683, training accuracy 0.56250\n",
      "epoch[0/100] training loss 0.00703, training accuracy 0.52734\n",
      "epoch[0/100] training loss 0.00665, training accuracy 0.58984\n",
      "epoch[0/100] training loss 0.00667, training accuracy 0.55078\n",
      "epoch[0/100] training loss 0.00647, training accuracy 0.62500\n",
      "epoch[0/100] training loss 0.00658, training accuracy 0.55859\n",
      "epoch[0/100] training loss 0.00686, training accuracy 0.55859\n",
      "epoch[0/100] training loss 0.00656, training accuracy 0.57422\n",
      "epoch[0/100] training loss 0.00632, training accuracy 0.59375\n",
      "epoch[0/100] training loss 0.00674, training accuracy 0.54688\n",
      "epoch[0/100] training loss 0.00653, training accuracy 0.55078\n",
      "epoch[0/100] training loss 0.00577, training accuracy 0.66406\n",
      "epoch[0/100] training loss 0.00631, training accuracy 0.57031\n",
      "epoch[0/100] training loss 0.00604, training accuracy 0.62500\n",
      "epoch[0/100] training loss 0.00588, training accuracy 0.62891\n",
      "epoch[0/100] training loss 0.00621, training accuracy 0.59766\n",
      "epoch[0/100] training loss 0.00592, training accuracy 0.63672\n",
      "epoch[0/100] training loss 0.00595, training accuracy 0.64844\n",
      "epoch[0/100] training loss 0.00613, training accuracy 0.59375\n",
      "epoch[0/100] training loss 0.00592, training accuracy 0.62500\n",
      "epoch[0/100] training loss 0.00557, training accuracy 0.67578\n",
      "epoch[0/100] training loss 0.00570, training accuracy 0.62891\n",
      "epoch[0/100] training loss 0.00592, training accuracy 0.62500\n",
      "epoch[0/100] training loss 0.00586, training accuracy 0.64453\n",
      "epoch[0/100] training loss 0.00555, training accuracy 0.71094\n",
      "epoch[0/100] training loss 0.00560, training accuracy 0.66406\n",
      "epoch[0/100] training loss 0.00428, training accuracy 0.06250\n",
      "[val] acc : 0.67434, loss : 1.41428\n",
      "best acc : 0.67434, best loss : 1.41428\n",
      "epoch[1/100] training loss 0.00567, training accuracy 0.66406\n",
      "epoch[1/100] training loss 0.00567, training accuracy 0.64062\n",
      "epoch[1/100] training loss 0.00554, training accuracy 0.65625\n",
      "epoch[1/100] training loss 0.00536, training accuracy 0.69531\n",
      "epoch[1/100] training loss 0.00498, training accuracy 0.78516\n",
      "epoch[1/100] training loss 0.00562, training accuracy 0.63672\n",
      "epoch[1/100] training loss 0.00576, training accuracy 0.63281\n",
      "epoch[1/100] training loss 0.00562, training accuracy 0.67188\n",
      "epoch[1/100] training loss 0.00567, training accuracy 0.68750\n",
      "epoch[1/100] training loss 0.00549, training accuracy 0.70312\n",
      "epoch[1/100] training loss 0.00545, training accuracy 0.68359\n",
      "epoch[1/100] training loss 0.00585, training accuracy 0.66406\n",
      "epoch[1/100] training loss 0.00536, training accuracy 0.72656\n",
      "epoch[1/100] training loss 0.00544, training accuracy 0.70312\n",
      "epoch[1/100] training loss 0.00533, training accuracy 0.71094\n",
      "epoch[1/100] training loss 0.00542, training accuracy 0.70703\n",
      "epoch[1/100] training loss 0.00533, training accuracy 0.71875\n",
      "epoch[1/100] training loss 0.00555, training accuracy 0.66797\n",
      "epoch[1/100] training loss 0.00550, training accuracy 0.64844\n",
      "epoch[1/100] training loss 0.00555, training accuracy 0.66016\n",
      "epoch[1/100] training loss 0.00524, training accuracy 0.71484\n",
      "epoch[1/100] training loss 0.00528, training accuracy 0.69922\n",
      "epoch[1/100] training loss 0.00534, training accuracy 0.70703\n",
      "epoch[1/100] training loss 0.00518, training accuracy 0.72266\n",
      "epoch[1/100] training loss 0.00519, training accuracy 0.73828\n",
      "epoch[1/100] training loss 0.00512, training accuracy 0.75781\n",
      "epoch[1/100] training loss 0.00523, training accuracy 0.70312\n",
      "epoch[1/100] training loss 0.00503, training accuracy 0.75000\n",
      "epoch[1/100] training loss 0.00485, training accuracy 0.77344\n",
      "epoch[1/100] training loss 0.00515, training accuracy 0.70312\n",
      "epoch[1/100] training loss 0.00514, training accuracy 0.73438\n",
      "epoch[1/100] training loss 0.00501, training accuracy 0.73047\n",
      "epoch[1/100] training loss 0.00518, training accuracy 0.69141\n",
      "epoch[1/100] training loss 0.00506, training accuracy 0.73047\n",
      "epoch[1/100] training loss 0.00506, training accuracy 0.73438\n",
      "epoch[1/100] training loss 0.00510, training accuracy 0.75000\n",
      "epoch[1/100] training loss 0.00511, training accuracy 0.72656\n",
      "epoch[1/100] training loss 0.00508, training accuracy 0.74219\n",
      "epoch[1/100] training loss 0.00519, training accuracy 0.75391\n",
      "epoch[1/100] training loss 0.00482, training accuracy 0.77734\n",
      "epoch[1/100] training loss 0.00511, training accuracy 0.75391\n",
      "epoch[1/100] training loss 0.00496, training accuracy 0.75000\n",
      "epoch[1/100] training loss 0.00509, training accuracy 0.71484\n",
      "epoch[1/100] training loss 0.00513, training accuracy 0.73438\n",
      "epoch[1/100] training loss 0.00493, training accuracy 0.71094\n",
      "epoch[1/100] training loss 0.00506, training accuracy 0.76953\n",
      "epoch[1/100] training loss 0.00486, training accuracy 0.74219\n",
      "epoch[1/100] training loss 0.00476, training accuracy 0.78906\n",
      "epoch[1/100] training loss 0.00501, training accuracy 0.73047\n",
      "epoch[1/100] training loss 0.00514, training accuracy 0.72656\n",
      "epoch[1/100] training loss 0.00500, training accuracy 0.76172\n",
      "epoch[1/100] training loss 0.00507, training accuracy 0.75000\n",
      "epoch[1/100] training loss 0.00500, training accuracy 0.71484\n",
      "epoch[1/100] training loss 0.00503, training accuracy 0.72266\n",
      "epoch[1/100] training loss 0.00500, training accuracy 0.73828\n",
      "epoch[1/100] training loss 0.00493, training accuracy 0.73047\n",
      "epoch[1/100] training loss 0.00471, training accuracy 0.76172\n",
      "epoch[1/100] training loss 0.00490, training accuracy 0.75781\n",
      "epoch[1/100] training loss 0.00503, training accuracy 0.73047\n",
      "epoch[1/100] training loss 0.00462, training accuracy 0.05078\n",
      "[val] acc : 0.76534, loss : 1.22234\n",
      "best acc : 0.76534, best loss : 1.22234\n",
      "epoch[2/100] training loss 0.00489, training accuracy 0.71484\n",
      "epoch[2/100] training loss 0.00491, training accuracy 0.72656\n",
      "epoch[2/100] training loss 0.00513, training accuracy 0.69922\n",
      "epoch[2/100] training loss 0.00487, training accuracy 0.76172\n",
      "epoch[2/100] training loss 0.00531, training accuracy 0.70703\n",
      "epoch[2/100] training loss 0.00490, training accuracy 0.75781\n",
      "epoch[2/100] training loss 0.00470, training accuracy 0.78906\n",
      "epoch[2/100] training loss 0.00493, training accuracy 0.76953\n",
      "epoch[2/100] training loss 0.00487, training accuracy 0.75391\n",
      "epoch[2/100] training loss 0.00505, training accuracy 0.75781\n",
      "epoch[2/100] training loss 0.00473, training accuracy 0.77734\n",
      "epoch[2/100] training loss 0.00451, training accuracy 0.82812\n",
      "epoch[2/100] training loss 0.00473, training accuracy 0.78125\n",
      "epoch[2/100] training loss 0.00457, training accuracy 0.79297\n",
      "epoch[2/100] training loss 0.00485, training accuracy 0.78516\n",
      "epoch[2/100] training loss 0.00523, training accuracy 0.69922\n",
      "epoch[2/100] training loss 0.00493, training accuracy 0.74219\n",
      "epoch[2/100] training loss 0.00485, training accuracy 0.75000\n",
      "epoch[2/100] training loss 0.00485, training accuracy 0.77344\n",
      "epoch[2/100] training loss 0.00449, training accuracy 0.80078\n",
      "epoch[2/100] training loss 0.00472, training accuracy 0.78906\n",
      "epoch[2/100] training loss 0.00498, training accuracy 0.73828\n",
      "epoch[2/100] training loss 0.00460, training accuracy 0.78125\n",
      "epoch[2/100] training loss 0.00464, training accuracy 0.79297\n",
      "epoch[2/100] training loss 0.00494, training accuracy 0.73438\n",
      "epoch[2/100] training loss 0.00482, training accuracy 0.75000\n",
      "epoch[2/100] training loss 0.00481, training accuracy 0.77734\n",
      "epoch[2/100] training loss 0.00500, training accuracy 0.76172\n",
      "epoch[2/100] training loss 0.00471, training accuracy 0.77344\n",
      "epoch[2/100] training loss 0.00464, training accuracy 0.78516\n",
      "epoch[2/100] training loss 0.00482, training accuracy 0.73828\n",
      "epoch[2/100] training loss 0.00488, training accuracy 0.71875\n",
      "epoch[2/100] training loss 0.00469, training accuracy 0.76953\n",
      "epoch[2/100] training loss 0.00468, training accuracy 0.80078\n",
      "epoch[2/100] training loss 0.00488, training accuracy 0.77344\n",
      "epoch[2/100] training loss 0.00450, training accuracy 0.79297\n",
      "epoch[2/100] training loss 0.00475, training accuracy 0.76172\n",
      "epoch[2/100] training loss 0.00469, training accuracy 0.76562\n",
      "epoch[2/100] training loss 0.00457, training accuracy 0.77734\n",
      "epoch[2/100] training loss 0.00450, training accuracy 0.81641\n",
      "epoch[2/100] training loss 0.00446, training accuracy 0.78906\n",
      "epoch[2/100] training loss 0.00461, training accuracy 0.77734\n",
      "epoch[2/100] training loss 0.00474, training accuracy 0.76172\n",
      "epoch[2/100] training loss 0.00470, training accuracy 0.75781\n",
      "epoch[2/100] training loss 0.00452, training accuracy 0.79688\n",
      "epoch[2/100] training loss 0.00457, training accuracy 0.77734\n",
      "epoch[2/100] training loss 0.00460, training accuracy 0.77344\n",
      "epoch[2/100] training loss 0.00444, training accuracy 0.81641\n",
      "epoch[2/100] training loss 0.00449, training accuracy 0.79688\n",
      "epoch[2/100] training loss 0.00463, training accuracy 0.79688\n",
      "epoch[2/100] training loss 0.00444, training accuracy 0.80469\n",
      "epoch[2/100] training loss 0.00446, training accuracy 0.79688\n",
      "epoch[2/100] training loss 0.00435, training accuracy 0.79297\n",
      "epoch[2/100] training loss 0.00452, training accuracy 0.79688\n",
      "epoch[2/100] training loss 0.00444, training accuracy 0.82031\n",
      "epoch[2/100] training loss 0.00459, training accuracy 0.78906\n",
      "epoch[2/100] training loss 0.00455, training accuracy 0.77344\n",
      "epoch[2/100] training loss 0.00467, training accuracy 0.77344\n",
      "epoch[2/100] training loss 0.00466, training accuracy 0.76562\n",
      "epoch[2/100] training loss 0.00420, training accuracy 0.05469\n",
      "[val] acc : 0.79471, loss : 1.13885\n",
      "best acc : 0.79471, best loss : 1.13885\n",
      "epoch[3/100] training loss 0.00461, training accuracy 0.77734\n",
      "epoch[3/100] training loss 0.00448, training accuracy 0.76953\n",
      "epoch[3/100] training loss 0.00461, training accuracy 0.80078\n",
      "epoch[3/100] training loss 0.00479, training accuracy 0.76953\n",
      "epoch[3/100] training loss 0.00451, training accuracy 0.78906\n",
      "epoch[3/100] training loss 0.00443, training accuracy 0.79297\n",
      "epoch[3/100] training loss 0.00447, training accuracy 0.79688\n",
      "epoch[3/100] training loss 0.00456, training accuracy 0.78125\n",
      "epoch[3/100] training loss 0.00440, training accuracy 0.79297\n",
      "epoch[3/100] training loss 0.00458, training accuracy 0.80078\n",
      "epoch[3/100] training loss 0.00466, training accuracy 0.76953\n",
      "epoch[3/100] training loss 0.00442, training accuracy 0.80469\n",
      "epoch[3/100] training loss 0.00451, training accuracy 0.78516\n",
      "epoch[3/100] training loss 0.00472, training accuracy 0.77734\n",
      "epoch[3/100] training loss 0.00441, training accuracy 0.82422\n",
      "epoch[3/100] training loss 0.00465, training accuracy 0.75781\n",
      "epoch[3/100] training loss 0.00450, training accuracy 0.79688\n",
      "epoch[3/100] training loss 0.00467, training accuracy 0.74609\n",
      "epoch[3/100] training loss 0.00442, training accuracy 0.80078\n",
      "epoch[3/100] training loss 0.00462, training accuracy 0.75781\n",
      "epoch[3/100] training loss 0.00450, training accuracy 0.77344\n",
      "epoch[3/100] training loss 0.00424, training accuracy 0.83203\n",
      "epoch[3/100] training loss 0.00428, training accuracy 0.82031\n",
      "epoch[3/100] training loss 0.00440, training accuracy 0.81250\n",
      "epoch[3/100] training loss 0.00462, training accuracy 0.76562\n",
      "epoch[3/100] training loss 0.00454, training accuracy 0.78906\n",
      "epoch[3/100] training loss 0.00455, training accuracy 0.78906\n",
      "epoch[3/100] training loss 0.00453, training accuracy 0.80078\n",
      "epoch[3/100] training loss 0.00452, training accuracy 0.81250\n",
      "epoch[3/100] training loss 0.00418, training accuracy 0.82812\n",
      "epoch[3/100] training loss 0.00455, training accuracy 0.76953\n",
      "epoch[3/100] training loss 0.00418, training accuracy 0.83203\n",
      "epoch[3/100] training loss 0.00451, training accuracy 0.80078\n",
      "epoch[3/100] training loss 0.00482, training accuracy 0.72266\n",
      "epoch[3/100] training loss 0.00427, training accuracy 0.83203\n",
      "epoch[3/100] training loss 0.00415, training accuracy 0.83984\n",
      "epoch[3/100] training loss 0.00446, training accuracy 0.82031\n",
      "epoch[3/100] training loss 0.00423, training accuracy 0.83203\n",
      "epoch[3/100] training loss 0.00411, training accuracy 0.85156\n",
      "epoch[3/100] training loss 0.00416, training accuracy 0.82031\n",
      "epoch[3/100] training loss 0.00453, training accuracy 0.76562\n",
      "epoch[3/100] training loss 0.00450, training accuracy 0.79688\n",
      "epoch[3/100] training loss 0.00475, training accuracy 0.75391\n",
      "epoch[3/100] training loss 0.00449, training accuracy 0.78906\n",
      "epoch[3/100] training loss 0.00442, training accuracy 0.80469\n",
      "epoch[3/100] training loss 0.00468, training accuracy 0.76953\n",
      "epoch[3/100] training loss 0.00422, training accuracy 0.82422\n",
      "epoch[3/100] training loss 0.00430, training accuracy 0.82422\n",
      "epoch[3/100] training loss 0.00430, training accuracy 0.82422\n",
      "epoch[3/100] training loss 0.00432, training accuracy 0.79297\n",
      "epoch[3/100] training loss 0.00433, training accuracy 0.82812\n",
      "epoch[3/100] training loss 0.00469, training accuracy 0.73438\n",
      "epoch[3/100] training loss 0.00426, training accuracy 0.80859\n",
      "epoch[3/100] training loss 0.00456, training accuracy 0.76172\n",
      "epoch[3/100] training loss 0.00415, training accuracy 0.83984\n",
      "epoch[3/100] training loss 0.00434, training accuracy 0.80078\n",
      "epoch[3/100] training loss 0.00453, training accuracy 0.79688\n",
      "epoch[3/100] training loss 0.00429, training accuracy 0.82031\n",
      "epoch[3/100] training loss 0.00464, training accuracy 0.77344\n",
      "epoch[3/100] training loss 0.00477, training accuracy 0.04688\n",
      "[val] acc : 0.81508, loss : 1.09440\n",
      "best acc : 0.81508, best loss : 1.09440\n",
      "epoch[4/100] training loss 0.00414, training accuracy 0.84375\n",
      "epoch[4/100] training loss 0.00452, training accuracy 0.78516\n",
      "epoch[4/100] training loss 0.00429, training accuracy 0.80859\n",
      "epoch[4/100] training loss 0.00470, training accuracy 0.73438\n",
      "epoch[4/100] training loss 0.00440, training accuracy 0.83594\n",
      "epoch[4/100] training loss 0.00426, training accuracy 0.81641\n",
      "epoch[4/100] training loss 0.00429, training accuracy 0.84766\n",
      "epoch[4/100] training loss 0.00404, training accuracy 0.84766\n",
      "epoch[4/100] training loss 0.00435, training accuracy 0.80469\n",
      "epoch[4/100] training loss 0.00461, training accuracy 0.78125\n",
      "epoch[4/100] training loss 0.00429, training accuracy 0.81641\n",
      "epoch[4/100] training loss 0.00476, training accuracy 0.75781\n",
      "epoch[4/100] training loss 0.00429, training accuracy 0.83984\n",
      "epoch[4/100] training loss 0.00429, training accuracy 0.81250\n",
      "epoch[4/100] training loss 0.00448, training accuracy 0.77734\n",
      "epoch[4/100] training loss 0.00444, training accuracy 0.78125\n",
      "epoch[4/100] training loss 0.00430, training accuracy 0.80469\n",
      "epoch[4/100] training loss 0.00433, training accuracy 0.80859\n",
      "epoch[4/100] training loss 0.00407, training accuracy 0.85938\n",
      "epoch[4/100] training loss 0.00439, training accuracy 0.81641\n",
      "epoch[4/100] training loss 0.00437, training accuracy 0.82031\n",
      "epoch[4/100] training loss 0.00410, training accuracy 0.84766\n",
      "epoch[4/100] training loss 0.00440, training accuracy 0.80469\n",
      "epoch[4/100] training loss 0.00431, training accuracy 0.78516\n",
      "epoch[4/100] training loss 0.00447, training accuracy 0.79688\n",
      "epoch[4/100] training loss 0.00457, training accuracy 0.77344\n",
      "epoch[4/100] training loss 0.00423, training accuracy 0.80469\n",
      "epoch[4/100] training loss 0.00438, training accuracy 0.82031\n",
      "epoch[4/100] training loss 0.00425, training accuracy 0.83594\n",
      "epoch[4/100] training loss 0.00425, training accuracy 0.82812\n",
      "epoch[4/100] training loss 0.00410, training accuracy 0.85547\n",
      "epoch[4/100] training loss 0.00455, training accuracy 0.76562\n",
      "epoch[4/100] training loss 0.00435, training accuracy 0.82031\n",
      "epoch[4/100] training loss 0.00428, training accuracy 0.81250\n",
      "epoch[4/100] training loss 0.00422, training accuracy 0.85938\n",
      "epoch[4/100] training loss 0.00453, training accuracy 0.78516\n",
      "epoch[4/100] training loss 0.00424, training accuracy 0.82422\n",
      "epoch[4/100] training loss 0.00423, training accuracy 0.82422\n",
      "epoch[4/100] training loss 0.00419, training accuracy 0.83594\n",
      "epoch[4/100] training loss 0.00424, training accuracy 0.80469\n",
      "epoch[4/100] training loss 0.00419, training accuracy 0.80859\n",
      "epoch[4/100] training loss 0.00433, training accuracy 0.78516\n",
      "epoch[4/100] training loss 0.00417, training accuracy 0.81641\n",
      "epoch[4/100] training loss 0.00424, training accuracy 0.82031\n",
      "epoch[4/100] training loss 0.00430, training accuracy 0.80859\n",
      "epoch[4/100] training loss 0.00411, training accuracy 0.83984\n",
      "epoch[4/100] training loss 0.00441, training accuracy 0.80859\n",
      "epoch[4/100] training loss 0.00405, training accuracy 0.85938\n",
      "epoch[4/100] training loss 0.00425, training accuracy 0.83594\n",
      "epoch[4/100] training loss 0.00408, training accuracy 0.84375\n",
      "epoch[4/100] training loss 0.00417, training accuracy 0.80078\n",
      "epoch[4/100] training loss 0.00425, training accuracy 0.80469\n",
      "epoch[4/100] training loss 0.00421, training accuracy 0.83984\n",
      "epoch[4/100] training loss 0.00414, training accuracy 0.84375\n",
      "epoch[4/100] training loss 0.00397, training accuracy 0.83594\n",
      "epoch[4/100] training loss 0.00435, training accuracy 0.78516\n",
      "epoch[4/100] training loss 0.00420, training accuracy 0.83984\n",
      "epoch[4/100] training loss 0.00417, training accuracy 0.80078\n",
      "epoch[4/100] training loss 0.00438, training accuracy 0.81250\n",
      "epoch[4/100] training loss 0.00445, training accuracy 0.04688\n",
      "[val] acc : 0.83122, loss : 1.05280\n",
      "best acc : 0.83122, best loss : 1.05280\n",
      "epoch[5/100] training loss 0.00441, training accuracy 0.81641\n",
      "epoch[5/100] training loss 0.00441, training accuracy 0.79688\n",
      "epoch[5/100] training loss 0.00433, training accuracy 0.78906\n",
      "epoch[5/100] training loss 0.00437, training accuracy 0.80078\n",
      "epoch[5/100] training loss 0.00414, training accuracy 0.85938\n",
      "epoch[5/100] training loss 0.00425, training accuracy 0.81250\n",
      "epoch[5/100] training loss 0.00436, training accuracy 0.75781\n",
      "epoch[5/100] training loss 0.00410, training accuracy 0.84766\n",
      "epoch[5/100] training loss 0.00407, training accuracy 0.82031\n",
      "epoch[5/100] training loss 0.00447, training accuracy 0.79297\n",
      "epoch[5/100] training loss 0.00417, training accuracy 0.85156\n",
      "epoch[5/100] training loss 0.00425, training accuracy 0.83203\n",
      "epoch[5/100] training loss 0.00426, training accuracy 0.81250\n",
      "epoch[5/100] training loss 0.00429, training accuracy 0.80859\n",
      "epoch[5/100] training loss 0.00407, training accuracy 0.85156\n",
      "epoch[5/100] training loss 0.00430, training accuracy 0.82031\n",
      "epoch[5/100] training loss 0.00405, training accuracy 0.85156\n",
      "epoch[5/100] training loss 0.00422, training accuracy 0.81641\n",
      "epoch[5/100] training loss 0.00396, training accuracy 0.84766\n",
      "epoch[5/100] training loss 0.00420, training accuracy 0.83594\n",
      "epoch[5/100] training loss 0.00414, training accuracy 0.83984\n",
      "epoch[5/100] training loss 0.00400, training accuracy 0.87500\n",
      "epoch[5/100] training loss 0.00407, training accuracy 0.87109\n",
      "epoch[5/100] training loss 0.00419, training accuracy 0.80859\n",
      "epoch[5/100] training loss 0.00403, training accuracy 0.84766\n",
      "epoch[5/100] training loss 0.00424, training accuracy 0.80859\n",
      "epoch[5/100] training loss 0.00396, training accuracy 0.86719\n",
      "epoch[5/100] training loss 0.00430, training accuracy 0.80859\n",
      "epoch[5/100] training loss 0.00420, training accuracy 0.80078\n",
      "epoch[5/100] training loss 0.00423, training accuracy 0.79688\n",
      "epoch[5/100] training loss 0.00446, training accuracy 0.75781\n",
      "epoch[5/100] training loss 0.00415, training accuracy 0.81641\n",
      "epoch[5/100] training loss 0.00412, training accuracy 0.81641\n",
      "epoch[5/100] training loss 0.00426, training accuracy 0.82031\n",
      "epoch[5/100] training loss 0.00431, training accuracy 0.81641\n",
      "epoch[5/100] training loss 0.00402, training accuracy 0.86719\n",
      "epoch[5/100] training loss 0.00398, training accuracy 0.86328\n",
      "epoch[5/100] training loss 0.00410, training accuracy 0.81641\n",
      "epoch[5/100] training loss 0.00422, training accuracy 0.80859\n",
      "epoch[5/100] training loss 0.00408, training accuracy 0.85156\n",
      "epoch[5/100] training loss 0.00405, training accuracy 0.85156\n",
      "epoch[5/100] training loss 0.00402, training accuracy 0.86719\n",
      "epoch[5/100] training loss 0.00416, training accuracy 0.82812\n",
      "epoch[5/100] training loss 0.00404, training accuracy 0.86328\n",
      "epoch[5/100] training loss 0.00420, training accuracy 0.81250\n",
      "epoch[5/100] training loss 0.00426, training accuracy 0.80078\n",
      "epoch[5/100] training loss 0.00406, training accuracy 0.81641\n",
      "epoch[5/100] training loss 0.00418, training accuracy 0.80469\n",
      "epoch[5/100] training loss 0.00419, training accuracy 0.82422\n",
      "epoch[5/100] training loss 0.00432, training accuracy 0.80078\n",
      "epoch[5/100] training loss 0.00433, training accuracy 0.80078\n",
      "epoch[5/100] training loss 0.00411, training accuracy 0.85547\n",
      "epoch[5/100] training loss 0.00408, training accuracy 0.82812\n",
      "epoch[5/100] training loss 0.00417, training accuracy 0.82812\n",
      "epoch[5/100] training loss 0.00405, training accuracy 0.85156\n",
      "epoch[5/100] training loss 0.00429, training accuracy 0.81250\n",
      "epoch[5/100] training loss 0.00413, training accuracy 0.84766\n",
      "epoch[5/100] training loss 0.00407, training accuracy 0.82422\n",
      "epoch[5/100] training loss 0.00390, training accuracy 0.85156\n",
      "epoch[5/100] training loss 0.00373, training accuracy 0.05469\n",
      "[val] acc : 0.83439, loss : 1.03686\n",
      "best acc : 0.83439, best loss : 1.03686\n",
      "epoch[6/100] training loss 0.00387, training accuracy 0.86719\n",
      "epoch[6/100] training loss 0.00409, training accuracy 0.81250\n",
      "epoch[6/100] training loss 0.00400, training accuracy 0.83594\n",
      "epoch[6/100] training loss 0.00423, training accuracy 0.84766\n",
      "epoch[6/100] training loss 0.00419, training accuracy 0.80078\n",
      "epoch[6/100] training loss 0.00420, training accuracy 0.81250\n",
      "epoch[6/100] training loss 0.00424, training accuracy 0.80469\n",
      "epoch[6/100] training loss 0.00427, training accuracy 0.80469\n",
      "epoch[6/100] training loss 0.00405, training accuracy 0.84766\n",
      "epoch[6/100] training loss 0.00402, training accuracy 0.87109\n",
      "epoch[6/100] training loss 0.00418, training accuracy 0.83984\n",
      "epoch[6/100] training loss 0.00395, training accuracy 0.84766\n",
      "epoch[6/100] training loss 0.00433, training accuracy 0.78906\n",
      "epoch[6/100] training loss 0.00396, training accuracy 0.82031\n",
      "epoch[6/100] training loss 0.00424, training accuracy 0.81641\n",
      "epoch[6/100] training loss 0.00411, training accuracy 0.82031\n",
      "epoch[6/100] training loss 0.00397, training accuracy 0.85547\n",
      "epoch[6/100] training loss 0.00433, training accuracy 0.78906\n",
      "epoch[6/100] training loss 0.00390, training accuracy 0.85156\n",
      "epoch[6/100] training loss 0.00420, training accuracy 0.82422\n",
      "epoch[6/100] training loss 0.00406, training accuracy 0.84375\n",
      "epoch[6/100] training loss 0.00412, training accuracy 0.83203\n",
      "epoch[6/100] training loss 0.00397, training accuracy 0.85547\n",
      "epoch[6/100] training loss 0.00399, training accuracy 0.84766\n",
      "epoch[6/100] training loss 0.00391, training accuracy 0.87500\n",
      "epoch[6/100] training loss 0.00429, training accuracy 0.80859\n",
      "epoch[6/100] training loss 0.00413, training accuracy 0.83594\n",
      "epoch[6/100] training loss 0.00405, training accuracy 0.85547\n",
      "epoch[6/100] training loss 0.00396, training accuracy 0.86719\n",
      "epoch[6/100] training loss 0.00410, training accuracy 0.84766\n",
      "epoch[6/100] training loss 0.00405, training accuracy 0.84766\n",
      "epoch[6/100] training loss 0.00403, training accuracy 0.83984\n",
      "epoch[6/100] training loss 0.00415, training accuracy 0.82031\n",
      "epoch[6/100] training loss 0.00410, training accuracy 0.82422\n",
      "epoch[6/100] training loss 0.00407, training accuracy 0.85547\n",
      "epoch[6/100] training loss 0.00397, training accuracy 0.86328\n",
      "epoch[6/100] training loss 0.00406, training accuracy 0.82422\n",
      "epoch[6/100] training loss 0.00400, training accuracy 0.84375\n",
      "epoch[6/100] training loss 0.00414, training accuracy 0.84375\n",
      "epoch[6/100] training loss 0.00423, training accuracy 0.79688\n",
      "epoch[6/100] training loss 0.00396, training accuracy 0.85547\n",
      "epoch[6/100] training loss 0.00401, training accuracy 0.84766\n",
      "epoch[6/100] training loss 0.00407, training accuracy 0.82422\n",
      "epoch[6/100] training loss 0.00398, training accuracy 0.82422\n",
      "epoch[6/100] training loss 0.00413, training accuracy 0.83594\n",
      "epoch[6/100] training loss 0.00410, training accuracy 0.83203\n",
      "epoch[6/100] training loss 0.00422, training accuracy 0.82031\n",
      "epoch[6/100] training loss 0.00423, training accuracy 0.81641\n",
      "epoch[6/100] training loss 0.00429, training accuracy 0.81250\n",
      "epoch[6/100] training loss 0.00395, training accuracy 0.85156\n",
      "epoch[6/100] training loss 0.00411, training accuracy 0.84375\n",
      "epoch[6/100] training loss 0.00390, training accuracy 0.84766\n",
      "epoch[6/100] training loss 0.00386, training accuracy 0.87109\n",
      "epoch[6/100] training loss 0.00394, training accuracy 0.87109\n",
      "epoch[6/100] training loss 0.00393, training accuracy 0.82422\n",
      "epoch[6/100] training loss 0.00377, training accuracy 0.87500\n",
      "epoch[6/100] training loss 0.00410, training accuracy 0.84375\n",
      "epoch[6/100] training loss 0.00414, training accuracy 0.82422\n",
      "epoch[6/100] training loss 0.00411, training accuracy 0.82812\n",
      "epoch[6/100] training loss 0.00452, training accuracy 0.03906\n",
      "[val] acc : 0.84074, loss : 1.01873\n",
      "best acc : 0.84074, best loss : 1.01873\n",
      "epoch[7/100] training loss 0.00385, training accuracy 0.85547\n",
      "epoch[7/100] training loss 0.00395, training accuracy 0.85938\n",
      "epoch[7/100] training loss 0.00427, training accuracy 0.80078\n",
      "epoch[7/100] training loss 0.00408, training accuracy 0.82812\n",
      "epoch[7/100] training loss 0.00403, training accuracy 0.83203\n",
      "epoch[7/100] training loss 0.00401, training accuracy 0.85156\n",
      "epoch[7/100] training loss 0.00430, training accuracy 0.81641\n",
      "epoch[7/100] training loss 0.00417, training accuracy 0.81250\n",
      "epoch[7/100] training loss 0.00387, training accuracy 0.87500\n",
      "epoch[7/100] training loss 0.00410, training accuracy 0.82031\n",
      "epoch[7/100] training loss 0.00408, training accuracy 0.85547\n",
      "epoch[7/100] training loss 0.00389, training accuracy 0.86719\n",
      "epoch[7/100] training loss 0.00394, training accuracy 0.82031\n",
      "epoch[7/100] training loss 0.00384, training accuracy 0.85156\n",
      "epoch[7/100] training loss 0.00397, training accuracy 0.87500\n",
      "epoch[7/100] training loss 0.00427, training accuracy 0.79688\n",
      "epoch[7/100] training loss 0.00417, training accuracy 0.82422\n",
      "epoch[7/100] training loss 0.00423, training accuracy 0.82031\n",
      "epoch[7/100] training loss 0.00392, training accuracy 0.86719\n",
      "epoch[7/100] training loss 0.00420, training accuracy 0.83203\n",
      "epoch[7/100] training loss 0.00391, training accuracy 0.86328\n",
      "epoch[7/100] training loss 0.00397, training accuracy 0.83203\n",
      "epoch[7/100] training loss 0.00366, training accuracy 0.89453\n",
      "epoch[7/100] training loss 0.00393, training accuracy 0.84375\n",
      "epoch[7/100] training loss 0.00397, training accuracy 0.85938\n",
      "epoch[7/100] training loss 0.00396, training accuracy 0.82812\n",
      "epoch[7/100] training loss 0.00396, training accuracy 0.86328\n",
      "epoch[7/100] training loss 0.00404, training accuracy 0.83984\n",
      "epoch[7/100] training loss 0.00415, training accuracy 0.81641\n",
      "epoch[7/100] training loss 0.00401, training accuracy 0.84766\n",
      "epoch[7/100] training loss 0.00416, training accuracy 0.81641\n",
      "epoch[7/100] training loss 0.00383, training accuracy 0.85547\n",
      "epoch[7/100] training loss 0.00422, training accuracy 0.83594\n",
      "epoch[7/100] training loss 0.00396, training accuracy 0.83594\n",
      "epoch[7/100] training loss 0.00398, training accuracy 0.87891\n",
      "epoch[7/100] training loss 0.00378, training accuracy 0.87109\n",
      "epoch[7/100] training loss 0.00396, training accuracy 0.85547\n",
      "epoch[7/100] training loss 0.00410, training accuracy 0.84766\n",
      "epoch[7/100] training loss 0.00395, training accuracy 0.85547\n",
      "epoch[7/100] training loss 0.00404, training accuracy 0.82031\n",
      "epoch[7/100] training loss 0.00385, training accuracy 0.89062\n",
      "epoch[7/100] training loss 0.00386, training accuracy 0.86328\n",
      "epoch[7/100] training loss 0.00416, training accuracy 0.83203\n",
      "epoch[7/100] training loss 0.00385, training accuracy 0.85938\n",
      "epoch[7/100] training loss 0.00393, training accuracy 0.86719\n",
      "epoch[7/100] training loss 0.00413, training accuracy 0.81250\n",
      "epoch[7/100] training loss 0.00410, training accuracy 0.82812\n",
      "epoch[7/100] training loss 0.00397, training accuracy 0.85938\n",
      "epoch[7/100] training loss 0.00410, training accuracy 0.83984\n",
      "epoch[7/100] training loss 0.00388, training accuracy 0.86328\n",
      "epoch[7/100] training loss 0.00403, training accuracy 0.83203\n",
      "epoch[7/100] training loss 0.00395, training accuracy 0.85938\n",
      "epoch[7/100] training loss 0.00394, training accuracy 0.84766\n",
      "epoch[7/100] training loss 0.00399, training accuracy 0.85547\n",
      "epoch[7/100] training loss 0.00383, training accuracy 0.87109\n",
      "epoch[7/100] training loss 0.00403, training accuracy 0.85547\n",
      "epoch[7/100] training loss 0.00401, training accuracy 0.83203\n",
      "epoch[7/100] training loss 0.00405, training accuracy 0.85938\n",
      "epoch[7/100] training loss 0.00397, training accuracy 0.83594\n",
      "epoch[7/100] training loss 0.00418, training accuracy 0.04688\n",
      "[val] acc : 0.84709, loss : 1.00353\n",
      "best acc : 0.84709, best loss : 1.00353\n",
      "epoch[8/100] training loss 0.00379, training accuracy 0.85938\n",
      "epoch[8/100] training loss 0.00396, training accuracy 0.85156\n",
      "epoch[8/100] training loss 0.00418, training accuracy 0.81641\n",
      "epoch[8/100] training loss 0.00391, training accuracy 0.87500\n",
      "epoch[8/100] training loss 0.00400, training accuracy 0.83203\n",
      "epoch[8/100] training loss 0.00398, training accuracy 0.82812\n",
      "epoch[8/100] training loss 0.00405, training accuracy 0.82812\n",
      "epoch[8/100] training loss 0.00413, training accuracy 0.80469\n",
      "epoch[8/100] training loss 0.00413, training accuracy 0.78516\n",
      "epoch[8/100] training loss 0.00388, training accuracy 0.87891\n",
      "epoch[8/100] training loss 0.00386, training accuracy 0.85547\n",
      "epoch[8/100] training loss 0.00430, training accuracy 0.79688\n",
      "epoch[8/100] training loss 0.00409, training accuracy 0.84766\n",
      "epoch[8/100] training loss 0.00395, training accuracy 0.85156\n",
      "epoch[8/100] training loss 0.00403, training accuracy 0.83594\n",
      "epoch[8/100] training loss 0.00384, training accuracy 0.86328\n",
      "epoch[8/100] training loss 0.00408, training accuracy 0.81641\n",
      "epoch[8/100] training loss 0.00388, training accuracy 0.86719\n",
      "epoch[8/100] training loss 0.00404, training accuracy 0.84375\n",
      "epoch[8/100] training loss 0.00397, training accuracy 0.86328\n",
      "epoch[8/100] training loss 0.00397, training accuracy 0.85547\n",
      "epoch[8/100] training loss 0.00412, training accuracy 0.80469\n",
      "epoch[8/100] training loss 0.00369, training accuracy 0.89453\n",
      "epoch[8/100] training loss 0.00408, training accuracy 0.83984\n",
      "epoch[8/100] training loss 0.00393, training accuracy 0.85547\n",
      "epoch[8/100] training loss 0.00378, training accuracy 0.86328\n",
      "epoch[8/100] training loss 0.00386, training accuracy 0.85938\n",
      "epoch[8/100] training loss 0.00395, training accuracy 0.85547\n",
      "epoch[8/100] training loss 0.00406, training accuracy 0.83984\n",
      "epoch[8/100] training loss 0.00376, training accuracy 0.87109\n",
      "epoch[8/100] training loss 0.00392, training accuracy 0.86328\n",
      "epoch[8/100] training loss 0.00405, training accuracy 0.82422\n",
      "epoch[8/100] training loss 0.00396, training accuracy 0.85547\n",
      "epoch[8/100] training loss 0.00396, training accuracy 0.85156\n",
      "epoch[8/100] training loss 0.00388, training accuracy 0.86328\n",
      "epoch[8/100] training loss 0.00387, training accuracy 0.85938\n",
      "epoch[8/100] training loss 0.00399, training accuracy 0.85547\n",
      "epoch[8/100] training loss 0.00403, training accuracy 0.83594\n",
      "epoch[8/100] training loss 0.00384, training accuracy 0.87109\n",
      "epoch[8/100] training loss 0.00383, training accuracy 0.85156\n",
      "epoch[8/100] training loss 0.00396, training accuracy 0.84766\n",
      "epoch[8/100] training loss 0.00387, training accuracy 0.85156\n",
      "epoch[8/100] training loss 0.00400, training accuracy 0.83594\n",
      "epoch[8/100] training loss 0.00409, training accuracy 0.84375\n",
      "epoch[8/100] training loss 0.00402, training accuracy 0.83203\n",
      "epoch[8/100] training loss 0.00398, training accuracy 0.85938\n",
      "epoch[8/100] training loss 0.00390, training accuracy 0.86328\n",
      "epoch[8/100] training loss 0.00412, training accuracy 0.83984\n",
      "epoch[8/100] training loss 0.00381, training accuracy 0.85156\n",
      "epoch[8/100] training loss 0.00417, training accuracy 0.81250\n",
      "epoch[8/100] training loss 0.00437, training accuracy 0.79688\n",
      "epoch[8/100] training loss 0.00381, training accuracy 0.86328\n",
      "epoch[8/100] training loss 0.00382, training accuracy 0.84766\n",
      "epoch[8/100] training loss 0.00383, training accuracy 0.86328\n",
      "epoch[8/100] training loss 0.00383, training accuracy 0.87891\n",
      "epoch[8/100] training loss 0.00410, training accuracy 0.83203\n",
      "epoch[8/100] training loss 0.00396, training accuracy 0.83203\n",
      "epoch[8/100] training loss 0.00386, training accuracy 0.85547\n",
      "epoch[8/100] training loss 0.00373, training accuracy 0.86719\n",
      "epoch[8/100] training loss 0.00326, training accuracy 0.05859\n",
      "[val] acc : 0.85079, loss : 0.98648\n",
      "best acc : 0.85079, best loss : 0.98648\n",
      "epoch[9/100] training loss 0.00403, training accuracy 0.84375\n",
      "epoch[9/100] training loss 0.00369, training accuracy 0.89062\n",
      "epoch[9/100] training loss 0.00384, training accuracy 0.85547\n",
      "epoch[9/100] training loss 0.00387, training accuracy 0.84375\n",
      "epoch[9/100] training loss 0.00406, training accuracy 0.85938\n",
      "epoch[9/100] training loss 0.00409, training accuracy 0.84375\n",
      "epoch[9/100] training loss 0.00390, training accuracy 0.85547\n",
      "epoch[9/100] training loss 0.00415, training accuracy 0.83594\n",
      "epoch[9/100] training loss 0.00407, training accuracy 0.85156\n",
      "epoch[9/100] training loss 0.00384, training accuracy 0.85938\n",
      "epoch[9/100] training loss 0.00368, training accuracy 0.88672\n",
      "epoch[9/100] training loss 0.00371, training accuracy 0.90234\n",
      "epoch[9/100] training loss 0.00392, training accuracy 0.83984\n",
      "epoch[9/100] training loss 0.00388, training accuracy 0.84375\n",
      "epoch[9/100] training loss 0.00389, training accuracy 0.84375\n",
      "epoch[9/100] training loss 0.00384, training accuracy 0.85547\n",
      "epoch[9/100] training loss 0.00381, training accuracy 0.86328\n",
      "epoch[9/100] training loss 0.00388, training accuracy 0.85938\n",
      "epoch[9/100] training loss 0.00382, training accuracy 0.86719\n",
      "epoch[9/100] training loss 0.00415, training accuracy 0.82422\n",
      "epoch[9/100] training loss 0.00399, training accuracy 0.85938\n",
      "epoch[9/100] training loss 0.00383, training accuracy 0.86328\n",
      "epoch[9/100] training loss 0.00407, training accuracy 0.82812\n",
      "epoch[9/100] training loss 0.00378, training accuracy 0.86328\n",
      "epoch[9/100] training loss 0.00400, training accuracy 0.84766\n",
      "epoch[9/100] training loss 0.00379, training accuracy 0.84375\n",
      "epoch[9/100] training loss 0.00375, training accuracy 0.85156\n",
      "epoch[9/100] training loss 0.00381, training accuracy 0.85938\n",
      "epoch[9/100] training loss 0.00415, training accuracy 0.83203\n",
      "epoch[9/100] training loss 0.00397, training accuracy 0.84375\n",
      "epoch[9/100] training loss 0.00408, training accuracy 0.84766\n",
      "epoch[9/100] training loss 0.00427, training accuracy 0.82031\n",
      "epoch[9/100] training loss 0.00373, training accuracy 0.90625\n",
      "epoch[9/100] training loss 0.00378, training accuracy 0.87500\n",
      "epoch[9/100] training loss 0.00407, training accuracy 0.85156\n",
      "epoch[9/100] training loss 0.00400, training accuracy 0.85547\n",
      "epoch[9/100] training loss 0.00385, training accuracy 0.85938\n",
      "epoch[9/100] training loss 0.00395, training accuracy 0.85547\n",
      "epoch[9/100] training loss 0.00399, training accuracy 0.83203\n",
      "epoch[9/100] training loss 0.00364, training accuracy 0.88672\n",
      "epoch[9/100] training loss 0.00384, training accuracy 0.84375\n",
      "epoch[9/100] training loss 0.00380, training accuracy 0.84766\n",
      "epoch[9/100] training loss 0.00413, training accuracy 0.80859\n",
      "epoch[9/100] training loss 0.00362, training accuracy 0.87891\n",
      "epoch[9/100] training loss 0.00390, training accuracy 0.86328\n",
      "epoch[9/100] training loss 0.00368, training accuracy 0.89453\n",
      "epoch[9/100] training loss 0.00401, training accuracy 0.83203\n",
      "epoch[9/100] training loss 0.00406, training accuracy 0.83984\n",
      "epoch[9/100] training loss 0.00363, training accuracy 0.88672\n",
      "epoch[9/100] training loss 0.00382, training accuracy 0.85938\n",
      "epoch[9/100] training loss 0.00374, training accuracy 0.87891\n",
      "epoch[9/100] training loss 0.00367, training accuracy 0.87109\n",
      "epoch[9/100] training loss 0.00381, training accuracy 0.85547\n",
      "epoch[9/100] training loss 0.00402, training accuracy 0.86328\n",
      "epoch[9/100] training loss 0.00398, training accuracy 0.83984\n",
      "epoch[9/100] training loss 0.00398, training accuracy 0.81250\n",
      "epoch[9/100] training loss 0.00389, training accuracy 0.85938\n",
      "epoch[9/100] training loss 0.00400, training accuracy 0.87109\n",
      "epoch[9/100] training loss 0.00374, training accuracy 0.85938\n",
      "epoch[9/100] training loss 0.00408, training accuracy 0.05859\n",
      "[val] acc : 0.85450, loss : 0.97320\n",
      "best acc : 0.85450, best loss : 0.97320\n",
      "epoch[10/100] training loss 0.00383, training accuracy 0.87500\n",
      "epoch[10/100] training loss 0.00392, training accuracy 0.83984\n",
      "epoch[10/100] training loss 0.00392, training accuracy 0.85938\n",
      "epoch[10/100] training loss 0.00394, training accuracy 0.81250\n",
      "epoch[10/100] training loss 0.00397, training accuracy 0.83594\n",
      "epoch[10/100] training loss 0.00408, training accuracy 0.82422\n",
      "epoch[10/100] training loss 0.00383, training accuracy 0.84375\n",
      "epoch[10/100] training loss 0.00367, training accuracy 0.86719\n",
      "epoch[10/100] training loss 0.00363, training accuracy 0.89844\n",
      "epoch[10/100] training loss 0.00371, training accuracy 0.87500\n",
      "epoch[10/100] training loss 0.00407, training accuracy 0.83594\n",
      "epoch[10/100] training loss 0.00396, training accuracy 0.84375\n",
      "epoch[10/100] training loss 0.00365, training accuracy 0.87891\n",
      "epoch[10/100] training loss 0.00367, training accuracy 0.87891\n",
      "epoch[10/100] training loss 0.00364, training accuracy 0.87891\n",
      "epoch[10/100] training loss 0.00395, training accuracy 0.83594\n",
      "epoch[10/100] training loss 0.00396, training accuracy 0.84766\n",
      "epoch[10/100] training loss 0.00383, training accuracy 0.87891\n",
      "epoch[10/100] training loss 0.00413, training accuracy 0.82031\n",
      "epoch[10/100] training loss 0.00354, training accuracy 0.89453\n",
      "epoch[10/100] training loss 0.00378, training accuracy 0.87500\n",
      "epoch[10/100] training loss 0.00361, training accuracy 0.87891\n",
      "epoch[10/100] training loss 0.00383, training accuracy 0.88281\n",
      "epoch[10/100] training loss 0.00396, training accuracy 0.86328\n",
      "epoch[10/100] training loss 0.00391, training accuracy 0.84375\n",
      "epoch[10/100] training loss 0.00389, training accuracy 0.87109\n",
      "epoch[10/100] training loss 0.00399, training accuracy 0.83984\n",
      "epoch[10/100] training loss 0.00410, training accuracy 0.81641\n",
      "epoch[10/100] training loss 0.00386, training accuracy 0.83594\n",
      "epoch[10/100] training loss 0.00360, training accuracy 0.91016\n",
      "epoch[10/100] training loss 0.00401, training accuracy 0.84375\n",
      "epoch[10/100] training loss 0.00370, training accuracy 0.88281\n",
      "epoch[10/100] training loss 0.00384, training accuracy 0.86719\n",
      "epoch[10/100] training loss 0.00394, training accuracy 0.87500\n",
      "epoch[10/100] training loss 0.00421, training accuracy 0.80469\n",
      "epoch[10/100] training loss 0.00371, training accuracy 0.86328\n",
      "epoch[10/100] training loss 0.00390, training accuracy 0.85547\n",
      "epoch[10/100] training loss 0.00392, training accuracy 0.84375\n",
      "epoch[10/100] training loss 0.00380, training accuracy 0.87109\n",
      "epoch[10/100] training loss 0.00398, training accuracy 0.81641\n",
      "epoch[10/100] training loss 0.00375, training accuracy 0.85938\n",
      "epoch[10/100] training loss 0.00369, training accuracy 0.87109\n",
      "epoch[10/100] training loss 0.00387, training accuracy 0.87500\n",
      "epoch[10/100] training loss 0.00378, training accuracy 0.86328\n",
      "epoch[10/100] training loss 0.00372, training accuracy 0.85938\n",
      "epoch[10/100] training loss 0.00366, training accuracy 0.86328\n",
      "epoch[10/100] training loss 0.00379, training accuracy 0.85938\n",
      "epoch[10/100] training loss 0.00395, training accuracy 0.83984\n",
      "epoch[10/100] training loss 0.00381, training accuracy 0.86719\n",
      "epoch[10/100] training loss 0.00374, training accuracy 0.89062\n",
      "epoch[10/100] training loss 0.00398, training accuracy 0.83984\n",
      "epoch[10/100] training loss 0.00360, training accuracy 0.89453\n",
      "epoch[10/100] training loss 0.00376, training accuracy 0.87500\n",
      "epoch[10/100] training loss 0.00401, training accuracy 0.83984\n",
      "epoch[10/100] training loss 0.00380, training accuracy 0.87891\n",
      "epoch[10/100] training loss 0.00368, training accuracy 0.87500\n",
      "epoch[10/100] training loss 0.00376, training accuracy 0.88281\n",
      "epoch[10/100] training loss 0.00374, training accuracy 0.84375\n",
      "epoch[10/100] training loss 0.00383, training accuracy 0.85156\n",
      "epoch[10/100] training loss 0.00392, training accuracy 0.05469\n",
      "[val] acc : 0.86217, loss : 0.96111\n",
      "best acc : 0.86217, best loss : 0.96111\n",
      "epoch[11/100] training loss 0.00375, training accuracy 0.86719\n",
      "epoch[11/100] training loss 0.00379, training accuracy 0.86328\n",
      "epoch[11/100] training loss 0.00402, training accuracy 0.83984\n",
      "epoch[11/100] training loss 0.00399, training accuracy 0.83594\n",
      "epoch[11/100] training loss 0.00409, training accuracy 0.82031\n",
      "epoch[11/100] training loss 0.00379, training accuracy 0.84766\n",
      "epoch[11/100] training loss 0.00371, training accuracy 0.87109\n",
      "epoch[11/100] training loss 0.00395, training accuracy 0.84766\n",
      "epoch[11/100] training loss 0.00392, training accuracy 0.84375\n",
      "epoch[11/100] training loss 0.00398, training accuracy 0.83984\n",
      "epoch[11/100] training loss 0.00390, training accuracy 0.81250\n",
      "epoch[11/100] training loss 0.00386, training accuracy 0.85547\n",
      "epoch[11/100] training loss 0.00392, training accuracy 0.84375\n",
      "epoch[11/100] training loss 0.00380, training accuracy 0.86719\n",
      "epoch[11/100] training loss 0.00372, training accuracy 0.87500\n",
      "epoch[11/100] training loss 0.00369, training accuracy 0.86328\n",
      "epoch[11/100] training loss 0.00395, training accuracy 0.85547\n",
      "epoch[11/100] training loss 0.00393, training accuracy 0.86328\n",
      "epoch[11/100] training loss 0.00397, training accuracy 0.83984\n",
      "epoch[11/100] training loss 0.00359, training accuracy 0.88672\n",
      "epoch[11/100] training loss 0.00369, training accuracy 0.88281\n",
      "epoch[11/100] training loss 0.00358, training accuracy 0.90234\n",
      "epoch[11/100] training loss 0.00369, training accuracy 0.86719\n",
      "epoch[11/100] training loss 0.00387, training accuracy 0.85547\n",
      "epoch[11/100] training loss 0.00373, training accuracy 0.87891\n",
      "epoch[11/100] training loss 0.00385, training accuracy 0.86328\n",
      "epoch[11/100] training loss 0.00371, training accuracy 0.86719\n",
      "epoch[11/100] training loss 0.00390, training accuracy 0.85156\n",
      "epoch[11/100] training loss 0.00392, training accuracy 0.85156\n",
      "epoch[11/100] training loss 0.00378, training accuracy 0.85938\n",
      "epoch[11/100] training loss 0.00388, training accuracy 0.85547\n",
      "epoch[11/100] training loss 0.00375, training accuracy 0.85938\n",
      "epoch[11/100] training loss 0.00382, training accuracy 0.87891\n",
      "epoch[11/100] training loss 0.00371, training accuracy 0.89453\n",
      "epoch[11/100] training loss 0.00402, training accuracy 0.82422\n",
      "epoch[11/100] training loss 0.00377, training accuracy 0.88281\n",
      "epoch[11/100] training loss 0.00364, training accuracy 0.88672\n",
      "epoch[11/100] training loss 0.00370, training accuracy 0.87109\n",
      "epoch[11/100] training loss 0.00393, training accuracy 0.82422\n",
      "epoch[11/100] training loss 0.00381, training accuracy 0.87891\n",
      "epoch[11/100] training loss 0.00356, training accuracy 0.87891\n",
      "epoch[11/100] training loss 0.00392, training accuracy 0.83594\n",
      "epoch[11/100] training loss 0.00399, training accuracy 0.85156\n",
      "epoch[11/100] training loss 0.00392, training accuracy 0.84375\n",
      "epoch[11/100] training loss 0.00377, training accuracy 0.85156\n",
      "epoch[11/100] training loss 0.00390, training accuracy 0.87109\n",
      "epoch[11/100] training loss 0.00360, training accuracy 0.88281\n",
      "epoch[11/100] training loss 0.00360, training accuracy 0.87891\n",
      "epoch[11/100] training loss 0.00377, training accuracy 0.87109\n",
      "epoch[11/100] training loss 0.00377, training accuracy 0.87891\n",
      "epoch[11/100] training loss 0.00406, training accuracy 0.81250\n",
      "epoch[11/100] training loss 0.00373, training accuracy 0.89844\n",
      "epoch[11/100] training loss 0.00384, training accuracy 0.87500\n",
      "epoch[11/100] training loss 0.00364, training accuracy 0.87500\n",
      "epoch[11/100] training loss 0.00366, training accuracy 0.87891\n",
      "epoch[11/100] training loss 0.00378, training accuracy 0.85938\n",
      "epoch[11/100] training loss 0.00375, training accuracy 0.89062\n",
      "epoch[11/100] training loss 0.00424, training accuracy 0.78125\n",
      "epoch[11/100] training loss 0.00385, training accuracy 0.88281\n",
      "epoch[11/100] training loss 0.00366, training accuracy 0.05078\n",
      "[val] acc : 0.86138, loss : 0.95482\n",
      "best acc : 0.86217, best loss : 0.95482\n",
      "epoch[12/100] training loss 0.00382, training accuracy 0.86719\n",
      "epoch[12/100] training loss 0.00372, training accuracy 0.87500\n",
      "epoch[12/100] training loss 0.00358, training accuracy 0.90625\n",
      "epoch[12/100] training loss 0.00378, training accuracy 0.87109\n",
      "epoch[12/100] training loss 0.00371, training accuracy 0.87500\n",
      "epoch[12/100] training loss 0.00389, training accuracy 0.83203\n",
      "epoch[12/100] training loss 0.00384, training accuracy 0.84375\n",
      "epoch[12/100] training loss 0.00384, training accuracy 0.85547\n",
      "epoch[12/100] training loss 0.00378, training accuracy 0.87500\n",
      "epoch[12/100] training loss 0.00373, training accuracy 0.86719\n",
      "epoch[12/100] training loss 0.00382, training accuracy 0.87109\n",
      "epoch[12/100] training loss 0.00390, training accuracy 0.85547\n",
      "epoch[12/100] training loss 0.00368, training accuracy 0.86719\n",
      "epoch[12/100] training loss 0.00389, training accuracy 0.83984\n",
      "epoch[12/100] training loss 0.00370, training accuracy 0.87891\n",
      "epoch[12/100] training loss 0.00372, training accuracy 0.88672\n",
      "epoch[12/100] training loss 0.00395, training accuracy 0.84766\n",
      "epoch[12/100] training loss 0.00366, training accuracy 0.86328\n",
      "epoch[12/100] training loss 0.00366, training accuracy 0.87500\n",
      "epoch[12/100] training loss 0.00368, training accuracy 0.89844\n",
      "epoch[12/100] training loss 0.00355, training accuracy 0.89844\n",
      "epoch[12/100] training loss 0.00382, training accuracy 0.85547\n",
      "epoch[12/100] training loss 0.00389, training accuracy 0.84766\n",
      "epoch[12/100] training loss 0.00384, training accuracy 0.84766\n",
      "epoch[12/100] training loss 0.00370, training accuracy 0.87891\n",
      "epoch[12/100] training loss 0.00381, training accuracy 0.86719\n",
      "epoch[12/100] training loss 0.00380, training accuracy 0.85938\n",
      "epoch[12/100] training loss 0.00368, training accuracy 0.87500\n",
      "epoch[12/100] training loss 0.00383, training accuracy 0.85156\n",
      "epoch[12/100] training loss 0.00348, training accuracy 0.91406\n",
      "epoch[12/100] training loss 0.00364, training accuracy 0.88281\n",
      "epoch[12/100] training loss 0.00393, training accuracy 0.83203\n",
      "epoch[12/100] training loss 0.00378, training accuracy 0.85156\n",
      "epoch[12/100] training loss 0.00382, training accuracy 0.85547\n",
      "epoch[12/100] training loss 0.00405, training accuracy 0.82812\n",
      "epoch[12/100] training loss 0.00390, training accuracy 0.84375\n",
      "epoch[12/100] training loss 0.00371, training accuracy 0.86328\n",
      "epoch[12/100] training loss 0.00353, training accuracy 0.89844\n",
      "epoch[12/100] training loss 0.00382, training accuracy 0.87109\n",
      "epoch[12/100] training loss 0.00388, training accuracy 0.84375\n",
      "epoch[12/100] training loss 0.00385, training accuracy 0.86719\n",
      "epoch[12/100] training loss 0.00375, training accuracy 0.87891\n",
      "epoch[12/100] training loss 0.00365, training accuracy 0.89453\n",
      "epoch[12/100] training loss 0.00383, training accuracy 0.87109\n",
      "epoch[12/100] training loss 0.00357, training accuracy 0.88672\n",
      "epoch[12/100] training loss 0.00361, training accuracy 0.89062\n",
      "epoch[12/100] training loss 0.00375, training accuracy 0.89062\n",
      "epoch[12/100] training loss 0.00390, training accuracy 0.85547\n",
      "epoch[12/100] training loss 0.00400, training accuracy 0.84375\n",
      "epoch[12/100] training loss 0.00381, training accuracy 0.86328\n",
      "epoch[12/100] training loss 0.00370, training accuracy 0.87109\n",
      "epoch[12/100] training loss 0.00385, training accuracy 0.86328\n",
      "epoch[12/100] training loss 0.00351, training accuracy 0.90234\n",
      "epoch[12/100] training loss 0.00368, training accuracy 0.87500\n",
      "epoch[12/100] training loss 0.00371, training accuracy 0.85156\n",
      "epoch[12/100] training loss 0.00371, training accuracy 0.86719\n",
      "epoch[12/100] training loss 0.00353, training accuracy 0.89062\n",
      "epoch[12/100] training loss 0.00371, training accuracy 0.88672\n",
      "epoch[12/100] training loss 0.00356, training accuracy 0.87500\n",
      "epoch[12/100] training loss 0.00511, training accuracy 0.05078\n",
      "[val] acc : 0.85794, loss : 0.96202\n",
      "best acc : 0.86217, best loss : 0.95482\n",
      "epoch[13/100] training loss 0.00363, training accuracy 0.89062\n",
      "epoch[13/100] training loss 0.00377, training accuracy 0.85547\n",
      "epoch[13/100] training loss 0.00386, training accuracy 0.87109\n",
      "epoch[13/100] training loss 0.00409, training accuracy 0.85547\n",
      "epoch[13/100] training loss 0.00366, training accuracy 0.87500\n",
      "epoch[13/100] training loss 0.00366, training accuracy 0.87500\n",
      "epoch[13/100] training loss 0.00366, training accuracy 0.90234\n",
      "epoch[13/100] training loss 0.00384, training accuracy 0.87500\n",
      "epoch[13/100] training loss 0.00406, training accuracy 0.81250\n",
      "epoch[13/100] training loss 0.00391, training accuracy 0.83984\n",
      "epoch[13/100] training loss 0.00384, training accuracy 0.86328\n",
      "epoch[13/100] training loss 0.00367, training accuracy 0.87891\n",
      "epoch[13/100] training loss 0.00391, training accuracy 0.85938\n",
      "epoch[13/100] training loss 0.00377, training accuracy 0.87891\n",
      "epoch[13/100] training loss 0.00391, training accuracy 0.87891\n",
      "epoch[13/100] training loss 0.00375, training accuracy 0.87109\n",
      "epoch[13/100] training loss 0.00361, training accuracy 0.88281\n",
      "epoch[13/100] training loss 0.00372, training accuracy 0.87109\n",
      "epoch[13/100] training loss 0.00345, training accuracy 0.90625\n",
      "epoch[13/100] training loss 0.00347, training accuracy 0.91406\n",
      "epoch[13/100] training loss 0.00381, training accuracy 0.83203\n",
      "epoch[13/100] training loss 0.00391, training accuracy 0.85547\n",
      "epoch[13/100] training loss 0.00358, training accuracy 0.90234\n",
      "epoch[13/100] training loss 0.00368, training accuracy 0.89453\n",
      "epoch[13/100] training loss 0.00379, training accuracy 0.88281\n",
      "epoch[13/100] training loss 0.00366, training accuracy 0.87109\n",
      "epoch[13/100] training loss 0.00357, training accuracy 0.89453\n",
      "epoch[13/100] training loss 0.00374, training accuracy 0.87891\n",
      "epoch[13/100] training loss 0.00371, training accuracy 0.88672\n",
      "epoch[13/100] training loss 0.00381, training accuracy 0.87109\n",
      "epoch[13/100] training loss 0.00372, training accuracy 0.88281\n",
      "epoch[13/100] training loss 0.00368, training accuracy 0.88672\n",
      "epoch[13/100] training loss 0.00374, training accuracy 0.85938\n",
      "epoch[13/100] training loss 0.00377, training accuracy 0.85156\n",
      "epoch[13/100] training loss 0.00403, training accuracy 0.82812\n",
      "epoch[13/100] training loss 0.00370, training accuracy 0.88281\n",
      "epoch[13/100] training loss 0.00358, training accuracy 0.91406\n",
      "epoch[13/100] training loss 0.00388, training accuracy 0.83984\n",
      "epoch[13/100] training loss 0.00375, training accuracy 0.85156\n",
      "epoch[13/100] training loss 0.00386, training accuracy 0.87891\n",
      "epoch[13/100] training loss 0.00391, training accuracy 0.85156\n",
      "epoch[13/100] training loss 0.00380, training accuracy 0.86719\n",
      "epoch[13/100] training loss 0.00369, training accuracy 0.85547\n",
      "epoch[13/100] training loss 0.00378, training accuracy 0.87891\n",
      "epoch[13/100] training loss 0.00364, training accuracy 0.88281\n",
      "epoch[13/100] training loss 0.00391, training accuracy 0.85156\n",
      "epoch[13/100] training loss 0.00385, training accuracy 0.88281\n",
      "epoch[13/100] training loss 0.00408, training accuracy 0.82031\n",
      "epoch[13/100] training loss 0.00358, training accuracy 0.88672\n",
      "epoch[13/100] training loss 0.00381, training accuracy 0.87109\n",
      "epoch[13/100] training loss 0.00396, training accuracy 0.86328\n",
      "epoch[13/100] training loss 0.00383, training accuracy 0.85156\n",
      "epoch[13/100] training loss 0.00379, training accuracy 0.85938\n",
      "epoch[13/100] training loss 0.00376, training accuracy 0.87109\n",
      "epoch[13/100] training loss 0.00397, training accuracy 0.85547\n",
      "epoch[13/100] training loss 0.00367, training accuracy 0.88672\n",
      "epoch[13/100] training loss 0.00376, training accuracy 0.89062\n",
      "epoch[13/100] training loss 0.00371, training accuracy 0.86719\n",
      "epoch[13/100] training loss 0.00370, training accuracy 0.86719\n",
      "epoch[13/100] training loss 0.00430, training accuracy 0.04688\n",
      "[val] acc : 0.84947, loss : 0.96425\n",
      "best acc : 0.86217, best loss : 0.95482\n",
      "epoch[14/100] training loss 0.00369, training accuracy 0.86719\n",
      "epoch[14/100] training loss 0.00375, training accuracy 0.87109\n",
      "epoch[14/100] training loss 0.00403, training accuracy 0.81250\n",
      "epoch[14/100] training loss 0.00391, training accuracy 0.82422\n",
      "epoch[14/100] training loss 0.00391, training accuracy 0.85547\n",
      "epoch[14/100] training loss 0.00381, training accuracy 0.85547\n",
      "epoch[14/100] training loss 0.00394, training accuracy 0.84766\n",
      "epoch[14/100] training loss 0.00370, training accuracy 0.88281\n",
      "epoch[14/100] training loss 0.00369, training accuracy 0.88672\n",
      "epoch[14/100] training loss 0.00397, training accuracy 0.83984\n",
      "epoch[14/100] training loss 0.00381, training accuracy 0.87109\n",
      "epoch[14/100] training loss 0.00371, training accuracy 0.88281\n",
      "epoch[14/100] training loss 0.00355, training accuracy 0.88672\n",
      "epoch[14/100] training loss 0.00368, training accuracy 0.89062\n",
      "epoch[14/100] training loss 0.00366, training accuracy 0.86719\n",
      "epoch[14/100] training loss 0.00392, training accuracy 0.86328\n",
      "epoch[14/100] training loss 0.00375, training accuracy 0.88281\n",
      "epoch[14/100] training loss 0.00367, training accuracy 0.89453\n",
      "epoch[14/100] training loss 0.00376, training accuracy 0.87109\n",
      "epoch[14/100] training loss 0.00368, training accuracy 0.89062\n",
      "epoch[14/100] training loss 0.00374, training accuracy 0.85547\n",
      "epoch[14/100] training loss 0.00383, training accuracy 0.86328\n",
      "epoch[14/100] training loss 0.00381, training accuracy 0.85938\n",
      "epoch[14/100] training loss 0.00392, training accuracy 0.86328\n",
      "epoch[14/100] training loss 0.00381, training accuracy 0.84766\n",
      "epoch[14/100] training loss 0.00391, training accuracy 0.85938\n",
      "epoch[14/100] training loss 0.00355, training accuracy 0.88281\n",
      "epoch[14/100] training loss 0.00380, training accuracy 0.85938\n",
      "epoch[14/100] training loss 0.00365, training accuracy 0.90234\n",
      "epoch[14/100] training loss 0.00372, training accuracy 0.90234\n",
      "epoch[14/100] training loss 0.00379, training accuracy 0.87891\n",
      "epoch[14/100] training loss 0.00358, training accuracy 0.88672\n",
      "epoch[14/100] training loss 0.00355, training accuracy 0.88672\n",
      "epoch[14/100] training loss 0.00371, training accuracy 0.88281\n",
      "epoch[14/100] training loss 0.00402, training accuracy 0.82812\n",
      "epoch[14/100] training loss 0.00364, training accuracy 0.88281\n",
      "epoch[14/100] training loss 0.00368, training accuracy 0.86719\n",
      "epoch[14/100] training loss 0.00356, training accuracy 0.88672\n",
      "epoch[14/100] training loss 0.00368, training accuracy 0.87891\n",
      "epoch[14/100] training loss 0.00362, training accuracy 0.86719\n",
      "epoch[14/100] training loss 0.00392, training accuracy 0.83594\n",
      "epoch[14/100] training loss 0.00363, training accuracy 0.89062\n",
      "epoch[14/100] training loss 0.00380, training accuracy 0.86328\n",
      "epoch[14/100] training loss 0.00371, training accuracy 0.87891\n",
      "epoch[14/100] training loss 0.00364, training accuracy 0.91406\n",
      "epoch[14/100] training loss 0.00393, training accuracy 0.86719\n",
      "epoch[14/100] training loss 0.00372, training accuracy 0.86328\n",
      "epoch[14/100] training loss 0.00349, training accuracy 0.90234\n",
      "epoch[14/100] training loss 0.00353, training accuracy 0.91797\n",
      "epoch[14/100] training loss 0.00373, training accuracy 0.85156\n",
      "epoch[14/100] training loss 0.00378, training accuracy 0.85547\n",
      "epoch[14/100] training loss 0.00361, training accuracy 0.89062\n",
      "epoch[14/100] training loss 0.00363, training accuracy 0.88672\n",
      "epoch[14/100] training loss 0.00346, training accuracy 0.91016\n",
      "epoch[14/100] training loss 0.00385, training accuracy 0.85938\n",
      "epoch[14/100] training loss 0.00367, training accuracy 0.87109\n",
      "epoch[14/100] training loss 0.00378, training accuracy 0.87109\n",
      "epoch[14/100] training loss 0.00372, training accuracy 0.90234\n",
      "epoch[14/100] training loss 0.00365, training accuracy 0.89062\n",
      "epoch[14/100] training loss 0.00327, training accuracy 0.05469\n",
      "[val] acc : 0.86164, loss : 0.94565\n",
      "best acc : 0.86217, best loss : 0.94565\n",
      "epoch[15/100] training loss 0.00371, training accuracy 0.85547\n",
      "epoch[15/100] training loss 0.00382, training accuracy 0.86328\n",
      "epoch[15/100] training loss 0.00370, training accuracy 0.87109\n",
      "epoch[15/100] training loss 0.00363, training accuracy 0.87500\n",
      "epoch[15/100] training loss 0.00365, training accuracy 0.89062\n",
      "epoch[15/100] training loss 0.00380, training accuracy 0.83984\n",
      "epoch[15/100] training loss 0.00383, training accuracy 0.85938\n",
      "epoch[15/100] training loss 0.00389, training accuracy 0.87109\n",
      "epoch[15/100] training loss 0.00365, training accuracy 0.87891\n",
      "epoch[15/100] training loss 0.00366, training accuracy 0.88281\n",
      "epoch[15/100] training loss 0.00363, training accuracy 0.87500\n",
      "epoch[15/100] training loss 0.00353, training accuracy 0.89453\n",
      "epoch[15/100] training loss 0.00376, training accuracy 0.86719\n",
      "epoch[15/100] training loss 0.00372, training accuracy 0.87109\n",
      "epoch[15/100] training loss 0.00365, training accuracy 0.88672\n",
      "epoch[15/100] training loss 0.00381, training accuracy 0.85938\n",
      "epoch[15/100] training loss 0.00364, training accuracy 0.87109\n",
      "epoch[15/100] training loss 0.00361, training accuracy 0.89062\n",
      "epoch[15/100] training loss 0.00351, training accuracy 0.92188\n",
      "epoch[15/100] training loss 0.00346, training accuracy 0.91406\n",
      "epoch[15/100] training loss 0.00377, training accuracy 0.88281\n",
      "epoch[15/100] training loss 0.00382, training accuracy 0.85547\n",
      "epoch[15/100] training loss 0.00385, training accuracy 0.86328\n",
      "epoch[15/100] training loss 0.00376, training accuracy 0.86328\n",
      "epoch[15/100] training loss 0.00353, training accuracy 0.90625\n",
      "epoch[15/100] training loss 0.00365, training accuracy 0.87500\n",
      "epoch[15/100] training loss 0.00376, training accuracy 0.87500\n",
      "epoch[15/100] training loss 0.00354, training accuracy 0.90234\n",
      "epoch[15/100] training loss 0.00356, training accuracy 0.91016\n",
      "epoch[15/100] training loss 0.00359, training accuracy 0.90625\n",
      "epoch[15/100] training loss 0.00361, training accuracy 0.87500\n",
      "epoch[15/100] training loss 0.00365, training accuracy 0.88281\n",
      "epoch[15/100] training loss 0.00357, training accuracy 0.87109\n",
      "epoch[15/100] training loss 0.00352, training accuracy 0.89453\n",
      "epoch[15/100] training loss 0.00377, training accuracy 0.84375\n",
      "epoch[15/100] training loss 0.00353, training accuracy 0.88281\n",
      "epoch[15/100] training loss 0.00364, training accuracy 0.86719\n",
      "epoch[15/100] training loss 0.00363, training accuracy 0.87109\n",
      "epoch[15/100] training loss 0.00369, training accuracy 0.85938\n",
      "epoch[15/100] training loss 0.00382, training accuracy 0.85156\n",
      "epoch[15/100] training loss 0.00361, training accuracy 0.89453\n",
      "epoch[15/100] training loss 0.00361, training accuracy 0.89062\n",
      "epoch[15/100] training loss 0.00356, training accuracy 0.89844\n",
      "epoch[15/100] training loss 0.00372, training accuracy 0.86328\n",
      "epoch[15/100] training loss 0.00376, training accuracy 0.84375\n",
      "epoch[15/100] training loss 0.00372, training accuracy 0.87891\n",
      "epoch[15/100] training loss 0.00375, training accuracy 0.87109\n",
      "epoch[15/100] training loss 0.00372, training accuracy 0.88281\n",
      "epoch[15/100] training loss 0.00335, training accuracy 0.91797\n",
      "epoch[15/100] training loss 0.00360, training accuracy 0.88672\n",
      "epoch[15/100] training loss 0.00362, training accuracy 0.88672\n",
      "epoch[15/100] training loss 0.00380, training accuracy 0.84766\n",
      "epoch[15/100] training loss 0.00376, training accuracy 0.87109\n",
      "epoch[15/100] training loss 0.00352, training accuracy 0.90625\n",
      "epoch[15/100] training loss 0.00377, training accuracy 0.86719\n",
      "epoch[15/100] training loss 0.00358, training accuracy 0.87500\n",
      "epoch[15/100] training loss 0.00368, training accuracy 0.89844\n",
      "epoch[15/100] training loss 0.00357, training accuracy 0.88281\n",
      "epoch[15/100] training loss 0.00362, training accuracy 0.87500\n",
      "epoch[15/100] training loss 0.00306, training accuracy 0.05859\n",
      "[val] acc : 0.86667, loss : 0.93036\n",
      "best acc : 0.86667, best loss : 0.93036\n",
      "epoch[16/100] training loss 0.00359, training accuracy 0.87891\n",
      "epoch[16/100] training loss 0.00374, training accuracy 0.87891\n",
      "epoch[16/100] training loss 0.00355, training accuracy 0.87891\n",
      "epoch[16/100] training loss 0.00372, training accuracy 0.86328\n",
      "epoch[16/100] training loss 0.00366, training accuracy 0.88281\n",
      "epoch[16/100] training loss 0.00364, training accuracy 0.87500\n",
      "epoch[16/100] training loss 0.00383, training accuracy 0.85938\n",
      "epoch[16/100] training loss 0.00360, training accuracy 0.88281\n",
      "epoch[16/100] training loss 0.00386, training accuracy 0.85547\n",
      "epoch[16/100] training loss 0.00362, training accuracy 0.87891\n",
      "epoch[16/100] training loss 0.00381, training accuracy 0.86328\n",
      "epoch[16/100] training loss 0.00371, training accuracy 0.84766\n",
      "epoch[16/100] training loss 0.00373, training accuracy 0.85547\n",
      "epoch[16/100] training loss 0.00353, training accuracy 0.90625\n",
      "epoch[16/100] training loss 0.00372, training accuracy 0.89844\n",
      "epoch[16/100] training loss 0.00369, training accuracy 0.89062\n",
      "epoch[16/100] training loss 0.00380, training accuracy 0.84766\n",
      "epoch[16/100] training loss 0.00370, training accuracy 0.87109\n",
      "epoch[16/100] training loss 0.00368, training accuracy 0.88672\n",
      "epoch[16/100] training loss 0.00350, training accuracy 0.88672\n",
      "epoch[16/100] training loss 0.00365, training accuracy 0.90234\n",
      "epoch[16/100] training loss 0.00361, training accuracy 0.88281\n",
      "epoch[16/100] training loss 0.00355, training accuracy 0.90234\n",
      "epoch[16/100] training loss 0.00366, training accuracy 0.88281\n",
      "epoch[16/100] training loss 0.00340, training accuracy 0.91406\n",
      "epoch[16/100] training loss 0.00351, training accuracy 0.89844\n",
      "epoch[16/100] training loss 0.00350, training accuracy 0.90234\n",
      "epoch[16/100] training loss 0.00383, training accuracy 0.85156\n",
      "epoch[16/100] training loss 0.00357, training accuracy 0.89062\n",
      "epoch[16/100] training loss 0.00368, training accuracy 0.87500\n",
      "epoch[16/100] training loss 0.00361, training accuracy 0.87891\n",
      "epoch[16/100] training loss 0.00380, training accuracy 0.85547\n",
      "epoch[16/100] training loss 0.00363, training accuracy 0.87500\n",
      "epoch[16/100] training loss 0.00359, training accuracy 0.89062\n",
      "epoch[16/100] training loss 0.00344, training accuracy 0.87891\n",
      "epoch[16/100] training loss 0.00356, training accuracy 0.89062\n",
      "epoch[16/100] training loss 0.00355, training accuracy 0.87891\n",
      "epoch[16/100] training loss 0.00357, training accuracy 0.91016\n",
      "epoch[16/100] training loss 0.00357, training accuracy 0.89453\n",
      "epoch[16/100] training loss 0.00373, training accuracy 0.87109\n",
      "epoch[16/100] training loss 0.00381, training accuracy 0.86328\n",
      "epoch[16/100] training loss 0.00355, training accuracy 0.88281\n",
      "epoch[16/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[16/100] training loss 0.00387, training accuracy 0.85938\n",
      "epoch[16/100] training loss 0.00351, training accuracy 0.89844\n",
      "epoch[16/100] training loss 0.00367, training accuracy 0.88281\n",
      "epoch[16/100] training loss 0.00367, training accuracy 0.86328\n",
      "epoch[16/100] training loss 0.00370, training accuracy 0.88672\n",
      "epoch[16/100] training loss 0.00344, training accuracy 0.89453\n",
      "epoch[16/100] training loss 0.00358, training accuracy 0.87891\n",
      "epoch[16/100] training loss 0.00371, training accuracy 0.87109\n",
      "epoch[16/100] training loss 0.00374, training accuracy 0.88672\n",
      "epoch[16/100] training loss 0.00359, training accuracy 0.88672\n",
      "epoch[16/100] training loss 0.00383, training accuracy 0.83984\n",
      "epoch[16/100] training loss 0.00348, training accuracy 0.90625\n",
      "epoch[16/100] training loss 0.00368, training accuracy 0.85156\n",
      "epoch[16/100] training loss 0.00359, training accuracy 0.88281\n",
      "epoch[16/100] training loss 0.00374, training accuracy 0.82812\n",
      "epoch[16/100] training loss 0.00370, training accuracy 0.87109\n",
      "epoch[16/100] training loss 0.00336, training accuracy 0.05859\n",
      "[val] acc : 0.86958, loss : 0.92984\n",
      "best acc : 0.86958, best loss : 0.92984\n",
      "epoch[17/100] training loss 0.00359, training accuracy 0.88672\n",
      "epoch[17/100] training loss 0.00346, training accuracy 0.90234\n",
      "epoch[17/100] training loss 0.00353, training accuracy 0.89453\n",
      "epoch[17/100] training loss 0.00369, training accuracy 0.87891\n",
      "epoch[17/100] training loss 0.00357, training accuracy 0.89844\n",
      "epoch[17/100] training loss 0.00374, training accuracy 0.88672\n",
      "epoch[17/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[17/100] training loss 0.00363, training accuracy 0.88672\n",
      "epoch[17/100] training loss 0.00350, training accuracy 0.87109\n",
      "epoch[17/100] training loss 0.00353, training accuracy 0.90234\n",
      "epoch[17/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[17/100] training loss 0.00363, training accuracy 0.89062\n",
      "epoch[17/100] training loss 0.00359, training accuracy 0.87891\n",
      "epoch[17/100] training loss 0.00370, training accuracy 0.85938\n",
      "epoch[17/100] training loss 0.00366, training accuracy 0.87891\n",
      "epoch[17/100] training loss 0.00357, training accuracy 0.89062\n",
      "epoch[17/100] training loss 0.00370, training accuracy 0.89062\n",
      "epoch[17/100] training loss 0.00348, training accuracy 0.93359\n",
      "epoch[17/100] training loss 0.00383, training accuracy 0.82031\n",
      "epoch[17/100] training loss 0.00361, training accuracy 0.87109\n",
      "epoch[17/100] training loss 0.00362, training accuracy 0.87891\n",
      "epoch[17/100] training loss 0.00369, training accuracy 0.85156\n",
      "epoch[17/100] training loss 0.00358, training accuracy 0.91406\n",
      "epoch[17/100] training loss 0.00346, training accuracy 0.91016\n",
      "epoch[17/100] training loss 0.00381, training accuracy 0.83594\n",
      "epoch[17/100] training loss 0.00396, training accuracy 0.83984\n",
      "epoch[17/100] training loss 0.00365, training accuracy 0.86328\n",
      "epoch[17/100] training loss 0.00386, training accuracy 0.85547\n",
      "epoch[17/100] training loss 0.00357, training accuracy 0.89062\n",
      "epoch[17/100] training loss 0.00369, training accuracy 0.85547\n",
      "epoch[17/100] training loss 0.00365, training accuracy 0.89844\n",
      "epoch[17/100] training loss 0.00372, training accuracy 0.86328\n",
      "epoch[17/100] training loss 0.00379, training accuracy 0.85156\n",
      "epoch[17/100] training loss 0.00358, training accuracy 0.87891\n",
      "epoch[17/100] training loss 0.00363, training accuracy 0.87891\n",
      "epoch[17/100] training loss 0.00369, training accuracy 0.87500\n",
      "epoch[17/100] training loss 0.00367, training accuracy 0.86719\n",
      "epoch[17/100] training loss 0.00390, training accuracy 0.84766\n",
      "epoch[17/100] training loss 0.00365, training accuracy 0.88672\n",
      "epoch[17/100] training loss 0.00362, training accuracy 0.88281\n",
      "epoch[17/100] training loss 0.00348, training accuracy 0.90625\n",
      "epoch[17/100] training loss 0.00363, training accuracy 0.89844\n",
      "epoch[17/100] training loss 0.00364, training accuracy 0.88281\n",
      "epoch[17/100] training loss 0.00358, training accuracy 0.90234\n",
      "epoch[17/100] training loss 0.00349, training accuracy 0.91406\n",
      "epoch[17/100] training loss 0.00360, training accuracy 0.89062\n",
      "epoch[17/100] training loss 0.00380, training accuracy 0.86719\n",
      "epoch[17/100] training loss 0.00375, training accuracy 0.87891\n",
      "epoch[17/100] training loss 0.00366, training accuracy 0.89062\n",
      "epoch[17/100] training loss 0.00359, training accuracy 0.89453\n",
      "epoch[17/100] training loss 0.00377, training accuracy 0.85547\n",
      "epoch[17/100] training loss 0.00361, training accuracy 0.89453\n",
      "epoch[17/100] training loss 0.00362, training accuracy 0.88672\n",
      "epoch[17/100] training loss 0.00365, training accuracy 0.88672\n",
      "epoch[17/100] training loss 0.00368, training accuracy 0.86719\n",
      "epoch[17/100] training loss 0.00355, training accuracy 0.87500\n",
      "epoch[17/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[17/100] training loss 0.00369, training accuracy 0.85547\n",
      "epoch[17/100] training loss 0.00355, training accuracy 0.90234\n",
      "epoch[17/100] training loss 0.00329, training accuracy 0.05469\n",
      "[val] acc : 0.86852, loss : 0.92539\n",
      "best acc : 0.86958, best loss : 0.92539\n",
      "epoch[18/100] training loss 0.00357, training accuracy 0.89844\n",
      "epoch[18/100] training loss 0.00375, training accuracy 0.85938\n",
      "epoch[18/100] training loss 0.00373, training accuracy 0.87109\n",
      "epoch[18/100] training loss 0.00371, training accuracy 0.86719\n",
      "epoch[18/100] training loss 0.00369, training accuracy 0.86719\n",
      "epoch[18/100] training loss 0.00359, training accuracy 0.87109\n",
      "epoch[18/100] training loss 0.00362, training accuracy 0.87891\n",
      "epoch[18/100] training loss 0.00369, training accuracy 0.85938\n",
      "epoch[18/100] training loss 0.00354, training accuracy 0.89062\n",
      "epoch[18/100] training loss 0.00387, training accuracy 0.85156\n",
      "epoch[18/100] training loss 0.00366, training accuracy 0.87500\n",
      "epoch[18/100] training loss 0.00378, training accuracy 0.85547\n",
      "epoch[18/100] training loss 0.00359, training accuracy 0.89453\n",
      "epoch[18/100] training loss 0.00364, training accuracy 0.88281\n",
      "epoch[18/100] training loss 0.00357, training accuracy 0.91016\n",
      "epoch[18/100] training loss 0.00357, training accuracy 0.89062\n",
      "epoch[18/100] training loss 0.00353, training accuracy 0.89844\n",
      "epoch[18/100] training loss 0.00353, training accuracy 0.90234\n",
      "epoch[18/100] training loss 0.00335, training accuracy 0.94141\n",
      "epoch[18/100] training loss 0.00358, training accuracy 0.88672\n",
      "epoch[18/100] training loss 0.00356, training accuracy 0.87891\n",
      "epoch[18/100] training loss 0.00352, training accuracy 0.89062\n",
      "epoch[18/100] training loss 0.00368, training accuracy 0.86328\n",
      "epoch[18/100] training loss 0.00366, training accuracy 0.89453\n",
      "epoch[18/100] training loss 0.00365, training accuracy 0.89453\n",
      "epoch[18/100] training loss 0.00360, training accuracy 0.86328\n",
      "epoch[18/100] training loss 0.00350, training accuracy 0.89844\n",
      "epoch[18/100] training loss 0.00354, training accuracy 0.89062\n",
      "epoch[18/100] training loss 0.00339, training accuracy 0.91797\n",
      "epoch[18/100] training loss 0.00373, training accuracy 0.87500\n",
      "epoch[18/100] training loss 0.00368, training accuracy 0.88672\n",
      "epoch[18/100] training loss 0.00352, training accuracy 0.88672\n",
      "epoch[18/100] training loss 0.00347, training accuracy 0.89453\n",
      "epoch[18/100] training loss 0.00367, training accuracy 0.87109\n",
      "epoch[18/100] training loss 0.00349, training accuracy 0.89844\n",
      "epoch[18/100] training loss 0.00341, training accuracy 0.90625\n",
      "epoch[18/100] training loss 0.00365, training accuracy 0.86719\n",
      "epoch[18/100] training loss 0.00364, training accuracy 0.86719\n",
      "epoch[18/100] training loss 0.00374, training accuracy 0.85938\n",
      "epoch[18/100] training loss 0.00361, training accuracy 0.87891\n",
      "epoch[18/100] training loss 0.00355, training accuracy 0.91016\n",
      "epoch[18/100] training loss 0.00348, training accuracy 0.92578\n",
      "epoch[18/100] training loss 0.00361, training accuracy 0.87500\n",
      "epoch[18/100] training loss 0.00349, training accuracy 0.90234\n",
      "epoch[18/100] training loss 0.00366, training accuracy 0.87500\n",
      "epoch[18/100] training loss 0.00348, training accuracy 0.91406\n",
      "epoch[18/100] training loss 0.00361, training accuracy 0.87109\n",
      "epoch[18/100] training loss 0.00355, training accuracy 0.88281\n",
      "epoch[18/100] training loss 0.00359, training accuracy 0.87109\n",
      "epoch[18/100] training loss 0.00378, training accuracy 0.84766\n",
      "epoch[18/100] training loss 0.00355, training accuracy 0.91016\n",
      "epoch[18/100] training loss 0.00344, training accuracy 0.92188\n",
      "epoch[18/100] training loss 0.00353, training accuracy 0.90234\n",
      "epoch[18/100] training loss 0.00352, training accuracy 0.92969\n",
      "epoch[18/100] training loss 0.00377, training accuracy 0.85547\n",
      "epoch[18/100] training loss 0.00367, training accuracy 0.87109\n",
      "epoch[18/100] training loss 0.00323, training accuracy 0.93750\n",
      "epoch[18/100] training loss 0.00383, training accuracy 0.83594\n",
      "epoch[18/100] training loss 0.00354, training accuracy 0.91016\n",
      "epoch[18/100] training loss 0.00415, training accuracy 0.04688\n",
      "[val] acc : 0.86905, loss : 0.92508\n",
      "best acc : 0.86958, best loss : 0.92508\n",
      "epoch[19/100] training loss 0.00357, training accuracy 0.90625\n",
      "epoch[19/100] training loss 0.00349, training accuracy 0.89844\n",
      "epoch[19/100] training loss 0.00362, training accuracy 0.87891\n",
      "epoch[19/100] training loss 0.00359, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00360, training accuracy 0.89844\n",
      "epoch[19/100] training loss 0.00390, training accuracy 0.84375\n",
      "epoch[19/100] training loss 0.00333, training accuracy 0.92188\n",
      "epoch[19/100] training loss 0.00345, training accuracy 0.90234\n",
      "epoch[19/100] training loss 0.00351, training accuracy 0.92188\n",
      "epoch[19/100] training loss 0.00352, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00365, training accuracy 0.87891\n",
      "epoch[19/100] training loss 0.00349, training accuracy 0.91797\n",
      "epoch[19/100] training loss 0.00354, training accuracy 0.87500\n",
      "epoch[19/100] training loss 0.00367, training accuracy 0.86328\n",
      "epoch[19/100] training loss 0.00387, training accuracy 0.82031\n",
      "epoch[19/100] training loss 0.00359, training accuracy 0.90234\n",
      "epoch[19/100] training loss 0.00336, training accuracy 0.91016\n",
      "epoch[19/100] training loss 0.00353, training accuracy 0.89062\n",
      "epoch[19/100] training loss 0.00361, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00369, training accuracy 0.85547\n",
      "epoch[19/100] training loss 0.00372, training accuracy 0.87891\n",
      "epoch[19/100] training loss 0.00354, training accuracy 0.89453\n",
      "epoch[19/100] training loss 0.00345, training accuracy 0.90234\n",
      "epoch[19/100] training loss 0.00348, training accuracy 0.91016\n",
      "epoch[19/100] training loss 0.00370, training accuracy 0.86719\n",
      "epoch[19/100] training loss 0.00354, training accuracy 0.89844\n",
      "epoch[19/100] training loss 0.00373, training accuracy 0.89453\n",
      "epoch[19/100] training loss 0.00344, training accuracy 0.90234\n",
      "epoch[19/100] training loss 0.00382, training accuracy 0.85547\n",
      "epoch[19/100] training loss 0.00377, training accuracy 0.85156\n",
      "epoch[19/100] training loss 0.00373, training accuracy 0.87109\n",
      "epoch[19/100] training loss 0.00357, training accuracy 0.89453\n",
      "epoch[19/100] training loss 0.00367, training accuracy 0.87891\n",
      "epoch[19/100] training loss 0.00362, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00362, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00354, training accuracy 0.92969\n",
      "epoch[19/100] training loss 0.00361, training accuracy 0.87891\n",
      "epoch[19/100] training loss 0.00370, training accuracy 0.86719\n",
      "epoch[19/100] training loss 0.00329, training accuracy 0.93359\n",
      "epoch[19/100] training loss 0.00370, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00368, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00367, training accuracy 0.89844\n",
      "epoch[19/100] training loss 0.00361, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00349, training accuracy 0.90625\n",
      "epoch[19/100] training loss 0.00357, training accuracy 0.87891\n",
      "epoch[19/100] training loss 0.00356, training accuracy 0.89453\n",
      "epoch[19/100] training loss 0.00354, training accuracy 0.87891\n",
      "epoch[19/100] training loss 0.00372, training accuracy 0.87891\n",
      "epoch[19/100] training loss 0.00353, training accuracy 0.90234\n",
      "epoch[19/100] training loss 0.00356, training accuracy 0.90625\n",
      "epoch[19/100] training loss 0.00372, training accuracy 0.87500\n",
      "epoch[19/100] training loss 0.00350, training accuracy 0.89844\n",
      "epoch[19/100] training loss 0.00359, training accuracy 0.88672\n",
      "epoch[19/100] training loss 0.00360, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00365, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00354, training accuracy 0.88672\n",
      "epoch[19/100] training loss 0.00353, training accuracy 0.88281\n",
      "epoch[19/100] training loss 0.00350, training accuracy 0.87891\n",
      "epoch[19/100] training loss 0.00367, training accuracy 0.87109\n",
      "epoch[19/100] training loss 0.00339, training accuracy 0.05859\n",
      "[val] acc : 0.87222, loss : 0.91660\n",
      "best acc : 0.87222, best loss : 0.91660\n",
      "epoch[20/100] training loss 0.00330, training accuracy 0.92578\n",
      "epoch[20/100] training loss 0.00342, training accuracy 0.90625\n",
      "epoch[20/100] training loss 0.00349, training accuracy 0.90625\n",
      "epoch[20/100] training loss 0.00355, training accuracy 0.88672\n",
      "epoch[20/100] training loss 0.00363, training accuracy 0.88672\n",
      "epoch[20/100] training loss 0.00372, training accuracy 0.87109\n",
      "epoch[20/100] training loss 0.00363, training accuracy 0.88672\n",
      "epoch[20/100] training loss 0.00361, training accuracy 0.86719\n",
      "epoch[20/100] training loss 0.00355, training accuracy 0.90625\n",
      "epoch[20/100] training loss 0.00342, training accuracy 0.92188\n",
      "epoch[20/100] training loss 0.00357, training accuracy 0.89844\n",
      "epoch[20/100] training loss 0.00356, training accuracy 0.89453\n",
      "epoch[20/100] training loss 0.00341, training accuracy 0.91016\n",
      "epoch[20/100] training loss 0.00363, training accuracy 0.87891\n",
      "epoch[20/100] training loss 0.00336, training accuracy 0.89844\n",
      "epoch[20/100] training loss 0.00350, training accuracy 0.89062\n",
      "epoch[20/100] training loss 0.00338, training accuracy 0.90234\n",
      "epoch[20/100] training loss 0.00361, training accuracy 0.89844\n",
      "epoch[20/100] training loss 0.00349, training accuracy 0.89844\n",
      "epoch[20/100] training loss 0.00371, training accuracy 0.86328\n",
      "epoch[20/100] training loss 0.00358, training accuracy 0.91406\n",
      "epoch[20/100] training loss 0.00389, training accuracy 0.84766\n",
      "epoch[20/100] training loss 0.00351, training accuracy 0.92578\n",
      "epoch[20/100] training loss 0.00365, training accuracy 0.88672\n",
      "epoch[20/100] training loss 0.00366, training accuracy 0.89844\n",
      "epoch[20/100] training loss 0.00355, training accuracy 0.91016\n",
      "epoch[20/100] training loss 0.00371, training accuracy 0.85547\n",
      "epoch[20/100] training loss 0.00362, training accuracy 0.87109\n",
      "epoch[20/100] training loss 0.00339, training accuracy 0.92188\n",
      "epoch[20/100] training loss 0.00355, training accuracy 0.88672\n",
      "epoch[20/100] training loss 0.00361, training accuracy 0.89453\n",
      "epoch[20/100] training loss 0.00366, training accuracy 0.87891\n",
      "epoch[20/100] training loss 0.00358, training accuracy 0.89844\n",
      "epoch[20/100] training loss 0.00357, training accuracy 0.88672\n",
      "epoch[20/100] training loss 0.00352, training accuracy 0.89453\n",
      "epoch[20/100] training loss 0.00356, training accuracy 0.89844\n",
      "epoch[20/100] training loss 0.00358, training accuracy 0.87500\n",
      "epoch[20/100] training loss 0.00354, training accuracy 0.88281\n",
      "epoch[20/100] training loss 0.00354, training accuracy 0.88672\n",
      "epoch[20/100] training loss 0.00370, training accuracy 0.85938\n",
      "epoch[20/100] training loss 0.00347, training accuracy 0.90234\n",
      "epoch[20/100] training loss 0.00353, training accuracy 0.90234\n",
      "epoch[20/100] training loss 0.00376, training accuracy 0.86328\n",
      "epoch[20/100] training loss 0.00353, training accuracy 0.89453\n",
      "epoch[20/100] training loss 0.00360, training accuracy 0.88672\n",
      "epoch[20/100] training loss 0.00334, training accuracy 0.91406\n",
      "epoch[20/100] training loss 0.00376, training accuracy 0.87891\n",
      "epoch[20/100] training loss 0.00361, training accuracy 0.89453\n",
      "epoch[20/100] training loss 0.00346, training accuracy 0.90625\n",
      "epoch[20/100] training loss 0.00354, training accuracy 0.89844\n",
      "epoch[20/100] training loss 0.00365, training accuracy 0.86328\n",
      "epoch[20/100] training loss 0.00374, training accuracy 0.87500\n",
      "epoch[20/100] training loss 0.00345, training accuracy 0.89844\n",
      "epoch[20/100] training loss 0.00357, training accuracy 0.88672\n",
      "epoch[20/100] training loss 0.00354, training accuracy 0.89062\n",
      "epoch[20/100] training loss 0.00369, training accuracy 0.86328\n",
      "epoch[20/100] training loss 0.00367, training accuracy 0.86328\n",
      "epoch[20/100] training loss 0.00350, training accuracy 0.91406\n",
      "epoch[20/100] training loss 0.00368, training accuracy 0.87500\n",
      "epoch[20/100] training loss 0.00303, training accuracy 0.06250\n",
      "[val] acc : 0.87328, loss : 0.91822\n",
      "best acc : 0.87328, best loss : 0.91660\n",
      "epoch[21/100] training loss 0.00365, training accuracy 0.87891\n",
      "epoch[21/100] training loss 0.00359, training accuracy 0.88672\n",
      "epoch[21/100] training loss 0.00366, training accuracy 0.89062\n",
      "epoch[21/100] training loss 0.00349, training accuracy 0.88672\n",
      "epoch[21/100] training loss 0.00351, training accuracy 0.90234\n",
      "epoch[21/100] training loss 0.00369, training accuracy 0.90625\n",
      "epoch[21/100] training loss 0.00366, training accuracy 0.89844\n",
      "epoch[21/100] training loss 0.00373, training accuracy 0.89062\n",
      "epoch[21/100] training loss 0.00343, training accuracy 0.91406\n",
      "epoch[21/100] training loss 0.00359, training accuracy 0.89453\n",
      "epoch[21/100] training loss 0.00348, training accuracy 0.90234\n",
      "epoch[21/100] training loss 0.00363, training accuracy 0.87109\n",
      "epoch[21/100] training loss 0.00350, training accuracy 0.88672\n",
      "epoch[21/100] training loss 0.00357, training accuracy 0.90625\n",
      "epoch[21/100] training loss 0.00347, training accuracy 0.90625\n",
      "epoch[21/100] training loss 0.00355, training accuracy 0.87891\n",
      "epoch[21/100] training loss 0.00347, training accuracy 0.88672\n",
      "epoch[21/100] training loss 0.00349, training accuracy 0.89844\n",
      "epoch[21/100] training loss 0.00366, training accuracy 0.87109\n",
      "epoch[21/100] training loss 0.00348, training accuracy 0.90234\n",
      "epoch[21/100] training loss 0.00358, training accuracy 0.89453\n",
      "epoch[21/100] training loss 0.00360, training accuracy 0.91406\n",
      "epoch[21/100] training loss 0.00367, training accuracy 0.88281\n",
      "epoch[21/100] training loss 0.00342, training accuracy 0.94141\n",
      "epoch[21/100] training loss 0.00348, training accuracy 0.89453\n",
      "epoch[21/100] training loss 0.00354, training accuracy 0.90625\n",
      "epoch[21/100] training loss 0.00354, training accuracy 0.89844\n",
      "epoch[21/100] training loss 0.00359, training accuracy 0.89453\n",
      "epoch[21/100] training loss 0.00354, training accuracy 0.89453\n",
      "epoch[21/100] training loss 0.00335, training accuracy 0.90234\n",
      "epoch[21/100] training loss 0.00334, training accuracy 0.91797\n",
      "epoch[21/100] training loss 0.00348, training accuracy 0.89844\n",
      "epoch[21/100] training loss 0.00379, training accuracy 0.87109\n",
      "epoch[21/100] training loss 0.00361, training accuracy 0.86719\n",
      "epoch[21/100] training loss 0.00353, training accuracy 0.87891\n",
      "epoch[21/100] training loss 0.00359, training accuracy 0.89062\n",
      "epoch[21/100] training loss 0.00348, training accuracy 0.89844\n",
      "epoch[21/100] training loss 0.00369, training accuracy 0.87109\n",
      "epoch[21/100] training loss 0.00346, training accuracy 0.91797\n",
      "epoch[21/100] training loss 0.00369, training accuracy 0.87891\n",
      "epoch[21/100] training loss 0.00357, training accuracy 0.91016\n",
      "epoch[21/100] training loss 0.00338, training accuracy 0.92188\n",
      "epoch[21/100] training loss 0.00357, training accuracy 0.89844\n",
      "epoch[21/100] training loss 0.00349, training accuracy 0.89062\n",
      "epoch[21/100] training loss 0.00366, training accuracy 0.86719\n",
      "epoch[21/100] training loss 0.00356, training accuracy 0.89453\n",
      "epoch[21/100] training loss 0.00333, training accuracy 0.92969\n",
      "epoch[21/100] training loss 0.00357, training accuracy 0.89453\n",
      "epoch[21/100] training loss 0.00361, training accuracy 0.90234\n",
      "epoch[21/100] training loss 0.00367, training accuracy 0.87891\n",
      "epoch[21/100] training loss 0.00341, training accuracy 0.91016\n",
      "epoch[21/100] training loss 0.00356, training accuracy 0.86719\n",
      "epoch[21/100] training loss 0.00348, training accuracy 0.91016\n",
      "epoch[21/100] training loss 0.00354, training accuracy 0.88672\n",
      "epoch[21/100] training loss 0.00360, training accuracy 0.89062\n",
      "epoch[21/100] training loss 0.00364, training accuracy 0.87500\n",
      "epoch[21/100] training loss 0.00340, training accuracy 0.91406\n",
      "epoch[21/100] training loss 0.00330, training accuracy 0.91797\n",
      "epoch[21/100] training loss 0.00348, training accuracy 0.91016\n",
      "epoch[21/100] training loss 0.00288, training accuracy 0.05859\n",
      "[val] acc : 0.87989, loss : 0.90721\n",
      "best acc : 0.87989, best loss : 0.90721\n",
      "epoch[22/100] training loss 0.00339, training accuracy 0.91406\n",
      "epoch[22/100] training loss 0.00382, training accuracy 0.86719\n",
      "epoch[22/100] training loss 0.00347, training accuracy 0.90234\n",
      "epoch[22/100] training loss 0.00369, training accuracy 0.88672\n",
      "epoch[22/100] training loss 0.00363, training accuracy 0.88672\n",
      "epoch[22/100] training loss 0.00362, training accuracy 0.86328\n",
      "epoch[22/100] training loss 0.00366, training accuracy 0.91016\n",
      "epoch[22/100] training loss 0.00352, training accuracy 0.88281\n",
      "epoch[22/100] training loss 0.00355, training accuracy 0.89844\n",
      "epoch[22/100] training loss 0.00354, training accuracy 0.87500\n",
      "epoch[22/100] training loss 0.00327, training accuracy 0.91406\n",
      "epoch[22/100] training loss 0.00338, training accuracy 0.91016\n",
      "epoch[22/100] training loss 0.00334, training accuracy 0.93359\n",
      "epoch[22/100] training loss 0.00347, training accuracy 0.91016\n",
      "epoch[22/100] training loss 0.00352, training accuracy 0.87891\n",
      "epoch[22/100] training loss 0.00349, training accuracy 0.89844\n",
      "epoch[22/100] training loss 0.00338, training accuracy 0.92578\n",
      "epoch[22/100] training loss 0.00354, training accuracy 0.88672\n",
      "epoch[22/100] training loss 0.00364, training accuracy 0.89062\n",
      "epoch[22/100] training loss 0.00363, training accuracy 0.88281\n",
      "epoch[22/100] training loss 0.00330, training accuracy 0.94141\n",
      "epoch[22/100] training loss 0.00339, training accuracy 0.91797\n",
      "epoch[22/100] training loss 0.00351, training accuracy 0.89844\n",
      "epoch[22/100] training loss 0.00351, training accuracy 0.89062\n",
      "epoch[22/100] training loss 0.00346, training accuracy 0.89062\n",
      "epoch[22/100] training loss 0.00353, training accuracy 0.89062\n",
      "epoch[22/100] training loss 0.00362, training accuracy 0.88281\n",
      "epoch[22/100] training loss 0.00364, training accuracy 0.87500\n",
      "epoch[22/100] training loss 0.00330, training accuracy 0.93359\n",
      "epoch[22/100] training loss 0.00335, training accuracy 0.91406\n",
      "epoch[22/100] training loss 0.00365, training accuracy 0.88281\n",
      "epoch[22/100] training loss 0.00359, training accuracy 0.87891\n",
      "epoch[22/100] training loss 0.00369, training accuracy 0.89062\n",
      "epoch[22/100] training loss 0.00352, training accuracy 0.88672\n",
      "epoch[22/100] training loss 0.00343, training accuracy 0.91406\n",
      "epoch[22/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[22/100] training loss 0.00341, training accuracy 0.92188\n",
      "epoch[22/100] training loss 0.00375, training accuracy 0.85156\n",
      "epoch[22/100] training loss 0.00360, training accuracy 0.89453\n",
      "epoch[22/100] training loss 0.00361, training accuracy 0.87891\n",
      "epoch[22/100] training loss 0.00349, training accuracy 0.91016\n",
      "epoch[22/100] training loss 0.00353, training accuracy 0.89062\n",
      "epoch[22/100] training loss 0.00337, training accuracy 0.91016\n",
      "epoch[22/100] training loss 0.00340, training accuracy 0.88281\n",
      "epoch[22/100] training loss 0.00351, training accuracy 0.89844\n",
      "epoch[22/100] training loss 0.00363, training accuracy 0.89453\n",
      "epoch[22/100] training loss 0.00340, training accuracy 0.91406\n",
      "epoch[22/100] training loss 0.00349, training accuracy 0.89062\n",
      "epoch[22/100] training loss 0.00361, training accuracy 0.88672\n",
      "epoch[22/100] training loss 0.00390, training accuracy 0.85938\n",
      "epoch[22/100] training loss 0.00368, training accuracy 0.85938\n",
      "epoch[22/100] training loss 0.00335, training accuracy 0.92188\n",
      "epoch[22/100] training loss 0.00335, training accuracy 0.90234\n",
      "epoch[22/100] training loss 0.00344, training accuracy 0.92188\n",
      "epoch[22/100] training loss 0.00350, training accuracy 0.90625\n",
      "epoch[22/100] training loss 0.00353, training accuracy 0.88281\n",
      "epoch[22/100] training loss 0.00350, training accuracy 0.89844\n",
      "epoch[22/100] training loss 0.00342, training accuracy 0.91016\n",
      "epoch[22/100] training loss 0.00350, training accuracy 0.89844\n",
      "epoch[22/100] training loss 0.00336, training accuracy 0.05859\n",
      "[val] acc : 0.87619, loss : 0.90641\n",
      "best acc : 0.87989, best loss : 0.90641\n",
      "epoch[23/100] training loss 0.00357, training accuracy 0.88281\n",
      "epoch[23/100] training loss 0.00349, training accuracy 0.91406\n",
      "epoch[23/100] training loss 0.00340, training accuracy 0.90625\n",
      "epoch[23/100] training loss 0.00354, training accuracy 0.87891\n",
      "epoch[23/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[23/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[23/100] training loss 0.00329, training accuracy 0.91016\n",
      "epoch[23/100] training loss 0.00359, training accuracy 0.88281\n",
      "epoch[23/100] training loss 0.00345, training accuracy 0.89453\n",
      "epoch[23/100] training loss 0.00346, training accuracy 0.90625\n",
      "epoch[23/100] training loss 0.00350, training accuracy 0.90234\n",
      "epoch[23/100] training loss 0.00366, training accuracy 0.90234\n",
      "epoch[23/100] training loss 0.00365, training accuracy 0.89062\n",
      "epoch[23/100] training loss 0.00347, training accuracy 0.91797\n",
      "epoch[23/100] training loss 0.00355, training accuracy 0.87891\n",
      "epoch[23/100] training loss 0.00356, training accuracy 0.87891\n",
      "epoch[23/100] training loss 0.00337, training accuracy 0.91797\n",
      "epoch[23/100] training loss 0.00350, training accuracy 0.90234\n",
      "epoch[23/100] training loss 0.00363, training accuracy 0.86719\n",
      "epoch[23/100] training loss 0.00352, training accuracy 0.89062\n",
      "epoch[23/100] training loss 0.00348, training accuracy 0.91016\n",
      "epoch[23/100] training loss 0.00348, training accuracy 0.92578\n",
      "epoch[23/100] training loss 0.00330, training accuracy 0.93359\n",
      "epoch[23/100] training loss 0.00361, training accuracy 0.90234\n",
      "epoch[23/100] training loss 0.00335, training accuracy 0.91797\n",
      "epoch[23/100] training loss 0.00351, training accuracy 0.91406\n",
      "epoch[23/100] training loss 0.00338, training accuracy 0.92578\n",
      "epoch[23/100] training loss 0.00360, training accuracy 0.87109\n",
      "epoch[23/100] training loss 0.00354, training accuracy 0.88672\n",
      "epoch[23/100] training loss 0.00341, training accuracy 0.91016\n",
      "epoch[23/100] training loss 0.00357, training accuracy 0.89453\n",
      "epoch[23/100] training loss 0.00353, training accuracy 0.88281\n",
      "epoch[23/100] training loss 0.00358, training accuracy 0.87500\n",
      "epoch[23/100] training loss 0.00334, training accuracy 0.92188\n",
      "epoch[23/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[23/100] training loss 0.00347, training accuracy 0.90234\n",
      "epoch[23/100] training loss 0.00353, training accuracy 0.89062\n",
      "epoch[23/100] training loss 0.00363, training accuracy 0.86328\n",
      "epoch[23/100] training loss 0.00341, training accuracy 0.90625\n",
      "epoch[23/100] training loss 0.00344, training accuracy 0.90234\n",
      "epoch[23/100] training loss 0.00345, training accuracy 0.90625\n",
      "epoch[23/100] training loss 0.00363, training accuracy 0.87109\n",
      "epoch[23/100] training loss 0.00361, training accuracy 0.85547\n",
      "epoch[23/100] training loss 0.00336, training accuracy 0.92188\n",
      "epoch[23/100] training loss 0.00344, training accuracy 0.91016\n",
      "epoch[23/100] training loss 0.00339, training accuracy 0.92969\n",
      "epoch[23/100] training loss 0.00358, training accuracy 0.90234\n",
      "epoch[23/100] training loss 0.00365, training accuracy 0.89844\n",
      "epoch[23/100] training loss 0.00355, training accuracy 0.88672\n",
      "epoch[23/100] training loss 0.00351, training accuracy 0.90625\n",
      "epoch[23/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[23/100] training loss 0.00366, training accuracy 0.88281\n",
      "epoch[23/100] training loss 0.00354, training accuracy 0.88281\n",
      "epoch[23/100] training loss 0.00356, training accuracy 0.89453\n",
      "epoch[23/100] training loss 0.00354, training accuracy 0.89062\n",
      "epoch[23/100] training loss 0.00344, training accuracy 0.90625\n",
      "epoch[23/100] training loss 0.00367, training accuracy 0.88281\n",
      "epoch[23/100] training loss 0.00347, training accuracy 0.90234\n",
      "epoch[23/100] training loss 0.00357, training accuracy 0.89453\n",
      "epoch[23/100] training loss 0.00284, training accuracy 0.06250\n",
      "[val] acc : 0.88069, loss : 0.90291\n",
      "best acc : 0.88069, best loss : 0.90291\n",
      "epoch[24/100] training loss 0.00351, training accuracy 0.88672\n",
      "epoch[24/100] training loss 0.00351, training accuracy 0.91797\n",
      "epoch[24/100] training loss 0.00341, training accuracy 0.89062\n",
      "epoch[24/100] training loss 0.00353, training accuracy 0.89844\n",
      "epoch[24/100] training loss 0.00368, training accuracy 0.88281\n",
      "epoch[24/100] training loss 0.00343, training accuracy 0.89062\n",
      "epoch[24/100] training loss 0.00353, training accuracy 0.92188\n",
      "epoch[24/100] training loss 0.00348, training accuracy 0.91406\n",
      "epoch[24/100] training loss 0.00338, training accuracy 0.91797\n",
      "epoch[24/100] training loss 0.00356, training accuracy 0.87500\n",
      "epoch[24/100] training loss 0.00327, training accuracy 0.93750\n",
      "epoch[24/100] training loss 0.00349, training accuracy 0.90234\n",
      "epoch[24/100] training loss 0.00381, training accuracy 0.84375\n",
      "epoch[24/100] training loss 0.00339, training accuracy 0.91797\n",
      "epoch[24/100] training loss 0.00339, training accuracy 0.89844\n",
      "epoch[24/100] training loss 0.00357, training accuracy 0.89453\n",
      "epoch[24/100] training loss 0.00338, training accuracy 0.88672\n",
      "epoch[24/100] training loss 0.00339, training accuracy 0.92969\n",
      "epoch[24/100] training loss 0.00346, training accuracy 0.89453\n",
      "epoch[24/100] training loss 0.00329, training accuracy 0.92188\n",
      "epoch[24/100] training loss 0.00355, training accuracy 0.89844\n",
      "epoch[24/100] training loss 0.00340, training accuracy 0.91016\n",
      "epoch[24/100] training loss 0.00341, training accuracy 0.91797\n",
      "epoch[24/100] training loss 0.00331, training accuracy 0.92188\n",
      "epoch[24/100] training loss 0.00334, training accuracy 0.91406\n",
      "epoch[24/100] training loss 0.00348, training accuracy 0.89453\n",
      "epoch[24/100] training loss 0.00329, training accuracy 0.92969\n",
      "epoch[24/100] training loss 0.00337, training accuracy 0.92188\n",
      "epoch[24/100] training loss 0.00371, training accuracy 0.87109\n",
      "epoch[24/100] training loss 0.00374, training accuracy 0.85938\n",
      "epoch[24/100] training loss 0.00337, training accuracy 0.92578\n",
      "epoch[24/100] training loss 0.00347, training accuracy 0.89453\n",
      "epoch[24/100] training loss 0.00342, training accuracy 0.91016\n",
      "epoch[24/100] training loss 0.00353, training accuracy 0.90625\n",
      "epoch[24/100] training loss 0.00341, training accuracy 0.91797\n",
      "epoch[24/100] training loss 0.00338, training accuracy 0.91797\n",
      "epoch[24/100] training loss 0.00348, training accuracy 0.92188\n",
      "epoch[24/100] training loss 0.00343, training accuracy 0.91406\n",
      "epoch[24/100] training loss 0.00340, training accuracy 0.91016\n",
      "epoch[24/100] training loss 0.00376, training accuracy 0.87891\n",
      "epoch[24/100] training loss 0.00346, training accuracy 0.90625\n",
      "epoch[24/100] training loss 0.00347, training accuracy 0.89844\n",
      "epoch[24/100] training loss 0.00342, training accuracy 0.91797\n",
      "epoch[24/100] training loss 0.00359, training accuracy 0.89844\n",
      "epoch[24/100] training loss 0.00359, training accuracy 0.91797\n",
      "epoch[24/100] training loss 0.00361, training accuracy 0.89844\n",
      "epoch[24/100] training loss 0.00360, training accuracy 0.87891\n",
      "epoch[24/100] training loss 0.00343, training accuracy 0.90234\n",
      "epoch[24/100] training loss 0.00331, training accuracy 0.91016\n",
      "epoch[24/100] training loss 0.00365, training accuracy 0.88672\n",
      "epoch[24/100] training loss 0.00362, training accuracy 0.88672\n",
      "epoch[24/100] training loss 0.00357, training accuracy 0.89844\n",
      "epoch[24/100] training loss 0.00381, training accuracy 0.85938\n",
      "epoch[24/100] training loss 0.00344, training accuracy 0.91406\n",
      "epoch[24/100] training loss 0.00366, training accuracy 0.88281\n",
      "epoch[24/100] training loss 0.00346, training accuracy 0.91406\n",
      "epoch[24/100] training loss 0.00346, training accuracy 0.90234\n",
      "epoch[24/100] training loss 0.00342, training accuracy 0.89062\n",
      "epoch[24/100] training loss 0.00358, training accuracy 0.88672\n",
      "epoch[24/100] training loss 0.00375, training accuracy 0.05469\n",
      "[val] acc : 0.87646, loss : 0.90762\n",
      "best acc : 0.88069, best loss : 0.90291\n",
      "epoch[25/100] training loss 0.00358, training accuracy 0.88672\n",
      "epoch[25/100] training loss 0.00340, training accuracy 0.92188\n",
      "epoch[25/100] training loss 0.00372, training accuracy 0.87500\n",
      "epoch[25/100] training loss 0.00358, training accuracy 0.89062\n",
      "epoch[25/100] training loss 0.00349, training accuracy 0.89844\n",
      "epoch[25/100] training loss 0.00348, training accuracy 0.90625\n",
      "epoch[25/100] training loss 0.00364, training accuracy 0.89062\n",
      "epoch[25/100] training loss 0.00372, training accuracy 0.87500\n",
      "epoch[25/100] training loss 0.00365, training accuracy 0.89062\n",
      "epoch[25/100] training loss 0.00340, training accuracy 0.92188\n",
      "epoch[25/100] training loss 0.00358, training accuracy 0.89062\n",
      "epoch[25/100] training loss 0.00346, training accuracy 0.89062\n",
      "epoch[25/100] training loss 0.00340, training accuracy 0.91016\n",
      "epoch[25/100] training loss 0.00361, training accuracy 0.88281\n",
      "epoch[25/100] training loss 0.00340, training accuracy 0.90625\n",
      "epoch[25/100] training loss 0.00340, training accuracy 0.90234\n",
      "epoch[25/100] training loss 0.00364, training accuracy 0.88281\n",
      "epoch[25/100] training loss 0.00356, training accuracy 0.90625\n",
      "epoch[25/100] training loss 0.00352, training accuracy 0.90625\n",
      "epoch[25/100] training loss 0.00341, training accuracy 0.93359\n",
      "epoch[25/100] training loss 0.00344, training accuracy 0.91406\n",
      "epoch[25/100] training loss 0.00341, training accuracy 0.89844\n",
      "epoch[25/100] training loss 0.00368, training accuracy 0.87500\n",
      "epoch[25/100] training loss 0.00351, training accuracy 0.87109\n",
      "epoch[25/100] training loss 0.00340, training accuracy 0.91016\n",
      "epoch[25/100] training loss 0.00346, training accuracy 0.88672\n",
      "epoch[25/100] training loss 0.00345, training accuracy 0.89453\n",
      "epoch[25/100] training loss 0.00368, training accuracy 0.87109\n",
      "epoch[25/100] training loss 0.00342, training accuracy 0.89453\n",
      "epoch[25/100] training loss 0.00361, training accuracy 0.88281\n",
      "epoch[25/100] training loss 0.00368, training accuracy 0.85938\n",
      "epoch[25/100] training loss 0.00369, training accuracy 0.87109\n",
      "epoch[25/100] training loss 0.00352, training accuracy 0.90625\n",
      "epoch[25/100] training loss 0.00342, training accuracy 0.90625\n",
      "epoch[25/100] training loss 0.00360, training accuracy 0.86719\n",
      "epoch[25/100] training loss 0.00361, training accuracy 0.89453\n",
      "epoch[25/100] training loss 0.00343, training accuracy 0.90625\n",
      "epoch[25/100] training loss 0.00331, training accuracy 0.91406\n",
      "epoch[25/100] training loss 0.00343, training accuracy 0.88281\n",
      "epoch[25/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[25/100] training loss 0.00340, training accuracy 0.92969\n",
      "epoch[25/100] training loss 0.00342, training accuracy 0.92188\n",
      "epoch[25/100] training loss 0.00356, training accuracy 0.87891\n",
      "epoch[25/100] training loss 0.00352, training accuracy 0.88672\n",
      "epoch[25/100] training loss 0.00363, training accuracy 0.87500\n",
      "epoch[25/100] training loss 0.00345, training accuracy 0.90625\n",
      "epoch[25/100] training loss 0.00345, training accuracy 0.88281\n",
      "epoch[25/100] training loss 0.00334, training accuracy 0.91406\n",
      "epoch[25/100] training loss 0.00345, training accuracy 0.91406\n",
      "epoch[25/100] training loss 0.00335, training accuracy 0.94531\n",
      "epoch[25/100] training loss 0.00346, training accuracy 0.92188\n",
      "epoch[25/100] training loss 0.00334, training accuracy 0.92188\n",
      "epoch[25/100] training loss 0.00348, training accuracy 0.92188\n",
      "epoch[25/100] training loss 0.00352, training accuracy 0.89062\n",
      "epoch[25/100] training loss 0.00359, training accuracy 0.88672\n",
      "epoch[25/100] training loss 0.00332, training accuracy 0.91406\n",
      "epoch[25/100] training loss 0.00353, training accuracy 0.91016\n",
      "epoch[25/100] training loss 0.00354, training accuracy 0.87891\n",
      "epoch[25/100] training loss 0.00343, training accuracy 0.90234\n",
      "epoch[25/100] training loss 0.00338, training accuracy 0.05469\n",
      "[val] acc : 0.88360, loss : 0.89567\n",
      "best acc : 0.88360, best loss : 0.89567\n",
      "epoch[26/100] training loss 0.00350, training accuracy 0.88672\n",
      "epoch[26/100] training loss 0.00341, training accuracy 0.92969\n",
      "epoch[26/100] training loss 0.00349, training accuracy 0.88672\n",
      "epoch[26/100] training loss 0.00349, training accuracy 0.90234\n",
      "epoch[26/100] training loss 0.00353, training accuracy 0.88672\n",
      "epoch[26/100] training loss 0.00342, training accuracy 0.91406\n",
      "epoch[26/100] training loss 0.00341, training accuracy 0.92188\n",
      "epoch[26/100] training loss 0.00338, training accuracy 0.90625\n",
      "epoch[26/100] training loss 0.00354, training accuracy 0.89453\n",
      "epoch[26/100] training loss 0.00353, training accuracy 0.92578\n",
      "epoch[26/100] training loss 0.00354, training accuracy 0.91016\n",
      "epoch[26/100] training loss 0.00340, training accuracy 0.91016\n",
      "epoch[26/100] training loss 0.00344, training accuracy 0.90234\n",
      "epoch[26/100] training loss 0.00336, training accuracy 0.92188\n",
      "epoch[26/100] training loss 0.00327, training accuracy 0.91016\n",
      "epoch[26/100] training loss 0.00329, training accuracy 0.91797\n",
      "epoch[26/100] training loss 0.00342, training accuracy 0.91016\n",
      "epoch[26/100] training loss 0.00350, training accuracy 0.90234\n",
      "epoch[26/100] training loss 0.00362, training accuracy 0.88672\n",
      "epoch[26/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[26/100] training loss 0.00341, training accuracy 0.91406\n",
      "epoch[26/100] training loss 0.00357, training accuracy 0.89844\n",
      "epoch[26/100] training loss 0.00372, training accuracy 0.85156\n",
      "epoch[26/100] training loss 0.00360, training accuracy 0.87500\n",
      "epoch[26/100] training loss 0.00332, training accuracy 0.93359\n",
      "epoch[26/100] training loss 0.00344, training accuracy 0.91406\n",
      "epoch[26/100] training loss 0.00337, training accuracy 0.90625\n",
      "epoch[26/100] training loss 0.00344, training accuracy 0.91016\n",
      "epoch[26/100] training loss 0.00334, training accuracy 0.90234\n",
      "epoch[26/100] training loss 0.00336, training accuracy 0.91797\n",
      "epoch[26/100] training loss 0.00344, training accuracy 0.91406\n",
      "epoch[26/100] training loss 0.00336, training accuracy 0.91797\n",
      "epoch[26/100] training loss 0.00342, training accuracy 0.90625\n",
      "epoch[26/100] training loss 0.00348, training accuracy 0.92188\n",
      "epoch[26/100] training loss 0.00348, training accuracy 0.89844\n",
      "epoch[26/100] training loss 0.00338, training accuracy 0.92578\n",
      "epoch[26/100] training loss 0.00328, training accuracy 0.94531\n",
      "epoch[26/100] training loss 0.00354, training accuracy 0.91406\n",
      "epoch[26/100] training loss 0.00352, training accuracy 0.88672\n",
      "epoch[26/100] training loss 0.00344, training accuracy 0.90625\n",
      "epoch[26/100] training loss 0.00361, training accuracy 0.85938\n",
      "epoch[26/100] training loss 0.00343, training accuracy 0.91797\n",
      "epoch[26/100] training loss 0.00353, training accuracy 0.89062\n",
      "epoch[26/100] training loss 0.00336, training accuracy 0.91797\n",
      "epoch[26/100] training loss 0.00349, training accuracy 0.90625\n",
      "epoch[26/100] training loss 0.00353, training accuracy 0.90234\n",
      "epoch[26/100] training loss 0.00347, training accuracy 0.88281\n",
      "epoch[26/100] training loss 0.00346, training accuracy 0.90625\n",
      "epoch[26/100] training loss 0.00358, training accuracy 0.87500\n",
      "epoch[26/100] training loss 0.00355, training accuracy 0.89062\n",
      "epoch[26/100] training loss 0.00348, training accuracy 0.91016\n",
      "epoch[26/100] training loss 0.00338, training accuracy 0.89844\n",
      "epoch[26/100] training loss 0.00348, training accuracy 0.91406\n",
      "epoch[26/100] training loss 0.00358, training accuracy 0.89062\n",
      "epoch[26/100] training loss 0.00342, training accuracy 0.91406\n",
      "epoch[26/100] training loss 0.00343, training accuracy 0.90625\n",
      "epoch[26/100] training loss 0.00343, training accuracy 0.89844\n",
      "epoch[26/100] training loss 0.00348, training accuracy 0.91406\n",
      "epoch[26/100] training loss 0.00340, training accuracy 0.92969\n",
      "epoch[26/100] training loss 0.00304, training accuracy 0.06250\n",
      "[val] acc : 0.88915, loss : 0.88673\n",
      "best acc : 0.88915, best loss : 0.88673\n",
      "epoch[27/100] training loss 0.00335, training accuracy 0.90234\n",
      "epoch[27/100] training loss 0.00342, training accuracy 0.91406\n",
      "epoch[27/100] training loss 0.00343, training accuracy 0.90234\n",
      "epoch[27/100] training loss 0.00351, training accuracy 0.89844\n",
      "epoch[27/100] training loss 0.00338, training accuracy 0.91797\n",
      "epoch[27/100] training loss 0.00351, training accuracy 0.90625\n",
      "epoch[27/100] training loss 0.00373, training accuracy 0.87500\n",
      "epoch[27/100] training loss 0.00330, training accuracy 0.92188\n",
      "epoch[27/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[27/100] training loss 0.00334, training accuracy 0.92578\n",
      "epoch[27/100] training loss 0.00341, training accuracy 0.92578\n",
      "epoch[27/100] training loss 0.00340, training accuracy 0.92578\n",
      "epoch[27/100] training loss 0.00336, training accuracy 0.89844\n",
      "epoch[27/100] training loss 0.00351, training accuracy 0.89844\n",
      "epoch[27/100] training loss 0.00362, training accuracy 0.87891\n",
      "epoch[27/100] training loss 0.00339, training accuracy 0.89453\n",
      "epoch[27/100] training loss 0.00344, training accuracy 0.91016\n",
      "epoch[27/100] training loss 0.00341, training accuracy 0.90234\n",
      "epoch[27/100] training loss 0.00350, training accuracy 0.91016\n",
      "epoch[27/100] training loss 0.00336, training accuracy 0.92969\n",
      "epoch[27/100] training loss 0.00326, training accuracy 0.93359\n",
      "epoch[27/100] training loss 0.00339, training accuracy 0.91406\n",
      "epoch[27/100] training loss 0.00325, training accuracy 0.92578\n",
      "epoch[27/100] training loss 0.00321, training accuracy 0.93359\n",
      "epoch[27/100] training loss 0.00349, training accuracy 0.90625\n",
      "epoch[27/100] training loss 0.00347, training accuracy 0.91016\n",
      "epoch[27/100] training loss 0.00342, training accuracy 0.87500\n",
      "epoch[27/100] training loss 0.00356, training accuracy 0.88672\n",
      "epoch[27/100] training loss 0.00344, training accuracy 0.92188\n",
      "epoch[27/100] training loss 0.00336, training accuracy 0.93359\n",
      "epoch[27/100] training loss 0.00350, training accuracy 0.87109\n",
      "epoch[27/100] training loss 0.00325, training accuracy 0.93359\n",
      "epoch[27/100] training loss 0.00324, training accuracy 0.94531\n",
      "epoch[27/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[27/100] training loss 0.00364, training accuracy 0.86719\n",
      "epoch[27/100] training loss 0.00337, training accuracy 0.91016\n",
      "epoch[27/100] training loss 0.00345, training accuracy 0.91797\n",
      "epoch[27/100] training loss 0.00338, training accuracy 0.91016\n",
      "epoch[27/100] training loss 0.00336, training accuracy 0.91406\n",
      "epoch[27/100] training loss 0.00342, training accuracy 0.90234\n",
      "epoch[27/100] training loss 0.00348, training accuracy 0.90625\n",
      "epoch[27/100] training loss 0.00347, training accuracy 0.90625\n",
      "epoch[27/100] training loss 0.00372, training accuracy 0.87500\n",
      "epoch[27/100] training loss 0.00334, training accuracy 0.92578\n",
      "epoch[27/100] training loss 0.00355, training accuracy 0.90625\n",
      "epoch[27/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[27/100] training loss 0.00331, training accuracy 0.91406\n",
      "epoch[27/100] training loss 0.00358, training accuracy 0.88281\n",
      "epoch[27/100] training loss 0.00364, training accuracy 0.88281\n",
      "epoch[27/100] training loss 0.00371, training accuracy 0.87500\n",
      "epoch[27/100] training loss 0.00320, training accuracy 0.94141\n",
      "epoch[27/100] training loss 0.00336, training accuracy 0.91016\n",
      "epoch[27/100] training loss 0.00341, training accuracy 0.91406\n",
      "epoch[27/100] training loss 0.00349, training accuracy 0.89453\n",
      "epoch[27/100] training loss 0.00348, training accuracy 0.89453\n",
      "epoch[27/100] training loss 0.00346, training accuracy 0.90625\n",
      "epoch[27/100] training loss 0.00333, training accuracy 0.89453\n",
      "epoch[27/100] training loss 0.00342, training accuracy 0.89062\n",
      "epoch[27/100] training loss 0.00362, training accuracy 0.87891\n",
      "epoch[27/100] training loss 0.00303, training accuracy 0.05859\n",
      "[val] acc : 0.88624, loss : 0.89258\n",
      "best acc : 0.88915, best loss : 0.88673\n",
      "epoch[28/100] training loss 0.00354, training accuracy 0.89453\n",
      "epoch[28/100] training loss 0.00340, training accuracy 0.90234\n",
      "epoch[28/100] training loss 0.00332, training accuracy 0.92188\n",
      "epoch[28/100] training loss 0.00340, training accuracy 0.91016\n",
      "epoch[28/100] training loss 0.00344, training accuracy 0.90234\n",
      "epoch[28/100] training loss 0.00343, training accuracy 0.90234\n",
      "epoch[28/100] training loss 0.00349, training accuracy 0.89453\n",
      "epoch[28/100] training loss 0.00349, training accuracy 0.91016\n",
      "epoch[28/100] training loss 0.00358, training accuracy 0.89062\n",
      "epoch[28/100] training loss 0.00342, training accuracy 0.90234\n",
      "epoch[28/100] training loss 0.00325, training accuracy 0.93359\n",
      "epoch[28/100] training loss 0.00336, training accuracy 0.91406\n",
      "epoch[28/100] training loss 0.00350, training accuracy 0.88672\n",
      "epoch[28/100] training loss 0.00358, training accuracy 0.87891\n",
      "epoch[28/100] training loss 0.00347, training accuracy 0.89844\n",
      "epoch[28/100] training loss 0.00359, training accuracy 0.89062\n",
      "epoch[28/100] training loss 0.00337, training accuracy 0.91406\n",
      "epoch[28/100] training loss 0.00341, training accuracy 0.89844\n",
      "epoch[28/100] training loss 0.00342, training accuracy 0.91406\n",
      "epoch[28/100] training loss 0.00350, training accuracy 0.90625\n",
      "epoch[28/100] training loss 0.00329, training accuracy 0.92969\n",
      "epoch[28/100] training loss 0.00327, training accuracy 0.92188\n",
      "epoch[28/100] training loss 0.00334, training accuracy 0.91797\n",
      "epoch[28/100] training loss 0.00343, training accuracy 0.91406\n",
      "epoch[28/100] training loss 0.00351, training accuracy 0.88281\n",
      "epoch[28/100] training loss 0.00339, training accuracy 0.89844\n",
      "epoch[28/100] training loss 0.00337, training accuracy 0.90625\n",
      "epoch[28/100] training loss 0.00343, training accuracy 0.90234\n",
      "epoch[28/100] training loss 0.00341, training accuracy 0.91797\n",
      "epoch[28/100] training loss 0.00335, training accuracy 0.92969\n",
      "epoch[28/100] training loss 0.00329, training accuracy 0.91797\n",
      "epoch[28/100] training loss 0.00346, training accuracy 0.90625\n",
      "epoch[28/100] training loss 0.00351, training accuracy 0.87109\n",
      "epoch[28/100] training loss 0.00334, training accuracy 0.92188\n",
      "epoch[28/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[28/100] training loss 0.00330, training accuracy 0.94141\n",
      "epoch[28/100] training loss 0.00344, training accuracy 0.89844\n",
      "epoch[28/100] training loss 0.00336, training accuracy 0.91406\n",
      "epoch[28/100] training loss 0.00346, training accuracy 0.91406\n",
      "epoch[28/100] training loss 0.00344, training accuracy 0.88672\n",
      "epoch[28/100] training loss 0.00345, training accuracy 0.91406\n",
      "epoch[28/100] training loss 0.00341, training accuracy 0.90625\n",
      "epoch[28/100] training loss 0.00366, training accuracy 0.88281\n",
      "epoch[28/100] training loss 0.00334, training accuracy 0.93359\n",
      "epoch[28/100] training loss 0.00358, training accuracy 0.88672\n",
      "epoch[28/100] training loss 0.00331, training accuracy 0.94531\n",
      "epoch[28/100] training loss 0.00343, training accuracy 0.92578\n",
      "epoch[28/100] training loss 0.00344, training accuracy 0.91406\n",
      "epoch[28/100] training loss 0.00348, training accuracy 0.92578\n",
      "epoch[28/100] training loss 0.00335, training accuracy 0.90625\n",
      "epoch[28/100] training loss 0.00363, training accuracy 0.88672\n",
      "epoch[28/100] training loss 0.00327, training accuracy 0.91406\n",
      "epoch[28/100] training loss 0.00353, training accuracy 0.89453\n",
      "epoch[28/100] training loss 0.00340, training accuracy 0.90234\n",
      "epoch[28/100] training loss 0.00341, training accuracy 0.89062\n",
      "epoch[28/100] training loss 0.00353, training accuracy 0.90234\n",
      "epoch[28/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[28/100] training loss 0.00343, training accuracy 0.91797\n",
      "epoch[28/100] training loss 0.00329, training accuracy 0.93750\n",
      "epoch[28/100] training loss 0.00352, training accuracy 0.05859\n",
      "[val] acc : 0.88519, loss : 0.89475\n",
      "best acc : 0.88915, best loss : 0.88673\n",
      "epoch[29/100] training loss 0.00363, training accuracy 0.87109\n",
      "epoch[29/100] training loss 0.00332, training accuracy 0.92188\n",
      "epoch[29/100] training loss 0.00363, training accuracy 0.88672\n",
      "epoch[29/100] training loss 0.00356, training accuracy 0.87891\n",
      "epoch[29/100] training loss 0.00338, training accuracy 0.90234\n",
      "epoch[29/100] training loss 0.00333, training accuracy 0.91016\n",
      "epoch[29/100] training loss 0.00329, training accuracy 0.93750\n",
      "epoch[29/100] training loss 0.00342, training accuracy 0.92578\n",
      "epoch[29/100] training loss 0.00330, training accuracy 0.91406\n",
      "epoch[29/100] training loss 0.00348, training accuracy 0.91797\n",
      "epoch[29/100] training loss 0.00329, training accuracy 0.93359\n",
      "epoch[29/100] training loss 0.00328, training accuracy 0.92188\n",
      "epoch[29/100] training loss 0.00353, training accuracy 0.87109\n",
      "epoch[29/100] training loss 0.00343, training accuracy 0.90625\n",
      "epoch[29/100] training loss 0.00361, training accuracy 0.88281\n",
      "epoch[29/100] training loss 0.00340, training accuracy 0.91016\n",
      "epoch[29/100] training loss 0.00342, training accuracy 0.88672\n",
      "epoch[29/100] training loss 0.00359, training accuracy 0.89062\n",
      "epoch[29/100] training loss 0.00337, training accuracy 0.89844\n",
      "epoch[29/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[29/100] training loss 0.00326, training accuracy 0.94141\n",
      "epoch[29/100] training loss 0.00326, training accuracy 0.90625\n",
      "epoch[29/100] training loss 0.00349, training accuracy 0.89844\n",
      "epoch[29/100] training loss 0.00351, training accuracy 0.89062\n",
      "epoch[29/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[29/100] training loss 0.00335, training accuracy 0.92578\n",
      "epoch[29/100] training loss 0.00354, training accuracy 0.90234\n",
      "epoch[29/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[29/100] training loss 0.00327, training accuracy 0.92578\n",
      "epoch[29/100] training loss 0.00334, training accuracy 0.92188\n",
      "epoch[29/100] training loss 0.00332, training accuracy 0.92969\n",
      "epoch[29/100] training loss 0.00339, training accuracy 0.90234\n",
      "epoch[29/100] training loss 0.00341, training accuracy 0.91016\n",
      "epoch[29/100] training loss 0.00340, training accuracy 0.89062\n",
      "epoch[29/100] training loss 0.00346, training accuracy 0.91406\n",
      "epoch[29/100] training loss 0.00338, training accuracy 0.89844\n",
      "epoch[29/100] training loss 0.00343, training accuracy 0.88281\n",
      "epoch[29/100] training loss 0.00343, training accuracy 0.91016\n",
      "epoch[29/100] training loss 0.00335, training accuracy 0.90625\n",
      "epoch[29/100] training loss 0.00341, training accuracy 0.90625\n",
      "epoch[29/100] training loss 0.00352, training accuracy 0.91016\n",
      "epoch[29/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[29/100] training loss 0.00355, training accuracy 0.91406\n",
      "epoch[29/100] training loss 0.00346, training accuracy 0.90625\n",
      "epoch[29/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[29/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[29/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[29/100] training loss 0.00335, training accuracy 0.93359\n",
      "epoch[29/100] training loss 0.00347, training accuracy 0.92188\n",
      "epoch[29/100] training loss 0.00320, training accuracy 0.94531\n",
      "epoch[29/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[29/100] training loss 0.00359, training accuracy 0.88672\n",
      "epoch[29/100] training loss 0.00337, training accuracy 0.90625\n",
      "epoch[29/100] training loss 0.00357, training accuracy 0.89453\n",
      "epoch[29/100] training loss 0.00332, training accuracy 0.91406\n",
      "epoch[29/100] training loss 0.00324, training accuracy 0.94141\n",
      "epoch[29/100] training loss 0.00350, training accuracy 0.91016\n",
      "epoch[29/100] training loss 0.00344, training accuracy 0.90625\n",
      "epoch[29/100] training loss 0.00372, training accuracy 0.88281\n",
      "epoch[29/100] training loss 0.00320, training accuracy 0.05859\n",
      "[val] acc : 0.88677, loss : 0.88533\n",
      "best acc : 0.88915, best loss : 0.88533\n",
      "epoch[30/100] training loss 0.00341, training accuracy 0.91406\n",
      "epoch[30/100] training loss 0.00346, training accuracy 0.90234\n",
      "epoch[30/100] training loss 0.00341, training accuracy 0.90625\n",
      "epoch[30/100] training loss 0.00342, training accuracy 0.89453\n",
      "epoch[30/100] training loss 0.00332, training accuracy 0.92969\n",
      "epoch[30/100] training loss 0.00346, training accuracy 0.90625\n",
      "epoch[30/100] training loss 0.00336, training accuracy 0.91016\n",
      "epoch[30/100] training loss 0.00333, training accuracy 0.92188\n",
      "epoch[30/100] training loss 0.00346, training accuracy 0.87500\n",
      "epoch[30/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[30/100] training loss 0.00319, training accuracy 0.94922\n",
      "epoch[30/100] training loss 0.00332, training accuracy 0.92578\n",
      "epoch[30/100] training loss 0.00346, training accuracy 0.89844\n",
      "epoch[30/100] training loss 0.00327, training accuracy 0.94141\n",
      "epoch[30/100] training loss 0.00335, training accuracy 0.88672\n",
      "epoch[30/100] training loss 0.00331, training accuracy 0.91016\n",
      "epoch[30/100] training loss 0.00335, training accuracy 0.93359\n",
      "epoch[30/100] training loss 0.00342, training accuracy 0.89844\n",
      "epoch[30/100] training loss 0.00347, training accuracy 0.88281\n",
      "epoch[30/100] training loss 0.00363, training accuracy 0.89062\n",
      "epoch[30/100] training loss 0.00345, training accuracy 0.89844\n",
      "epoch[30/100] training loss 0.00336, training accuracy 0.91406\n",
      "epoch[30/100] training loss 0.00361, training accuracy 0.86719\n",
      "epoch[30/100] training loss 0.00337, training accuracy 0.91797\n",
      "epoch[30/100] training loss 0.00338, training accuracy 0.91016\n",
      "epoch[30/100] training loss 0.00344, training accuracy 0.88672\n",
      "epoch[30/100] training loss 0.00331, training accuracy 0.91797\n",
      "epoch[30/100] training loss 0.00341, training accuracy 0.91016\n",
      "epoch[30/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[30/100] training loss 0.00340, training accuracy 0.91406\n",
      "epoch[30/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[30/100] training loss 0.00332, training accuracy 0.92188\n",
      "epoch[30/100] training loss 0.00342, training accuracy 0.89453\n",
      "epoch[30/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[30/100] training loss 0.00355, training accuracy 0.89062\n",
      "epoch[30/100] training loss 0.00348, training accuracy 0.89062\n",
      "epoch[30/100] training loss 0.00334, training accuracy 0.91406\n",
      "epoch[30/100] training loss 0.00342, training accuracy 0.91797\n",
      "epoch[30/100] training loss 0.00322, training accuracy 0.91797\n",
      "epoch[30/100] training loss 0.00344, training accuracy 0.90625\n",
      "epoch[30/100] training loss 0.00335, training accuracy 0.91406\n",
      "epoch[30/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[30/100] training loss 0.00326, training accuracy 0.91797\n",
      "epoch[30/100] training loss 0.00346, training accuracy 0.91406\n",
      "epoch[30/100] training loss 0.00331, training accuracy 0.91406\n",
      "epoch[30/100] training loss 0.00336, training accuracy 0.91406\n",
      "epoch[30/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[30/100] training loss 0.00349, training accuracy 0.91016\n",
      "epoch[30/100] training loss 0.00346, training accuracy 0.89844\n",
      "epoch[30/100] training loss 0.00349, training accuracy 0.92188\n",
      "epoch[30/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[30/100] training loss 0.00333, training accuracy 0.92188\n",
      "epoch[30/100] training loss 0.00320, training accuracy 0.94141\n",
      "epoch[30/100] training loss 0.00331, training accuracy 0.90625\n",
      "epoch[30/100] training loss 0.00337, training accuracy 0.92969\n",
      "epoch[30/100] training loss 0.00367, training accuracy 0.87500\n",
      "epoch[30/100] training loss 0.00320, training accuracy 0.94141\n",
      "epoch[30/100] training loss 0.00360, training accuracy 0.87891\n",
      "epoch[30/100] training loss 0.00346, training accuracy 0.91797\n",
      "epoch[30/100] training loss 0.00314, training accuracy 0.05469\n",
      "[val] acc : 0.89074, loss : 0.88573\n",
      "best acc : 0.89074, best loss : 0.88533\n",
      "epoch[31/100] training loss 0.00349, training accuracy 0.89844\n",
      "epoch[31/100] training loss 0.00345, training accuracy 0.91016\n",
      "epoch[31/100] training loss 0.00356, training accuracy 0.89453\n",
      "epoch[31/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[31/100] training loss 0.00334, training accuracy 0.91016\n",
      "epoch[31/100] training loss 0.00342, training accuracy 0.87891\n",
      "epoch[31/100] training loss 0.00345, training accuracy 0.89844\n",
      "epoch[31/100] training loss 0.00338, training accuracy 0.89062\n",
      "epoch[31/100] training loss 0.00348, training accuracy 0.89062\n",
      "epoch[31/100] training loss 0.00344, training accuracy 0.88672\n",
      "epoch[31/100] training loss 0.00339, training accuracy 0.92578\n",
      "epoch[31/100] training loss 0.00353, training accuracy 0.90625\n",
      "epoch[31/100] training loss 0.00336, training accuracy 0.91797\n",
      "epoch[31/100] training loss 0.00334, training accuracy 0.89453\n",
      "epoch[31/100] training loss 0.00354, training accuracy 0.90625\n",
      "epoch[31/100] training loss 0.00329, training accuracy 0.91797\n",
      "epoch[31/100] training loss 0.00333, training accuracy 0.91406\n",
      "epoch[31/100] training loss 0.00341, training accuracy 0.90234\n",
      "epoch[31/100] training loss 0.00365, training accuracy 0.86328\n",
      "epoch[31/100] training loss 0.00330, training accuracy 0.92578\n",
      "epoch[31/100] training loss 0.00334, training accuracy 0.92188\n",
      "epoch[31/100] training loss 0.00349, training accuracy 0.90234\n",
      "epoch[31/100] training loss 0.00331, training accuracy 0.91797\n",
      "epoch[31/100] training loss 0.00324, training accuracy 0.94141\n",
      "epoch[31/100] training loss 0.00348, training accuracy 0.89453\n",
      "epoch[31/100] training loss 0.00350, training accuracy 0.90234\n",
      "epoch[31/100] training loss 0.00349, training accuracy 0.89062\n",
      "epoch[31/100] training loss 0.00332, training accuracy 0.91016\n",
      "epoch[31/100] training loss 0.00329, training accuracy 0.92969\n",
      "epoch[31/100] training loss 0.00339, training accuracy 0.91406\n",
      "epoch[31/100] training loss 0.00331, training accuracy 0.91016\n",
      "epoch[31/100] training loss 0.00322, training accuracy 0.92188\n",
      "epoch[31/100] training loss 0.00350, training accuracy 0.89453\n",
      "epoch[31/100] training loss 0.00352, training accuracy 0.90234\n",
      "epoch[31/100] training loss 0.00339, training accuracy 0.91016\n",
      "epoch[31/100] training loss 0.00322, training accuracy 0.93359\n",
      "epoch[31/100] training loss 0.00349, training accuracy 0.89453\n",
      "epoch[31/100] training loss 0.00323, training accuracy 0.94531\n",
      "epoch[31/100] training loss 0.00348, training accuracy 0.89453\n",
      "epoch[31/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[31/100] training loss 0.00339, training accuracy 0.92188\n",
      "epoch[31/100] training loss 0.00338, training accuracy 0.91797\n",
      "epoch[31/100] training loss 0.00340, training accuracy 0.89453\n",
      "epoch[31/100] training loss 0.00326, training accuracy 0.91406\n",
      "epoch[31/100] training loss 0.00337, training accuracy 0.92188\n",
      "epoch[31/100] training loss 0.00347, training accuracy 0.91406\n",
      "epoch[31/100] training loss 0.00325, training accuracy 0.92188\n",
      "epoch[31/100] training loss 0.00327, training accuracy 0.93359\n",
      "epoch[31/100] training loss 0.00327, training accuracy 0.92969\n",
      "epoch[31/100] training loss 0.00358, training accuracy 0.89062\n",
      "epoch[31/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[31/100] training loss 0.00345, training accuracy 0.90234\n",
      "epoch[31/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[31/100] training loss 0.00331, training accuracy 0.90234\n",
      "epoch[31/100] training loss 0.00343, training accuracy 0.90625\n",
      "epoch[31/100] training loss 0.00334, training accuracy 0.92188\n",
      "epoch[31/100] training loss 0.00345, training accuracy 0.91797\n",
      "epoch[31/100] training loss 0.00349, training accuracy 0.89844\n",
      "epoch[31/100] training loss 0.00353, training accuracy 0.89844\n",
      "epoch[31/100] training loss 0.00351, training accuracy 0.05469\n",
      "[val] acc : 0.89127, loss : 0.87746\n",
      "best acc : 0.89127, best loss : 0.87746\n",
      "epoch[32/100] training loss 0.00331, training accuracy 0.93359\n",
      "epoch[32/100] training loss 0.00326, training accuracy 0.90625\n",
      "epoch[32/100] training loss 0.00327, training accuracy 0.90234\n",
      "epoch[32/100] training loss 0.00341, training accuracy 0.90234\n",
      "epoch[32/100] training loss 0.00342, training accuracy 0.91797\n",
      "epoch[32/100] training loss 0.00335, training accuracy 0.93359\n",
      "epoch[32/100] training loss 0.00347, training accuracy 0.91016\n",
      "epoch[32/100] training loss 0.00327, training accuracy 0.93359\n",
      "epoch[32/100] training loss 0.00340, training accuracy 0.89453\n",
      "epoch[32/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[32/100] training loss 0.00332, training accuracy 0.92188\n",
      "epoch[32/100] training loss 0.00334, training accuracy 0.91406\n",
      "epoch[32/100] training loss 0.00350, training accuracy 0.89453\n",
      "epoch[32/100] training loss 0.00345, training accuracy 0.91797\n",
      "epoch[32/100] training loss 0.00345, training accuracy 0.90234\n",
      "epoch[32/100] training loss 0.00340, training accuracy 0.91797\n",
      "epoch[32/100] training loss 0.00337, training accuracy 0.93359\n",
      "epoch[32/100] training loss 0.00350, training accuracy 0.90234\n",
      "epoch[32/100] training loss 0.00347, training accuracy 0.91016\n",
      "epoch[32/100] training loss 0.00339, training accuracy 0.91406\n",
      "epoch[32/100] training loss 0.00338, training accuracy 0.90625\n",
      "epoch[32/100] training loss 0.00362, training accuracy 0.89453\n",
      "epoch[32/100] training loss 0.00339, training accuracy 0.90625\n",
      "epoch[32/100] training loss 0.00344, training accuracy 0.88672\n",
      "epoch[32/100] training loss 0.00318, training accuracy 0.94141\n",
      "epoch[32/100] training loss 0.00348, training accuracy 0.90234\n",
      "epoch[32/100] training loss 0.00335, training accuracy 0.91016\n",
      "epoch[32/100] training loss 0.00349, training accuracy 0.91016\n",
      "epoch[32/100] training loss 0.00360, training accuracy 0.89844\n",
      "epoch[32/100] training loss 0.00345, training accuracy 0.91406\n",
      "epoch[32/100] training loss 0.00332, training accuracy 0.91797\n",
      "epoch[32/100] training loss 0.00352, training accuracy 0.89844\n",
      "epoch[32/100] training loss 0.00336, training accuracy 0.92969\n",
      "epoch[32/100] training loss 0.00348, training accuracy 0.90625\n",
      "epoch[32/100] training loss 0.00337, training accuracy 0.91406\n",
      "epoch[32/100] training loss 0.00336, training accuracy 0.91797\n",
      "epoch[32/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[32/100] training loss 0.00323, training accuracy 0.93750\n",
      "epoch[32/100] training loss 0.00328, training accuracy 0.91797\n",
      "epoch[32/100] training loss 0.00331, training accuracy 0.93359\n",
      "epoch[32/100] training loss 0.00358, training accuracy 0.90625\n",
      "epoch[32/100] training loss 0.00322, training accuracy 0.92578\n",
      "epoch[32/100] training loss 0.00347, training accuracy 0.91016\n",
      "epoch[32/100] training loss 0.00344, training accuracy 0.92578\n",
      "epoch[32/100] training loss 0.00335, training accuracy 0.91016\n",
      "epoch[32/100] training loss 0.00327, training accuracy 0.92188\n",
      "epoch[32/100] training loss 0.00332, training accuracy 0.91406\n",
      "epoch[32/100] training loss 0.00328, training accuracy 0.94141\n",
      "epoch[32/100] training loss 0.00332, training accuracy 0.91406\n",
      "epoch[32/100] training loss 0.00327, training accuracy 0.93750\n",
      "epoch[32/100] training loss 0.00350, training accuracy 0.88672\n",
      "epoch[32/100] training loss 0.00322, training accuracy 0.94922\n",
      "epoch[32/100] training loss 0.00330, training accuracy 0.92578\n",
      "epoch[32/100] training loss 0.00340, training accuracy 0.92188\n",
      "epoch[32/100] training loss 0.00333, training accuracy 0.91016\n",
      "epoch[32/100] training loss 0.00318, training accuracy 0.94922\n",
      "epoch[32/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[32/100] training loss 0.00335, training accuracy 0.92969\n",
      "epoch[32/100] training loss 0.00347, training accuracy 0.89844\n",
      "epoch[32/100] training loss 0.00362, training accuracy 0.05469\n",
      "[val] acc : 0.88730, loss : 0.87734\n",
      "best acc : 0.89127, best loss : 0.87734\n",
      "epoch[33/100] training loss 0.00334, training accuracy 0.91797\n",
      "epoch[33/100] training loss 0.00338, training accuracy 0.90625\n",
      "epoch[33/100] training loss 0.00331, training accuracy 0.91016\n",
      "epoch[33/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[33/100] training loss 0.00336, training accuracy 0.91406\n",
      "epoch[33/100] training loss 0.00335, training accuracy 0.91406\n",
      "epoch[33/100] training loss 0.00347, training accuracy 0.89844\n",
      "epoch[33/100] training loss 0.00335, training accuracy 0.91797\n",
      "epoch[33/100] training loss 0.00328, training accuracy 0.94141\n",
      "epoch[33/100] training loss 0.00343, training accuracy 0.90625\n",
      "epoch[33/100] training loss 0.00340, training accuracy 0.91016\n",
      "epoch[33/100] training loss 0.00329, training accuracy 0.91406\n",
      "epoch[33/100] training loss 0.00321, training accuracy 0.92578\n",
      "epoch[33/100] training loss 0.00336, training accuracy 0.91797\n",
      "epoch[33/100] training loss 0.00335, training accuracy 0.90625\n",
      "epoch[33/100] training loss 0.00332, training accuracy 0.90625\n",
      "epoch[33/100] training loss 0.00341, training accuracy 0.91406\n",
      "epoch[33/100] training loss 0.00348, training accuracy 0.89062\n",
      "epoch[33/100] training loss 0.00329, training accuracy 0.93750\n",
      "epoch[33/100] training loss 0.00341, training accuracy 0.90625\n",
      "epoch[33/100] training loss 0.00321, training accuracy 0.92578\n",
      "epoch[33/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[33/100] training loss 0.00342, training accuracy 0.91406\n",
      "epoch[33/100] training loss 0.00343, training accuracy 0.90234\n",
      "epoch[33/100] training loss 0.00339, training accuracy 0.92969\n",
      "epoch[33/100] training loss 0.00336, training accuracy 0.91016\n",
      "epoch[33/100] training loss 0.00348, training accuracy 0.89453\n",
      "epoch[33/100] training loss 0.00345, training accuracy 0.89062\n",
      "epoch[33/100] training loss 0.00327, training accuracy 0.91406\n",
      "epoch[33/100] training loss 0.00333, training accuracy 0.94922\n",
      "epoch[33/100] training loss 0.00353, training accuracy 0.89062\n",
      "epoch[33/100] training loss 0.00353, training accuracy 0.90625\n",
      "epoch[33/100] training loss 0.00325, training accuracy 0.93359\n",
      "epoch[33/100] training loss 0.00326, training accuracy 0.92188\n",
      "epoch[33/100] training loss 0.00335, training accuracy 0.92578\n",
      "epoch[33/100] training loss 0.00334, training accuracy 0.90625\n",
      "epoch[33/100] training loss 0.00337, training accuracy 0.90625\n",
      "epoch[33/100] training loss 0.00345, training accuracy 0.89062\n",
      "epoch[33/100] training loss 0.00345, training accuracy 0.88281\n",
      "epoch[33/100] training loss 0.00342, training accuracy 0.92188\n",
      "epoch[33/100] training loss 0.00333, training accuracy 0.92969\n",
      "epoch[33/100] training loss 0.00344, training accuracy 0.91797\n",
      "epoch[33/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[33/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[33/100] training loss 0.00354, training accuracy 0.87109\n",
      "epoch[33/100] training loss 0.00336, training accuracy 0.93359\n",
      "epoch[33/100] training loss 0.00325, training accuracy 0.91406\n",
      "epoch[33/100] training loss 0.00318, training accuracy 0.94922\n",
      "epoch[33/100] training loss 0.00323, training accuracy 0.91797\n",
      "epoch[33/100] training loss 0.00343, training accuracy 0.89062\n",
      "epoch[33/100] training loss 0.00318, training accuracy 0.94922\n",
      "epoch[33/100] training loss 0.00342, training accuracy 0.91406\n",
      "epoch[33/100] training loss 0.00351, training accuracy 0.89453\n",
      "epoch[33/100] training loss 0.00356, training accuracy 0.89062\n",
      "epoch[33/100] training loss 0.00328, training accuracy 0.89844\n",
      "epoch[33/100] training loss 0.00333, training accuracy 0.91406\n",
      "epoch[33/100] training loss 0.00353, training accuracy 0.89453\n",
      "epoch[33/100] training loss 0.00332, training accuracy 0.91797\n",
      "epoch[33/100] training loss 0.00343, training accuracy 0.90625\n",
      "epoch[33/100] training loss 0.00303, training accuracy 0.05859\n",
      "[val] acc : 0.90026, loss : 0.87166\n",
      "best acc : 0.90026, best loss : 0.87166\n",
      "epoch[34/100] training loss 0.00331, training accuracy 0.91016\n",
      "epoch[34/100] training loss 0.00330, training accuracy 0.93359\n",
      "epoch[34/100] training loss 0.00349, training accuracy 0.90625\n",
      "epoch[34/100] training loss 0.00344, training accuracy 0.90625\n",
      "epoch[34/100] training loss 0.00347, training accuracy 0.92578\n",
      "epoch[34/100] training loss 0.00333, training accuracy 0.93750\n",
      "epoch[34/100] training loss 0.00326, training accuracy 0.92578\n",
      "epoch[34/100] training loss 0.00348, training accuracy 0.89453\n",
      "epoch[34/100] training loss 0.00332, training accuracy 0.91797\n",
      "epoch[34/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[34/100] training loss 0.00335, training accuracy 0.90625\n",
      "epoch[34/100] training loss 0.00349, training accuracy 0.88672\n",
      "epoch[34/100] training loss 0.00363, training accuracy 0.89062\n",
      "epoch[34/100] training loss 0.00331, training accuracy 0.91016\n",
      "epoch[34/100] training loss 0.00341, training accuracy 0.91016\n",
      "epoch[34/100] training loss 0.00318, training accuracy 0.96484\n",
      "epoch[34/100] training loss 0.00340, training accuracy 0.90625\n",
      "epoch[34/100] training loss 0.00341, training accuracy 0.91797\n",
      "epoch[34/100] training loss 0.00350, training accuracy 0.89453\n",
      "epoch[34/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[34/100] training loss 0.00337, training accuracy 0.92188\n",
      "epoch[34/100] training loss 0.00329, training accuracy 0.91797\n",
      "epoch[34/100] training loss 0.00328, training accuracy 0.91797\n",
      "epoch[34/100] training loss 0.00343, training accuracy 0.90625\n",
      "epoch[34/100] training loss 0.00346, training accuracy 0.91406\n",
      "epoch[34/100] training loss 0.00329, training accuracy 0.92969\n",
      "epoch[34/100] training loss 0.00341, training accuracy 0.91016\n",
      "epoch[34/100] training loss 0.00329, training accuracy 0.92578\n",
      "epoch[34/100] training loss 0.00334, training accuracy 0.92578\n",
      "epoch[34/100] training loss 0.00336, training accuracy 0.90625\n",
      "epoch[34/100] training loss 0.00321, training accuracy 0.93359\n",
      "epoch[34/100] training loss 0.00324, training accuracy 0.91406\n",
      "epoch[34/100] training loss 0.00332, training accuracy 0.91016\n",
      "epoch[34/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[34/100] training loss 0.00320, training accuracy 0.94531\n",
      "epoch[34/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[34/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[34/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[34/100] training loss 0.00336, training accuracy 0.93359\n",
      "epoch[34/100] training loss 0.00333, training accuracy 0.91406\n",
      "epoch[34/100] training loss 0.00342, training accuracy 0.89844\n",
      "epoch[34/100] training loss 0.00333, training accuracy 0.92578\n",
      "epoch[34/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[34/100] training loss 0.00332, training accuracy 0.91797\n",
      "epoch[34/100] training loss 0.00331, training accuracy 0.90625\n",
      "epoch[34/100] training loss 0.00339, training accuracy 0.90234\n",
      "epoch[34/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[34/100] training loss 0.00347, training accuracy 0.91016\n",
      "epoch[34/100] training loss 0.00336, training accuracy 0.92578\n",
      "epoch[34/100] training loss 0.00327, training accuracy 0.92188\n",
      "epoch[34/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[34/100] training loss 0.00328, training accuracy 0.91406\n",
      "epoch[34/100] training loss 0.00330, training accuracy 0.91406\n",
      "epoch[34/100] training loss 0.00344, training accuracy 0.89453\n",
      "epoch[34/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[34/100] training loss 0.00337, training accuracy 0.94141\n",
      "epoch[34/100] training loss 0.00325, training accuracy 0.94922\n",
      "epoch[34/100] training loss 0.00347, training accuracy 0.90234\n",
      "epoch[34/100] training loss 0.00332, training accuracy 0.92188\n",
      "epoch[34/100] training loss 0.00289, training accuracy 0.06250\n",
      "[val] acc : 0.89656, loss : 0.87376\n",
      "best acc : 0.90026, best loss : 0.87166\n",
      "epoch[35/100] training loss 0.00338, training accuracy 0.90234\n",
      "epoch[35/100] training loss 0.00345, training accuracy 0.89453\n",
      "epoch[35/100] training loss 0.00350, training accuracy 0.88281\n",
      "epoch[35/100] training loss 0.00329, training accuracy 0.92188\n",
      "epoch[35/100] training loss 0.00348, training accuracy 0.89062\n",
      "epoch[35/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[35/100] training loss 0.00335, training accuracy 0.92969\n",
      "epoch[35/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[35/100] training loss 0.00335, training accuracy 0.91016\n",
      "epoch[35/100] training loss 0.00325, training accuracy 0.94531\n",
      "epoch[35/100] training loss 0.00336, training accuracy 0.91406\n",
      "epoch[35/100] training loss 0.00346, training accuracy 0.90625\n",
      "epoch[35/100] training loss 0.00332, training accuracy 0.93359\n",
      "epoch[35/100] training loss 0.00342, training accuracy 0.91406\n",
      "epoch[35/100] training loss 0.00351, training accuracy 0.88672\n",
      "epoch[35/100] training loss 0.00320, training accuracy 0.92969\n",
      "epoch[35/100] training loss 0.00342, training accuracy 0.91797\n",
      "epoch[35/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[35/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[35/100] training loss 0.00334, training accuracy 0.91797\n",
      "epoch[35/100] training loss 0.00330, training accuracy 0.91406\n",
      "epoch[35/100] training loss 0.00346, training accuracy 0.91406\n",
      "epoch[35/100] training loss 0.00325, training accuracy 0.94531\n",
      "epoch[35/100] training loss 0.00342, training accuracy 0.91016\n",
      "epoch[35/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[35/100] training loss 0.00329, training accuracy 0.92188\n",
      "epoch[35/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[35/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[35/100] training loss 0.00329, training accuracy 0.92188\n",
      "epoch[35/100] training loss 0.00326, training accuracy 0.94922\n",
      "epoch[35/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[35/100] training loss 0.00342, training accuracy 0.90625\n",
      "epoch[35/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[35/100] training loss 0.00326, training accuracy 0.94141\n",
      "epoch[35/100] training loss 0.00326, training accuracy 0.93750\n",
      "epoch[35/100] training loss 0.00325, training accuracy 0.92188\n",
      "epoch[35/100] training loss 0.00340, training accuracy 0.91797\n",
      "epoch[35/100] training loss 0.00335, training accuracy 0.92578\n",
      "epoch[35/100] training loss 0.00330, training accuracy 0.93750\n",
      "epoch[35/100] training loss 0.00333, training accuracy 0.91016\n",
      "epoch[35/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[35/100] training loss 0.00331, training accuracy 0.91016\n",
      "epoch[35/100] training loss 0.00344, training accuracy 0.91406\n",
      "epoch[35/100] training loss 0.00334, training accuracy 0.91406\n",
      "epoch[35/100] training loss 0.00328, training accuracy 0.92188\n",
      "epoch[35/100] training loss 0.00326, training accuracy 0.93359\n",
      "epoch[35/100] training loss 0.00323, training accuracy 0.93750\n",
      "epoch[35/100] training loss 0.00327, training accuracy 0.92969\n",
      "epoch[35/100] training loss 0.00327, training accuracy 0.94922\n",
      "epoch[35/100] training loss 0.00345, training accuracy 0.90625\n",
      "epoch[35/100] training loss 0.00343, training accuracy 0.90625\n",
      "epoch[35/100] training loss 0.00350, training accuracy 0.90625\n",
      "epoch[35/100] training loss 0.00342, training accuracy 0.90234\n",
      "epoch[35/100] training loss 0.00334, training accuracy 0.92969\n",
      "epoch[35/100] training loss 0.00330, training accuracy 0.93359\n",
      "epoch[35/100] training loss 0.00344, training accuracy 0.91016\n",
      "epoch[35/100] training loss 0.00328, training accuracy 0.94922\n",
      "epoch[35/100] training loss 0.00337, training accuracy 0.93359\n",
      "epoch[35/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[35/100] training loss 0.00388, training accuracy 0.05859\n",
      "[val] acc : 0.89735, loss : 0.87703\n",
      "best acc : 0.90026, best loss : 0.87166\n",
      "epoch[36/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[36/100] training loss 0.00342, training accuracy 0.91797\n",
      "epoch[36/100] training loss 0.00342, training accuracy 0.91016\n",
      "epoch[36/100] training loss 0.00322, training accuracy 0.92578\n",
      "epoch[36/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[36/100] training loss 0.00358, training accuracy 0.90234\n",
      "epoch[36/100] training loss 0.00335, training accuracy 0.91016\n",
      "epoch[36/100] training loss 0.00337, training accuracy 0.91016\n",
      "epoch[36/100] training loss 0.00339, training accuracy 0.91016\n",
      "epoch[36/100] training loss 0.00318, training accuracy 0.94531\n",
      "epoch[36/100] training loss 0.00326, training accuracy 0.93359\n",
      "epoch[36/100] training loss 0.00334, training accuracy 0.92578\n",
      "epoch[36/100] training loss 0.00346, training accuracy 0.92188\n",
      "epoch[36/100] training loss 0.00335, training accuracy 0.92188\n",
      "epoch[36/100] training loss 0.00337, training accuracy 0.91797\n",
      "epoch[36/100] training loss 0.00347, training accuracy 0.91016\n",
      "epoch[36/100] training loss 0.00345, training accuracy 0.89844\n",
      "epoch[36/100] training loss 0.00330, training accuracy 0.90234\n",
      "epoch[36/100] training loss 0.00334, training accuracy 0.92969\n",
      "epoch[36/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[36/100] training loss 0.00329, training accuracy 0.93359\n",
      "epoch[36/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[36/100] training loss 0.00322, training accuracy 0.94141\n",
      "epoch[36/100] training loss 0.00316, training accuracy 0.94531\n",
      "epoch[36/100] training loss 0.00320, training accuracy 0.95703\n",
      "epoch[36/100] training loss 0.00333, training accuracy 0.92969\n",
      "epoch[36/100] training loss 0.00337, training accuracy 0.92578\n",
      "epoch[36/100] training loss 0.00318, training accuracy 0.94141\n",
      "epoch[36/100] training loss 0.00332, training accuracy 0.94531\n",
      "epoch[36/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[36/100] training loss 0.00322, training accuracy 0.92188\n",
      "epoch[36/100] training loss 0.00319, training accuracy 0.94922\n",
      "epoch[36/100] training loss 0.00328, training accuracy 0.91406\n",
      "epoch[36/100] training loss 0.00341, training accuracy 0.87891\n",
      "epoch[36/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[36/100] training loss 0.00339, training accuracy 0.90234\n",
      "epoch[36/100] training loss 0.00344, training accuracy 0.89062\n",
      "epoch[36/100] training loss 0.00325, training accuracy 0.92578\n",
      "epoch[36/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[36/100] training loss 0.00329, training accuracy 0.91016\n",
      "epoch[36/100] training loss 0.00332, training accuracy 0.91797\n",
      "epoch[36/100] training loss 0.00328, training accuracy 0.92188\n",
      "epoch[36/100] training loss 0.00329, training accuracy 0.93359\n",
      "epoch[36/100] training loss 0.00338, training accuracy 0.92188\n",
      "epoch[36/100] training loss 0.00339, training accuracy 0.92578\n",
      "epoch[36/100] training loss 0.00320, training accuracy 0.93359\n",
      "epoch[36/100] training loss 0.00348, training accuracy 0.91406\n",
      "epoch[36/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[36/100] training loss 0.00338, training accuracy 0.90234\n",
      "epoch[36/100] training loss 0.00332, training accuracy 0.92578\n",
      "epoch[36/100] training loss 0.00346, training accuracy 0.90234\n",
      "epoch[36/100] training loss 0.00327, training accuracy 0.91797\n",
      "epoch[36/100] training loss 0.00337, training accuracy 0.92188\n",
      "epoch[36/100] training loss 0.00345, training accuracy 0.91016\n",
      "epoch[36/100] training loss 0.00335, training accuracy 0.91016\n",
      "epoch[36/100] training loss 0.00323, training accuracy 0.92969\n",
      "epoch[36/100] training loss 0.00325, training accuracy 0.93750\n",
      "epoch[36/100] training loss 0.00327, training accuracy 0.91016\n",
      "epoch[36/100] training loss 0.00327, training accuracy 0.94141\n",
      "epoch[36/100] training loss 0.00340, training accuracy 0.05859\n",
      "[val] acc : 0.90212, loss : 0.87318\n",
      "best acc : 0.90212, best loss : 0.87166\n",
      "epoch[37/100] training loss 0.00332, training accuracy 0.92188\n",
      "epoch[37/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[37/100] training loss 0.00330, training accuracy 0.93750\n",
      "epoch[37/100] training loss 0.00341, training accuracy 0.90234\n",
      "epoch[37/100] training loss 0.00333, training accuracy 0.89062\n",
      "epoch[37/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[37/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[37/100] training loss 0.00347, training accuracy 0.89453\n",
      "epoch[37/100] training loss 0.00331, training accuracy 0.92969\n",
      "epoch[37/100] training loss 0.00353, training accuracy 0.89062\n",
      "epoch[37/100] training loss 0.00360, training accuracy 0.91406\n",
      "epoch[37/100] training loss 0.00341, training accuracy 0.90625\n",
      "epoch[37/100] training loss 0.00327, training accuracy 0.93359\n",
      "epoch[37/100] training loss 0.00326, training accuracy 0.93750\n",
      "epoch[37/100] training loss 0.00336, training accuracy 0.90625\n",
      "epoch[37/100] training loss 0.00334, training accuracy 0.92188\n",
      "epoch[37/100] training loss 0.00329, training accuracy 0.92188\n",
      "epoch[37/100] training loss 0.00337, training accuracy 0.89844\n",
      "epoch[37/100] training loss 0.00339, training accuracy 0.91016\n",
      "epoch[37/100] training loss 0.00325, training accuracy 0.91797\n",
      "epoch[37/100] training loss 0.00336, training accuracy 0.92188\n",
      "epoch[37/100] training loss 0.00318, training accuracy 0.91797\n",
      "epoch[37/100] training loss 0.00343, training accuracy 0.89844\n",
      "epoch[37/100] training loss 0.00324, training accuracy 0.93750\n",
      "epoch[37/100] training loss 0.00329, training accuracy 0.92578\n",
      "epoch[37/100] training loss 0.00332, training accuracy 0.93750\n",
      "epoch[37/100] training loss 0.00340, training accuracy 0.89453\n",
      "epoch[37/100] training loss 0.00346, training accuracy 0.90625\n",
      "epoch[37/100] training loss 0.00330, training accuracy 0.92188\n",
      "epoch[37/100] training loss 0.00345, training accuracy 0.89844\n",
      "epoch[37/100] training loss 0.00331, training accuracy 0.92188\n",
      "epoch[37/100] training loss 0.00329, training accuracy 0.92969\n",
      "epoch[37/100] training loss 0.00332, training accuracy 0.92188\n",
      "epoch[37/100] training loss 0.00339, training accuracy 0.92188\n",
      "epoch[37/100] training loss 0.00330, training accuracy 0.93750\n",
      "epoch[37/100] training loss 0.00338, training accuracy 0.91406\n",
      "epoch[37/100] training loss 0.00315, training accuracy 0.94922\n",
      "epoch[37/100] training loss 0.00325, training accuracy 0.91797\n",
      "epoch[37/100] training loss 0.00322, training accuracy 0.92578\n",
      "epoch[37/100] training loss 0.00337, training accuracy 0.92578\n",
      "epoch[37/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[37/100] training loss 0.00323, training accuracy 0.92188\n",
      "epoch[37/100] training loss 0.00335, training accuracy 0.90234\n",
      "epoch[37/100] training loss 0.00320, training accuracy 0.92969\n",
      "epoch[37/100] training loss 0.00350, training accuracy 0.89062\n",
      "epoch[37/100] training loss 0.00340, training accuracy 0.91016\n",
      "epoch[37/100] training loss 0.00318, training accuracy 0.93359\n",
      "epoch[37/100] training loss 0.00331, training accuracy 0.92969\n",
      "epoch[37/100] training loss 0.00334, training accuracy 0.92969\n",
      "epoch[37/100] training loss 0.00329, training accuracy 0.93359\n",
      "epoch[37/100] training loss 0.00327, training accuracy 0.93750\n",
      "epoch[37/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[37/100] training loss 0.00341, training accuracy 0.91406\n",
      "epoch[37/100] training loss 0.00328, training accuracy 0.93750\n",
      "epoch[37/100] training loss 0.00327, training accuracy 0.93359\n",
      "epoch[37/100] training loss 0.00331, training accuracy 0.92969\n",
      "epoch[37/100] training loss 0.00329, training accuracy 0.94141\n",
      "epoch[37/100] training loss 0.00340, training accuracy 0.89844\n",
      "epoch[37/100] training loss 0.00322, training accuracy 0.94531\n",
      "epoch[37/100] training loss 0.00284, training accuracy 0.06250\n",
      "[val] acc : 0.89921, loss : 0.86336\n",
      "best acc : 0.90212, best loss : 0.86336\n",
      "epoch[38/100] training loss 0.00334, training accuracy 0.91797\n",
      "epoch[38/100] training loss 0.00332, training accuracy 0.93359\n",
      "epoch[38/100] training loss 0.00331, training accuracy 0.92188\n",
      "epoch[38/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[38/100] training loss 0.00322, training accuracy 0.94141\n",
      "epoch[38/100] training loss 0.00332, training accuracy 0.92578\n",
      "epoch[38/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[38/100] training loss 0.00335, training accuracy 0.92188\n",
      "epoch[38/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[38/100] training loss 0.00339, training accuracy 0.89062\n",
      "epoch[38/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[38/100] training loss 0.00323, training accuracy 0.92578\n",
      "epoch[38/100] training loss 0.00337, training accuracy 0.89844\n",
      "epoch[38/100] training loss 0.00332, training accuracy 0.91016\n",
      "epoch[38/100] training loss 0.00337, training accuracy 0.90234\n",
      "epoch[38/100] training loss 0.00323, training accuracy 0.92578\n",
      "epoch[38/100] training loss 0.00325, training accuracy 0.91797\n",
      "epoch[38/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[38/100] training loss 0.00340, training accuracy 0.91406\n",
      "epoch[38/100] training loss 0.00323, training accuracy 0.91406\n",
      "epoch[38/100] training loss 0.00327, training accuracy 0.93750\n",
      "epoch[38/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[38/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[38/100] training loss 0.00333, training accuracy 0.92578\n",
      "epoch[38/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[38/100] training loss 0.00324, training accuracy 0.92578\n",
      "epoch[38/100] training loss 0.00322, training accuracy 0.92578\n",
      "epoch[38/100] training loss 0.00329, training accuracy 0.92969\n",
      "epoch[38/100] training loss 0.00331, training accuracy 0.91016\n",
      "epoch[38/100] training loss 0.00325, training accuracy 0.92578\n",
      "epoch[38/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[38/100] training loss 0.00327, training accuracy 0.93359\n",
      "epoch[38/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[38/100] training loss 0.00342, training accuracy 0.91016\n",
      "epoch[38/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[38/100] training loss 0.00337, training accuracy 0.91406\n",
      "epoch[38/100] training loss 0.00335, training accuracy 0.92188\n",
      "epoch[38/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[38/100] training loss 0.00330, training accuracy 0.91406\n",
      "epoch[38/100] training loss 0.00325, training accuracy 0.91406\n",
      "epoch[38/100] training loss 0.00329, training accuracy 0.92188\n",
      "epoch[38/100] training loss 0.00320, training accuracy 0.92578\n",
      "epoch[38/100] training loss 0.00337, training accuracy 0.90625\n",
      "epoch[38/100] training loss 0.00327, training accuracy 0.93359\n",
      "epoch[38/100] training loss 0.00345, training accuracy 0.93359\n",
      "epoch[38/100] training loss 0.00324, training accuracy 0.93750\n",
      "epoch[38/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[38/100] training loss 0.00329, training accuracy 0.92969\n",
      "epoch[38/100] training loss 0.00329, training accuracy 0.91016\n",
      "epoch[38/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[38/100] training loss 0.00343, training accuracy 0.89453\n",
      "epoch[38/100] training loss 0.00336, training accuracy 0.89844\n",
      "epoch[38/100] training loss 0.00323, training accuracy 0.94531\n",
      "epoch[38/100] training loss 0.00348, training accuracy 0.89453\n",
      "epoch[38/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[38/100] training loss 0.00336, training accuracy 0.92578\n",
      "epoch[38/100] training loss 0.00321, training accuracy 0.93359\n",
      "epoch[38/100] training loss 0.00342, training accuracy 0.93750\n",
      "epoch[38/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[38/100] training loss 0.00339, training accuracy 0.05859\n",
      "[val] acc : 0.90026, loss : 0.86341\n",
      "best acc : 0.90212, best loss : 0.86336\n",
      "epoch[39/100] training loss 0.00325, training accuracy 0.94141\n",
      "epoch[39/100] training loss 0.00329, training accuracy 0.89844\n",
      "epoch[39/100] training loss 0.00329, training accuracy 0.90234\n",
      "epoch[39/100] training loss 0.00343, training accuracy 0.90234\n",
      "epoch[39/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[39/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[39/100] training loss 0.00326, training accuracy 0.94531\n",
      "epoch[39/100] training loss 0.00335, training accuracy 0.90234\n",
      "epoch[39/100] training loss 0.00321, training accuracy 0.92578\n",
      "epoch[39/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[39/100] training loss 0.00334, training accuracy 0.90625\n",
      "epoch[39/100] training loss 0.00335, training accuracy 0.91406\n",
      "epoch[39/100] training loss 0.00322, training accuracy 0.92188\n",
      "epoch[39/100] training loss 0.00339, training accuracy 0.91016\n",
      "epoch[39/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[39/100] training loss 0.00332, training accuracy 0.93359\n",
      "epoch[39/100] training loss 0.00344, training accuracy 0.90625\n",
      "epoch[39/100] training loss 0.00331, training accuracy 0.91797\n",
      "epoch[39/100] training loss 0.00348, training accuracy 0.89844\n",
      "epoch[39/100] training loss 0.00329, training accuracy 0.91406\n",
      "epoch[39/100] training loss 0.00318, training accuracy 0.95703\n",
      "epoch[39/100] training loss 0.00333, training accuracy 0.90625\n",
      "epoch[39/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[39/100] training loss 0.00326, training accuracy 0.92578\n",
      "epoch[39/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[39/100] training loss 0.00325, training accuracy 0.92578\n",
      "epoch[39/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[39/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[39/100] training loss 0.00331, training accuracy 0.93359\n",
      "epoch[39/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[39/100] training loss 0.00329, training accuracy 0.93359\n",
      "epoch[39/100] training loss 0.00316, training accuracy 0.96484\n",
      "epoch[39/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[39/100] training loss 0.00338, training accuracy 0.91797\n",
      "epoch[39/100] training loss 0.00337, training accuracy 0.89844\n",
      "epoch[39/100] training loss 0.00338, training accuracy 0.90234\n",
      "epoch[39/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[39/100] training loss 0.00334, training accuracy 0.90234\n",
      "epoch[39/100] training loss 0.00318, training accuracy 0.92578\n",
      "epoch[39/100] training loss 0.00334, training accuracy 0.90625\n",
      "epoch[39/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[39/100] training loss 0.00316, training accuracy 0.95703\n",
      "epoch[39/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[39/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[39/100] training loss 0.00327, training accuracy 0.93359\n",
      "epoch[39/100] training loss 0.00343, training accuracy 0.91406\n",
      "epoch[39/100] training loss 0.00343, training accuracy 0.88672\n",
      "epoch[39/100] training loss 0.00325, training accuracy 0.93359\n",
      "epoch[39/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[39/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[39/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[39/100] training loss 0.00337, training accuracy 0.91406\n",
      "epoch[39/100] training loss 0.00317, training accuracy 0.94922\n",
      "epoch[39/100] training loss 0.00330, training accuracy 0.93750\n",
      "epoch[39/100] training loss 0.00325, training accuracy 0.93750\n",
      "epoch[39/100] training loss 0.00337, training accuracy 0.91797\n",
      "epoch[39/100] training loss 0.00318, training accuracy 0.95312\n",
      "epoch[39/100] training loss 0.00319, training accuracy 0.91016\n",
      "epoch[39/100] training loss 0.00332, training accuracy 0.94141\n",
      "epoch[39/100] training loss 0.00360, training accuracy 0.05078\n",
      "[val] acc : 0.90106, loss : 0.86125\n",
      "best acc : 0.90212, best loss : 0.86125\n",
      "epoch[40/100] training loss 0.00327, training accuracy 0.91016\n",
      "epoch[40/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[40/100] training loss 0.00331, training accuracy 0.92188\n",
      "epoch[40/100] training loss 0.00332, training accuracy 0.94531\n",
      "epoch[40/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[40/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[40/100] training loss 0.00331, training accuracy 0.93750\n",
      "epoch[40/100] training loss 0.00329, training accuracy 0.94141\n",
      "epoch[40/100] training loss 0.00317, training accuracy 0.94922\n",
      "epoch[40/100] training loss 0.00333, training accuracy 0.92188\n",
      "epoch[40/100] training loss 0.00325, training accuracy 0.92578\n",
      "epoch[40/100] training loss 0.00336, training accuracy 0.91016\n",
      "epoch[40/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[40/100] training loss 0.00335, training accuracy 0.91797\n",
      "epoch[40/100] training loss 0.00331, training accuracy 0.91797\n",
      "epoch[40/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[40/100] training loss 0.00326, training accuracy 0.93359\n",
      "epoch[40/100] training loss 0.00303, training accuracy 0.97266\n",
      "epoch[40/100] training loss 0.00352, training accuracy 0.92188\n",
      "epoch[40/100] training loss 0.00323, training accuracy 0.94922\n",
      "epoch[40/100] training loss 0.00327, training accuracy 0.93359\n",
      "epoch[40/100] training loss 0.00347, training accuracy 0.89062\n",
      "epoch[40/100] training loss 0.00330, training accuracy 0.91016\n",
      "epoch[40/100] training loss 0.00327, training accuracy 0.92578\n",
      "epoch[40/100] training loss 0.00324, training accuracy 0.91406\n",
      "epoch[40/100] training loss 0.00329, training accuracy 0.90625\n",
      "epoch[40/100] training loss 0.00322, training accuracy 0.93750\n",
      "epoch[40/100] training loss 0.00332, training accuracy 0.92969\n",
      "epoch[40/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[40/100] training loss 0.00344, training accuracy 0.91797\n",
      "epoch[40/100] training loss 0.00329, training accuracy 0.93359\n",
      "epoch[40/100] training loss 0.00329, training accuracy 0.92969\n",
      "epoch[40/100] training loss 0.00331, training accuracy 0.91406\n",
      "epoch[40/100] training loss 0.00329, training accuracy 0.92969\n",
      "epoch[40/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[40/100] training loss 0.00341, training accuracy 0.89062\n",
      "epoch[40/100] training loss 0.00321, training accuracy 0.94531\n",
      "epoch[40/100] training loss 0.00327, training accuracy 0.94141\n",
      "epoch[40/100] training loss 0.00320, training accuracy 0.93750\n",
      "epoch[40/100] training loss 0.00342, training accuracy 0.91016\n",
      "epoch[40/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[40/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[40/100] training loss 0.00339, training accuracy 0.91797\n",
      "epoch[40/100] training loss 0.00326, training accuracy 0.91406\n",
      "epoch[40/100] training loss 0.00333, training accuracy 0.92578\n",
      "epoch[40/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[40/100] training loss 0.00332, training accuracy 0.92969\n",
      "epoch[40/100] training loss 0.00336, training accuracy 0.91797\n",
      "epoch[40/100] training loss 0.00323, training accuracy 0.93750\n",
      "epoch[40/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[40/100] training loss 0.00330, training accuracy 0.92578\n",
      "epoch[40/100] training loss 0.00333, training accuracy 0.92188\n",
      "epoch[40/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[40/100] training loss 0.00341, training accuracy 0.90234\n",
      "epoch[40/100] training loss 0.00320, training accuracy 0.94922\n",
      "epoch[40/100] training loss 0.00334, training accuracy 0.91797\n",
      "epoch[40/100] training loss 0.00331, training accuracy 0.89844\n",
      "epoch[40/100] training loss 0.00320, training accuracy 0.94141\n",
      "epoch[40/100] training loss 0.00316, training accuracy 0.95703\n",
      "epoch[40/100] training loss 0.00369, training accuracy 0.05078\n",
      "[val] acc : 0.89947, loss : 0.86293\n",
      "best acc : 0.90212, best loss : 0.86125\n",
      "epoch[41/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[41/100] training loss 0.00336, training accuracy 0.89062\n",
      "epoch[41/100] training loss 0.00338, training accuracy 0.90625\n",
      "epoch[41/100] training loss 0.00350, training accuracy 0.91797\n",
      "epoch[41/100] training loss 0.00337, training accuracy 0.91016\n",
      "epoch[41/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[41/100] training loss 0.00339, training accuracy 0.89844\n",
      "epoch[41/100] training loss 0.00334, training accuracy 0.93359\n",
      "epoch[41/100] training loss 0.00335, training accuracy 0.92969\n",
      "epoch[41/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[41/100] training loss 0.00340, training accuracy 0.92969\n",
      "epoch[41/100] training loss 0.00327, training accuracy 0.92578\n",
      "epoch[41/100] training loss 0.00323, training accuracy 0.92578\n",
      "epoch[41/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[41/100] training loss 0.00317, training accuracy 0.92578\n",
      "epoch[41/100] training loss 0.00331, training accuracy 0.92969\n",
      "epoch[41/100] training loss 0.00336, training accuracy 0.91406\n",
      "epoch[41/100] training loss 0.00322, training accuracy 0.94141\n",
      "epoch[41/100] training loss 0.00325, training accuracy 0.93359\n",
      "epoch[41/100] training loss 0.00317, training accuracy 0.96094\n",
      "epoch[41/100] training loss 0.00332, training accuracy 0.91797\n",
      "epoch[41/100] training loss 0.00336, training accuracy 0.90234\n",
      "epoch[41/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[41/100] training loss 0.00340, training accuracy 0.90234\n",
      "epoch[41/100] training loss 0.00325, training accuracy 0.93750\n",
      "epoch[41/100] training loss 0.00320, training accuracy 0.94922\n",
      "epoch[41/100] training loss 0.00323, training accuracy 0.91016\n",
      "epoch[41/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[41/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[41/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[41/100] training loss 0.00332, training accuracy 0.91406\n",
      "epoch[41/100] training loss 0.00331, training accuracy 0.91797\n",
      "epoch[41/100] training loss 0.00313, training accuracy 0.95703\n",
      "epoch[41/100] training loss 0.00335, training accuracy 0.91016\n",
      "epoch[41/100] training loss 0.00333, training accuracy 0.90625\n",
      "epoch[41/100] training loss 0.00320, training accuracy 0.92188\n",
      "epoch[41/100] training loss 0.00320, training accuracy 0.92969\n",
      "epoch[41/100] training loss 0.00333, training accuracy 0.91406\n",
      "epoch[41/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[41/100] training loss 0.00317, training accuracy 0.96094\n",
      "epoch[41/100] training loss 0.00336, training accuracy 0.92578\n",
      "epoch[41/100] training loss 0.00328, training accuracy 0.91406\n",
      "epoch[41/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[41/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[41/100] training loss 0.00325, training accuracy 0.92188\n",
      "epoch[41/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[41/100] training loss 0.00321, training accuracy 0.92969\n",
      "epoch[41/100] training loss 0.00313, training accuracy 0.93359\n",
      "epoch[41/100] training loss 0.00323, training accuracy 0.93750\n",
      "epoch[41/100] training loss 0.00322, training accuracy 0.94141\n",
      "epoch[41/100] training loss 0.00317, training accuracy 0.94922\n",
      "epoch[41/100] training loss 0.00319, training accuracy 0.94531\n",
      "epoch[41/100] training loss 0.00326, training accuracy 0.93359\n",
      "epoch[41/100] training loss 0.00332, training accuracy 0.93359\n",
      "epoch[41/100] training loss 0.00322, training accuracy 0.92578\n",
      "epoch[41/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[41/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[41/100] training loss 0.00333, training accuracy 0.92578\n",
      "epoch[41/100] training loss 0.00308, training accuracy 0.96484\n",
      "epoch[41/100] training loss 0.00309, training accuracy 0.05859\n",
      "[val] acc : 0.90529, loss : 0.85683\n",
      "best acc : 0.90529, best loss : 0.85683\n",
      "epoch[42/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[42/100] training loss 0.00307, training accuracy 0.93359\n",
      "epoch[42/100] training loss 0.00330, training accuracy 0.92188\n",
      "epoch[42/100] training loss 0.00336, training accuracy 0.91406\n",
      "epoch[42/100] training loss 0.00332, training accuracy 0.92969\n",
      "epoch[42/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[42/100] training loss 0.00329, training accuracy 0.91406\n",
      "epoch[42/100] training loss 0.00313, training accuracy 0.95312\n",
      "epoch[42/100] training loss 0.00335, training accuracy 0.91797\n",
      "epoch[42/100] training loss 0.00325, training accuracy 0.94141\n",
      "epoch[42/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[42/100] training loss 0.00326, training accuracy 0.93359\n",
      "epoch[42/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[42/100] training loss 0.00339, training accuracy 0.92578\n",
      "epoch[42/100] training loss 0.00331, training accuracy 0.93359\n",
      "epoch[42/100] training loss 0.00329, training accuracy 0.90625\n",
      "epoch[42/100] training loss 0.00341, training accuracy 0.89062\n",
      "epoch[42/100] training loss 0.00337, training accuracy 0.91016\n",
      "epoch[42/100] training loss 0.00328, training accuracy 0.91406\n",
      "epoch[42/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[42/100] training loss 0.00330, training accuracy 0.92188\n",
      "epoch[42/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[42/100] training loss 0.00320, training accuracy 0.92578\n",
      "epoch[42/100] training loss 0.00341, training accuracy 0.91406\n",
      "epoch[42/100] training loss 0.00302, training accuracy 0.97266\n",
      "epoch[42/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[42/100] training loss 0.00318, training accuracy 0.94141\n",
      "epoch[42/100] training loss 0.00319, training accuracy 0.92578\n",
      "epoch[42/100] training loss 0.00320, training accuracy 0.94922\n",
      "epoch[42/100] training loss 0.00300, training accuracy 0.97266\n",
      "epoch[42/100] training loss 0.00317, training accuracy 0.94922\n",
      "epoch[42/100] training loss 0.00318, training accuracy 0.94922\n",
      "epoch[42/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[42/100] training loss 0.00302, training accuracy 0.97266\n",
      "epoch[42/100] training loss 0.00328, training accuracy 0.91016\n",
      "epoch[42/100] training loss 0.00324, training accuracy 0.92578\n",
      "epoch[42/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[42/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[42/100] training loss 0.00325, training accuracy 0.92578\n",
      "epoch[42/100] training loss 0.00329, training accuracy 0.92578\n",
      "epoch[42/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[42/100] training loss 0.00327, training accuracy 0.92578\n",
      "epoch[42/100] training loss 0.00326, training accuracy 0.91797\n",
      "epoch[42/100] training loss 0.00330, training accuracy 0.91406\n",
      "epoch[42/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[42/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[42/100] training loss 0.00332, training accuracy 0.91797\n",
      "epoch[42/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[42/100] training loss 0.00336, training accuracy 0.90234\n",
      "epoch[42/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[42/100] training loss 0.00321, training accuracy 0.93359\n",
      "epoch[42/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[42/100] training loss 0.00329, training accuracy 0.92578\n",
      "epoch[42/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[42/100] training loss 0.00331, training accuracy 0.93359\n",
      "epoch[42/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[42/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[42/100] training loss 0.00321, training accuracy 0.92969\n",
      "epoch[42/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[42/100] training loss 0.00312, training accuracy 0.05859\n",
      "[val] acc : 0.90556, loss : 0.85131\n",
      "best acc : 0.90556, best loss : 0.85131\n",
      "epoch[43/100] training loss 0.00328, training accuracy 0.91797\n",
      "epoch[43/100] training loss 0.00339, training accuracy 0.90234\n",
      "epoch[43/100] training loss 0.00342, training accuracy 0.92578\n",
      "epoch[43/100] training loss 0.00330, training accuracy 0.93750\n",
      "epoch[43/100] training loss 0.00317, training accuracy 0.95312\n",
      "epoch[43/100] training loss 0.00323, training accuracy 0.92188\n",
      "epoch[43/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[43/100] training loss 0.00331, training accuracy 0.91797\n",
      "epoch[43/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[43/100] training loss 0.00322, training accuracy 0.94531\n",
      "epoch[43/100] training loss 0.00314, training accuracy 0.95312\n",
      "epoch[43/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[43/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[43/100] training loss 0.00316, training accuracy 0.92969\n",
      "epoch[43/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[43/100] training loss 0.00329, training accuracy 0.93359\n",
      "epoch[43/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[43/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[43/100] training loss 0.00336, training accuracy 0.91797\n",
      "epoch[43/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[43/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[43/100] training loss 0.00320, training accuracy 0.93750\n",
      "epoch[43/100] training loss 0.00326, training accuracy 0.94141\n",
      "epoch[43/100] training loss 0.00325, training accuracy 0.91406\n",
      "epoch[43/100] training loss 0.00314, training accuracy 0.95312\n",
      "epoch[43/100] training loss 0.00322, training accuracy 0.93359\n",
      "epoch[43/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[43/100] training loss 0.00330, training accuracy 0.93359\n",
      "epoch[43/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[43/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[43/100] training loss 0.00331, training accuracy 0.92188\n",
      "epoch[43/100] training loss 0.00318, training accuracy 0.94531\n",
      "epoch[43/100] training loss 0.00318, training accuracy 0.94531\n",
      "epoch[43/100] training loss 0.00322, training accuracy 0.92188\n",
      "epoch[43/100] training loss 0.00333, training accuracy 0.90625\n",
      "epoch[43/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[43/100] training loss 0.00313, training accuracy 0.95703\n",
      "epoch[43/100] training loss 0.00333, training accuracy 0.90234\n",
      "epoch[43/100] training loss 0.00319, training accuracy 0.92969\n",
      "epoch[43/100] training loss 0.00327, training accuracy 0.92188\n",
      "epoch[43/100] training loss 0.00337, training accuracy 0.91406\n",
      "epoch[43/100] training loss 0.00318, training accuracy 0.95312\n",
      "epoch[43/100] training loss 0.00336, training accuracy 0.90234\n",
      "epoch[43/100] training loss 0.00323, training accuracy 0.92188\n",
      "epoch[43/100] training loss 0.00325, training accuracy 0.91797\n",
      "epoch[43/100] training loss 0.00329, training accuracy 0.92969\n",
      "epoch[43/100] training loss 0.00321, training accuracy 0.92188\n",
      "epoch[43/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[43/100] training loss 0.00322, training accuracy 0.93750\n",
      "epoch[43/100] training loss 0.00335, training accuracy 0.91016\n",
      "epoch[43/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[43/100] training loss 0.00317, training accuracy 0.95703\n",
      "epoch[43/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[43/100] training loss 0.00317, training accuracy 0.92578\n",
      "epoch[43/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[43/100] training loss 0.00339, training accuracy 0.89844\n",
      "epoch[43/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[43/100] training loss 0.00336, training accuracy 0.93750\n",
      "epoch[43/100] training loss 0.00313, training accuracy 0.95703\n",
      "epoch[43/100] training loss 0.00386, training accuracy 0.05469\n",
      "[val] acc : 0.90503, loss : 0.84726\n",
      "best acc : 0.90556, best loss : 0.84726\n",
      "epoch[44/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[44/100] training loss 0.00333, training accuracy 0.92188\n",
      "epoch[44/100] training loss 0.00329, training accuracy 0.92188\n",
      "epoch[44/100] training loss 0.00317, training accuracy 0.94922\n",
      "epoch[44/100] training loss 0.00322, training accuracy 0.95703\n",
      "epoch[44/100] training loss 0.00318, training accuracy 0.94531\n",
      "epoch[44/100] training loss 0.00313, training accuracy 0.95703\n",
      "epoch[44/100] training loss 0.00322, training accuracy 0.95312\n",
      "epoch[44/100] training loss 0.00314, training accuracy 0.95703\n",
      "epoch[44/100] training loss 0.00335, training accuracy 0.93359\n",
      "epoch[44/100] training loss 0.00334, training accuracy 0.91797\n",
      "epoch[44/100] training loss 0.00327, training accuracy 0.92969\n",
      "epoch[44/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[44/100] training loss 0.00320, training accuracy 0.92969\n",
      "epoch[44/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[44/100] training loss 0.00324, training accuracy 0.93750\n",
      "epoch[44/100] training loss 0.00329, training accuracy 0.91797\n",
      "epoch[44/100] training loss 0.00331, training accuracy 0.91797\n",
      "epoch[44/100] training loss 0.00320, training accuracy 0.94922\n",
      "epoch[44/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[44/100] training loss 0.00323, training accuracy 0.91016\n",
      "epoch[44/100] training loss 0.00312, training accuracy 0.95703\n",
      "epoch[44/100] training loss 0.00310, training accuracy 0.96094\n",
      "epoch[44/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[44/100] training loss 0.00320, training accuracy 0.92969\n",
      "epoch[44/100] training loss 0.00327, training accuracy 0.93359\n",
      "epoch[44/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[44/100] training loss 0.00328, training accuracy 0.91406\n",
      "epoch[44/100] training loss 0.00304, training accuracy 0.96875\n",
      "epoch[44/100] training loss 0.00342, training accuracy 0.91797\n",
      "epoch[44/100] training loss 0.00350, training accuracy 0.90234\n",
      "epoch[44/100] training loss 0.00337, training accuracy 0.90234\n",
      "epoch[44/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[44/100] training loss 0.00320, training accuracy 0.92969\n",
      "epoch[44/100] training loss 0.00313, training accuracy 0.96484\n",
      "epoch[44/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[44/100] training loss 0.00318, training accuracy 0.94531\n",
      "epoch[44/100] training loss 0.00330, training accuracy 0.93750\n",
      "epoch[44/100] training loss 0.00326, training accuracy 0.93359\n",
      "epoch[44/100] training loss 0.00335, training accuracy 0.91016\n",
      "epoch[44/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[44/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[44/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[44/100] training loss 0.00324, training accuracy 0.92578\n",
      "epoch[44/100] training loss 0.00327, training accuracy 0.92188\n",
      "epoch[44/100] training loss 0.00323, training accuracy 0.92578\n",
      "epoch[44/100] training loss 0.00332, training accuracy 0.90234\n",
      "epoch[44/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[44/100] training loss 0.00323, training accuracy 0.92969\n",
      "epoch[44/100] training loss 0.00319, training accuracy 0.92578\n",
      "epoch[44/100] training loss 0.00335, training accuracy 0.92578\n",
      "epoch[44/100] training loss 0.00322, training accuracy 0.91797\n",
      "epoch[44/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[44/100] training loss 0.00335, training accuracy 0.91406\n",
      "epoch[44/100] training loss 0.00329, training accuracy 0.91406\n",
      "epoch[44/100] training loss 0.00323, training accuracy 0.92969\n",
      "epoch[44/100] training loss 0.00344, training accuracy 0.89844\n",
      "epoch[44/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[44/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[44/100] training loss 0.00349, training accuracy 0.05469\n",
      "[val] acc : 0.90582, loss : 0.85727\n",
      "best acc : 0.90582, best loss : 0.84726\n",
      "epoch[45/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[45/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[45/100] training loss 0.00335, training accuracy 0.91016\n",
      "epoch[45/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[45/100] training loss 0.00322, training accuracy 0.94141\n",
      "epoch[45/100] training loss 0.00332, training accuracy 0.91797\n",
      "epoch[45/100] training loss 0.00332, training accuracy 0.90625\n",
      "epoch[45/100] training loss 0.00332, training accuracy 0.93359\n",
      "epoch[45/100] training loss 0.00325, training accuracy 0.91797\n",
      "epoch[45/100] training loss 0.00335, training accuracy 0.91797\n",
      "epoch[45/100] training loss 0.00323, training accuracy 0.92969\n",
      "epoch[45/100] training loss 0.00322, training accuracy 0.91016\n",
      "epoch[45/100] training loss 0.00323, training accuracy 0.94531\n",
      "epoch[45/100] training loss 0.00349, training accuracy 0.89453\n",
      "epoch[45/100] training loss 0.00325, training accuracy 0.93359\n",
      "epoch[45/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[45/100] training loss 0.00307, training accuracy 0.98047\n",
      "epoch[45/100] training loss 0.00327, training accuracy 0.92188\n",
      "epoch[45/100] training loss 0.00326, training accuracy 0.91797\n",
      "epoch[45/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[45/100] training loss 0.00329, training accuracy 0.91406\n",
      "epoch[45/100] training loss 0.00321, training accuracy 0.93359\n",
      "epoch[45/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[45/100] training loss 0.00327, training accuracy 0.92578\n",
      "epoch[45/100] training loss 0.00332, training accuracy 0.92578\n",
      "epoch[45/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[45/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[45/100] training loss 0.00313, training accuracy 0.96094\n",
      "epoch[45/100] training loss 0.00328, training accuracy 0.91406\n",
      "epoch[45/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[45/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[45/100] training loss 0.00333, training accuracy 0.92969\n",
      "epoch[45/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[45/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[45/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[45/100] training loss 0.00318, training accuracy 0.95312\n",
      "epoch[45/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[45/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[45/100] training loss 0.00338, training accuracy 0.92578\n",
      "epoch[45/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[45/100] training loss 0.00318, training accuracy 0.94141\n",
      "epoch[45/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[45/100] training loss 0.00322, training accuracy 0.93359\n",
      "epoch[45/100] training loss 0.00320, training accuracy 0.93750\n",
      "epoch[45/100] training loss 0.00334, training accuracy 0.91406\n",
      "epoch[45/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[45/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[45/100] training loss 0.00329, training accuracy 0.91797\n",
      "epoch[45/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[45/100] training loss 0.00333, training accuracy 0.92578\n",
      "epoch[45/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[45/100] training loss 0.00330, training accuracy 0.91797\n",
      "epoch[45/100] training loss 0.00323, training accuracy 0.92969\n",
      "epoch[45/100] training loss 0.00330, training accuracy 0.92188\n",
      "epoch[45/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[45/100] training loss 0.00315, training accuracy 0.94922\n",
      "epoch[45/100] training loss 0.00323, training accuracy 0.92969\n",
      "epoch[45/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[45/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[45/100] training loss 0.00332, training accuracy 0.05859\n",
      "[val] acc : 0.90450, loss : 0.85314\n",
      "best acc : 0.90582, best loss : 0.84726\n",
      "epoch[46/100] training loss 0.00316, training accuracy 0.92578\n",
      "epoch[46/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[46/100] training loss 0.00312, training accuracy 0.95703\n",
      "epoch[46/100] training loss 0.00325, training accuracy 0.93359\n",
      "epoch[46/100] training loss 0.00314, training accuracy 0.94922\n",
      "epoch[46/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[46/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[46/100] training loss 0.00320, training accuracy 0.94922\n",
      "epoch[46/100] training loss 0.00324, training accuracy 0.91797\n",
      "epoch[46/100] training loss 0.00329, training accuracy 0.94531\n",
      "epoch[46/100] training loss 0.00320, training accuracy 0.93750\n",
      "epoch[46/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[46/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[46/100] training loss 0.00334, training accuracy 0.91797\n",
      "epoch[46/100] training loss 0.00327, training accuracy 0.92578\n",
      "epoch[46/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[46/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[46/100] training loss 0.00314, training accuracy 0.94922\n",
      "epoch[46/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[46/100] training loss 0.00325, training accuracy 0.93750\n",
      "epoch[46/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[46/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[46/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[46/100] training loss 0.00320, training accuracy 0.93750\n",
      "epoch[46/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[46/100] training loss 0.00324, training accuracy 0.91797\n",
      "epoch[46/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[46/100] training loss 0.00318, training accuracy 0.94141\n",
      "epoch[46/100] training loss 0.00326, training accuracy 0.92188\n",
      "epoch[46/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[46/100] training loss 0.00320, training accuracy 0.92578\n",
      "epoch[46/100] training loss 0.00336, training accuracy 0.91406\n",
      "epoch[46/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[46/100] training loss 0.00319, training accuracy 0.92969\n",
      "epoch[46/100] training loss 0.00316, training accuracy 0.94531\n",
      "epoch[46/100] training loss 0.00324, training accuracy 0.91406\n",
      "epoch[46/100] training loss 0.00341, training accuracy 0.90234\n",
      "epoch[46/100] training loss 0.00326, training accuracy 0.91406\n",
      "epoch[46/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[46/100] training loss 0.00308, training accuracy 0.93750\n",
      "epoch[46/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[46/100] training loss 0.00322, training accuracy 0.95312\n",
      "epoch[46/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[46/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[46/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[46/100] training loss 0.00315, training accuracy 0.92578\n",
      "epoch[46/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[46/100] training loss 0.00330, training accuracy 0.92969\n",
      "epoch[46/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[46/100] training loss 0.00319, training accuracy 0.94531\n",
      "epoch[46/100] training loss 0.00322, training accuracy 0.94141\n",
      "epoch[46/100] training loss 0.00327, training accuracy 0.94922\n",
      "epoch[46/100] training loss 0.00321, training accuracy 0.94531\n",
      "epoch[46/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[46/100] training loss 0.00330, training accuracy 0.91797\n",
      "epoch[46/100] training loss 0.00313, training accuracy 0.95312\n",
      "epoch[46/100] training loss 0.00332, training accuracy 0.91016\n",
      "epoch[46/100] training loss 0.00326, training accuracy 0.93750\n",
      "epoch[46/100] training loss 0.00330, training accuracy 0.91406\n",
      "epoch[46/100] training loss 0.00285, training accuracy 0.06250\n",
      "[val] acc : 0.90794, loss : 0.84960\n",
      "best acc : 0.90794, best loss : 0.84726\n",
      "epoch[47/100] training loss 0.00321, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00314, training accuracy 0.93359\n",
      "epoch[47/100] training loss 0.00316, training accuracy 0.94922\n",
      "epoch[47/100] training loss 0.00336, training accuracy 0.90234\n",
      "epoch[47/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[47/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[47/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[47/100] training loss 0.00306, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00341, training accuracy 0.89844\n",
      "epoch[47/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[47/100] training loss 0.00324, training accuracy 0.94141\n",
      "epoch[47/100] training loss 0.00320, training accuracy 0.93750\n",
      "epoch[47/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[47/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[47/100] training loss 0.00330, training accuracy 0.91797\n",
      "epoch[47/100] training loss 0.00336, training accuracy 0.91016\n",
      "epoch[47/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[47/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[47/100] training loss 0.00325, training accuracy 0.93750\n",
      "epoch[47/100] training loss 0.00320, training accuracy 0.94141\n",
      "epoch[47/100] training loss 0.00324, training accuracy 0.94922\n",
      "epoch[47/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[47/100] training loss 0.00330, training accuracy 0.92578\n",
      "epoch[47/100] training loss 0.00322, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00336, training accuracy 0.91016\n",
      "epoch[47/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[47/100] training loss 0.00324, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00321, training accuracy 0.93359\n",
      "epoch[47/100] training loss 0.00323, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00329, training accuracy 0.92188\n",
      "epoch[47/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[47/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[47/100] training loss 0.00297, training accuracy 0.97656\n",
      "epoch[47/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[47/100] training loss 0.00319, training accuracy 0.92969\n",
      "epoch[47/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[47/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[47/100] training loss 0.00333, training accuracy 0.92969\n",
      "epoch[47/100] training loss 0.00332, training accuracy 0.91406\n",
      "epoch[47/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[47/100] training loss 0.00310, training accuracy 0.96484\n",
      "epoch[47/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[47/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00308, training accuracy 0.93359\n",
      "epoch[47/100] training loss 0.00340, training accuracy 0.89844\n",
      "epoch[47/100] training loss 0.00324, training accuracy 0.94141\n",
      "epoch[47/100] training loss 0.00310, training accuracy 0.96094\n",
      "epoch[47/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[47/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[47/100] training loss 0.00304, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00316, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[47/100] training loss 0.00324, training accuracy 0.94141\n",
      "epoch[47/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[47/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[47/100] training loss 0.00308, training accuracy 0.06250\n",
      "[val] acc : 0.90582, loss : 0.84670\n",
      "best acc : 0.90794, best loss : 0.84670\n",
      "epoch[48/100] training loss 0.00311, training accuracy 0.93359\n",
      "epoch[48/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[48/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[48/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[48/100] training loss 0.00326, training accuracy 0.92188\n",
      "epoch[48/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[48/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[48/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[48/100] training loss 0.00326, training accuracy 0.92188\n",
      "epoch[48/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[48/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[48/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[48/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[48/100] training loss 0.00327, training accuracy 0.92578\n",
      "epoch[48/100] training loss 0.00346, training accuracy 0.89453\n",
      "epoch[48/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[48/100] training loss 0.00324, training accuracy 0.92578\n",
      "epoch[48/100] training loss 0.00320, training accuracy 0.94531\n",
      "epoch[48/100] training loss 0.00325, training accuracy 0.91797\n",
      "epoch[48/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[48/100] training loss 0.00315, training accuracy 0.93359\n",
      "epoch[48/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[48/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[48/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[48/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[48/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[48/100] training loss 0.00314, training accuracy 0.93359\n",
      "epoch[48/100] training loss 0.00315, training accuracy 0.95703\n",
      "epoch[48/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[48/100] training loss 0.00322, training accuracy 0.91797\n",
      "epoch[48/100] training loss 0.00314, training accuracy 0.93750\n",
      "epoch[48/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[48/100] training loss 0.00320, training accuracy 0.94141\n",
      "epoch[48/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[48/100] training loss 0.00316, training accuracy 0.94531\n",
      "epoch[48/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[48/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[48/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[48/100] training loss 0.00326, training accuracy 0.93750\n",
      "epoch[48/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[48/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[48/100] training loss 0.00333, training accuracy 0.91406\n",
      "epoch[48/100] training loss 0.00312, training accuracy 0.95703\n",
      "epoch[48/100] training loss 0.00334, training accuracy 0.91406\n",
      "epoch[48/100] training loss 0.00316, training accuracy 0.92578\n",
      "epoch[48/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[48/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[48/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[48/100] training loss 0.00318, training accuracy 0.94531\n",
      "epoch[48/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[48/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[48/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[48/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[48/100] training loss 0.00311, training accuracy 0.96875\n",
      "epoch[48/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[48/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[48/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[48/100] training loss 0.00311, training accuracy 0.93359\n",
      "epoch[48/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[48/100] training loss 0.00334, training accuracy 0.05469\n",
      "[val] acc : 0.90873, loss : 0.84220\n",
      "best acc : 0.90873, best loss : 0.84220\n",
      "epoch[49/100] training loss 0.00333, training accuracy 0.91797\n",
      "epoch[49/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[49/100] training loss 0.00325, training accuracy 0.92188\n",
      "epoch[49/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[49/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[49/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[49/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[49/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[49/100] training loss 0.00320, training accuracy 0.94531\n",
      "epoch[49/100] training loss 0.00317, training accuracy 0.92969\n",
      "epoch[49/100] training loss 0.00323, training accuracy 0.93750\n",
      "epoch[49/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[49/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[49/100] training loss 0.00325, training accuracy 0.94922\n",
      "epoch[49/100] training loss 0.00327, training accuracy 0.94922\n",
      "epoch[49/100] training loss 0.00320, training accuracy 0.94531\n",
      "epoch[49/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[49/100] training loss 0.00326, training accuracy 0.91016\n",
      "epoch[49/100] training loss 0.00332, training accuracy 0.90625\n",
      "epoch[49/100] training loss 0.00294, training accuracy 0.96094\n",
      "epoch[49/100] training loss 0.00328, training accuracy 0.91797\n",
      "epoch[49/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[49/100] training loss 0.00319, training accuracy 0.94922\n",
      "epoch[49/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[49/100] training loss 0.00321, training accuracy 0.92188\n",
      "epoch[49/100] training loss 0.00326, training accuracy 0.93750\n",
      "epoch[49/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[49/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[49/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[49/100] training loss 0.00328, training accuracy 0.92188\n",
      "epoch[49/100] training loss 0.00319, training accuracy 0.92969\n",
      "epoch[49/100] training loss 0.00330, training accuracy 0.90625\n",
      "epoch[49/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[49/100] training loss 0.00319, training accuracy 0.92578\n",
      "epoch[49/100] training loss 0.00325, training accuracy 0.91797\n",
      "epoch[49/100] training loss 0.00323, training accuracy 0.91406\n",
      "epoch[49/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[49/100] training loss 0.00307, training accuracy 0.96484\n",
      "epoch[49/100] training loss 0.00325, training accuracy 0.95312\n",
      "epoch[49/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[49/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[49/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[49/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[49/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[49/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[49/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[49/100] training loss 0.00305, training accuracy 0.94922\n",
      "epoch[49/100] training loss 0.00330, training accuracy 0.91406\n",
      "epoch[49/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[49/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[49/100] training loss 0.00317, training accuracy 0.96484\n",
      "epoch[49/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[49/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[49/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[49/100] training loss 0.00318, training accuracy 0.94141\n",
      "epoch[49/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[49/100] training loss 0.00327, training accuracy 0.94531\n",
      "epoch[49/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[49/100] training loss 0.00325, training accuracy 0.93359\n",
      "epoch[49/100] training loss 0.00326, training accuracy 0.05469\n",
      "[val] acc : 0.91190, loss : 0.84413\n",
      "best acc : 0.91190, best loss : 0.84220\n",
      "epoch[50/100] training loss 0.00335, training accuracy 0.91406\n",
      "epoch[50/100] training loss 0.00323, training accuracy 0.92188\n",
      "epoch[50/100] training loss 0.00308, training accuracy 0.94531\n",
      "epoch[50/100] training loss 0.00315, training accuracy 0.95312\n",
      "epoch[50/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[50/100] training loss 0.00315, training accuracy 0.95703\n",
      "epoch[50/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[50/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[50/100] training loss 0.00329, training accuracy 0.91797\n",
      "epoch[50/100] training loss 0.00323, training accuracy 0.93750\n",
      "epoch[50/100] training loss 0.00333, training accuracy 0.92188\n",
      "epoch[50/100] training loss 0.00335, training accuracy 0.91016\n",
      "epoch[50/100] training loss 0.00322, training accuracy 0.92188\n",
      "epoch[50/100] training loss 0.00326, training accuracy 0.94141\n",
      "epoch[50/100] training loss 0.00335, training accuracy 0.92188\n",
      "epoch[50/100] training loss 0.00334, training accuracy 0.92188\n",
      "epoch[50/100] training loss 0.00328, training accuracy 0.94531\n",
      "epoch[50/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[50/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[50/100] training loss 0.00312, training accuracy 0.92969\n",
      "epoch[50/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[50/100] training loss 0.00344, training accuracy 0.90234\n",
      "epoch[50/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[50/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[50/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[50/100] training loss 0.00322, training accuracy 0.94141\n",
      "epoch[50/100] training loss 0.00310, training accuracy 0.97266\n",
      "epoch[50/100] training loss 0.00315, training accuracy 0.94922\n",
      "epoch[50/100] training loss 0.00309, training accuracy 0.96484\n",
      "epoch[50/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[50/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[50/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[50/100] training loss 0.00311, training accuracy 0.96094\n",
      "epoch[50/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[50/100] training loss 0.00324, training accuracy 0.93750\n",
      "epoch[50/100] training loss 0.00340, training accuracy 0.91406\n",
      "epoch[50/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[50/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[50/100] training loss 0.00315, training accuracy 0.93359\n",
      "epoch[50/100] training loss 0.00321, training accuracy 0.94531\n",
      "epoch[50/100] training loss 0.00323, training accuracy 0.91797\n",
      "epoch[50/100] training loss 0.00307, training accuracy 0.94531\n",
      "epoch[50/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[50/100] training loss 0.00321, training accuracy 0.91797\n",
      "epoch[50/100] training loss 0.00329, training accuracy 0.93750\n",
      "epoch[50/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[50/100] training loss 0.00320, training accuracy 0.94141\n",
      "epoch[50/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[50/100] training loss 0.00304, training accuracy 0.94531\n",
      "epoch[50/100] training loss 0.00318, training accuracy 0.94141\n",
      "epoch[50/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[50/100] training loss 0.00307, training accuracy 0.96875\n",
      "epoch[50/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[50/100] training loss 0.00323, training accuracy 0.92969\n",
      "epoch[50/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[50/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[50/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[50/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[50/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[50/100] training loss 0.00319, training accuracy 0.05859\n",
      "[val] acc : 0.90635, loss : 0.84405\n",
      "best acc : 0.91190, best loss : 0.84220\n",
      "epoch[51/100] training loss 0.00316, training accuracy 0.91797\n",
      "epoch[51/100] training loss 0.00324, training accuracy 0.91406\n",
      "epoch[51/100] training loss 0.00330, training accuracy 0.91406\n",
      "epoch[51/100] training loss 0.00325, training accuracy 0.92188\n",
      "epoch[51/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[51/100] training loss 0.00318, training accuracy 0.92578\n",
      "epoch[51/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[51/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[51/100] training loss 0.00322, training accuracy 0.94922\n",
      "epoch[51/100] training loss 0.00314, training accuracy 0.94922\n",
      "epoch[51/100] training loss 0.00317, training accuracy 0.92578\n",
      "epoch[51/100] training loss 0.00326, training accuracy 0.94531\n",
      "epoch[51/100] training loss 0.00333, training accuracy 0.90625\n",
      "epoch[51/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[51/100] training loss 0.00338, training accuracy 0.89453\n",
      "epoch[51/100] training loss 0.00322, training accuracy 0.92188\n",
      "epoch[51/100] training loss 0.00318, training accuracy 0.95312\n",
      "epoch[51/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[51/100] training loss 0.00320, training accuracy 0.94922\n",
      "epoch[51/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[51/100] training loss 0.00328, training accuracy 0.92188\n",
      "epoch[51/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[51/100] training loss 0.00320, training accuracy 0.92188\n",
      "epoch[51/100] training loss 0.00324, training accuracy 0.91797\n",
      "epoch[51/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[51/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[51/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[51/100] training loss 0.00320, training accuracy 0.94141\n",
      "epoch[51/100] training loss 0.00320, training accuracy 0.94141\n",
      "epoch[51/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[51/100] training loss 0.00322, training accuracy 0.94922\n",
      "epoch[51/100] training loss 0.00315, training accuracy 0.92188\n",
      "epoch[51/100] training loss 0.00306, training accuracy 0.94531\n",
      "epoch[51/100] training loss 0.00306, training accuracy 0.96875\n",
      "epoch[51/100] training loss 0.00304, training accuracy 0.96875\n",
      "epoch[51/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[51/100] training loss 0.00321, training accuracy 0.94922\n",
      "epoch[51/100] training loss 0.00312, training accuracy 0.93359\n",
      "epoch[51/100] training loss 0.00302, training accuracy 0.94141\n",
      "epoch[51/100] training loss 0.00325, training accuracy 0.93750\n",
      "epoch[51/100] training loss 0.00318, training accuracy 0.92969\n",
      "epoch[51/100] training loss 0.00322, training accuracy 0.95703\n",
      "epoch[51/100] training loss 0.00315, training accuracy 0.92969\n",
      "epoch[51/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[51/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[51/100] training loss 0.00303, training accuracy 0.94531\n",
      "epoch[51/100] training loss 0.00304, training accuracy 0.97266\n",
      "epoch[51/100] training loss 0.00322, training accuracy 0.94531\n",
      "epoch[51/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[51/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[51/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[51/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[51/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[51/100] training loss 0.00315, training accuracy 0.94922\n",
      "epoch[51/100] training loss 0.00316, training accuracy 0.96094\n",
      "epoch[51/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[51/100] training loss 0.00326, training accuracy 0.94531\n",
      "epoch[51/100] training loss 0.00321, training accuracy 0.94922\n",
      "epoch[51/100] training loss 0.00311, training accuracy 0.92578\n",
      "epoch[51/100] training loss 0.00281, training accuracy 0.06250\n",
      "[val] acc : 0.91032, loss : 0.84161\n",
      "best acc : 0.91190, best loss : 0.84161\n",
      "epoch[52/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[52/100] training loss 0.00322, training accuracy 0.93750\n",
      "epoch[52/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[52/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[52/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[52/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[52/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[52/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[52/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[52/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[52/100] training loss 0.00331, training accuracy 0.91016\n",
      "epoch[52/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[52/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[52/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[52/100] training loss 0.00318, training accuracy 0.93359\n",
      "epoch[52/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[52/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[52/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[52/100] training loss 0.00328, training accuracy 0.89453\n",
      "epoch[52/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[52/100] training loss 0.00330, training accuracy 0.91797\n",
      "epoch[52/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[52/100] training loss 0.00309, training accuracy 0.96094\n",
      "epoch[52/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[52/100] training loss 0.00319, training accuracy 0.92969\n",
      "epoch[52/100] training loss 0.00323, training accuracy 0.93750\n",
      "epoch[52/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[52/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[52/100] training loss 0.00314, training accuracy 0.94922\n",
      "epoch[52/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[52/100] training loss 0.00335, training accuracy 0.91406\n",
      "epoch[52/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[52/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[52/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[52/100] training loss 0.00320, training accuracy 0.91797\n",
      "epoch[52/100] training loss 0.00317, training accuracy 0.92188\n",
      "epoch[52/100] training loss 0.00313, training accuracy 0.95312\n",
      "epoch[52/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[52/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[52/100] training loss 0.00328, training accuracy 0.94141\n",
      "epoch[52/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[52/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[52/100] training loss 0.00313, training accuracy 0.92969\n",
      "epoch[52/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[52/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[52/100] training loss 0.00322, training accuracy 0.93750\n",
      "epoch[52/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[52/100] training loss 0.00308, training accuracy 0.94531\n",
      "epoch[52/100] training loss 0.00318, training accuracy 0.92578\n",
      "epoch[52/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[52/100] training loss 0.00322, training accuracy 0.94922\n",
      "epoch[52/100] training loss 0.00321, training accuracy 0.92969\n",
      "epoch[52/100] training loss 0.00325, training accuracy 0.94531\n",
      "epoch[52/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[52/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[52/100] training loss 0.00314, training accuracy 0.96484\n",
      "epoch[52/100] training loss 0.00320, training accuracy 0.95312\n",
      "epoch[52/100] training loss 0.00317, training accuracy 0.95312\n",
      "epoch[52/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[52/100] training loss 0.00367, training accuracy 0.05469\n",
      "[val] acc : 0.90899, loss : 0.83890\n",
      "best acc : 0.91190, best loss : 0.83890\n",
      "epoch[53/100] training loss 0.00325, training accuracy 0.92578\n",
      "epoch[53/100] training loss 0.00333, training accuracy 0.91016\n",
      "epoch[53/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[53/100] training loss 0.00319, training accuracy 0.96484\n",
      "epoch[53/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[53/100] training loss 0.00330, training accuracy 0.92188\n",
      "epoch[53/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[53/100] training loss 0.00328, training accuracy 0.93359\n",
      "epoch[53/100] training loss 0.00330, training accuracy 0.92188\n",
      "epoch[53/100] training loss 0.00330, training accuracy 0.93359\n",
      "epoch[53/100] training loss 0.00324, training accuracy 0.94141\n",
      "epoch[53/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[53/100] training loss 0.00315, training accuracy 0.95312\n",
      "epoch[53/100] training loss 0.00306, training accuracy 0.94141\n",
      "epoch[53/100] training loss 0.00325, training accuracy 0.94531\n",
      "epoch[53/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[53/100] training loss 0.00309, training accuracy 0.96875\n",
      "epoch[53/100] training loss 0.00305, training accuracy 0.94922\n",
      "epoch[53/100] training loss 0.00314, training accuracy 0.95312\n",
      "epoch[53/100] training loss 0.00304, training accuracy 0.97266\n",
      "epoch[53/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[53/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[53/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[53/100] training loss 0.00334, training accuracy 0.92578\n",
      "epoch[53/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[53/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[53/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[53/100] training loss 0.00326, training accuracy 0.91406\n",
      "epoch[53/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[53/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[53/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[53/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[53/100] training loss 0.00316, training accuracy 0.92969\n",
      "epoch[53/100] training loss 0.00314, training accuracy 0.94922\n",
      "epoch[53/100] training loss 0.00315, training accuracy 0.95703\n",
      "epoch[53/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[53/100] training loss 0.00315, training accuracy 0.95312\n",
      "epoch[53/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[53/100] training loss 0.00320, training accuracy 0.92578\n",
      "epoch[53/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[53/100] training loss 0.00315, training accuracy 0.93359\n",
      "epoch[53/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[53/100] training loss 0.00299, training accuracy 0.95703\n",
      "epoch[53/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[53/100] training loss 0.00310, training accuracy 0.96875\n",
      "epoch[53/100] training loss 0.00326, training accuracy 0.91797\n",
      "epoch[53/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[53/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[53/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[53/100] training loss 0.00320, training accuracy 0.91016\n",
      "epoch[53/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[53/100] training loss 0.00312, training accuracy 0.93750\n",
      "epoch[53/100] training loss 0.00336, training accuracy 0.90234\n",
      "epoch[53/100] training loss 0.00302, training accuracy 0.94922\n",
      "epoch[53/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[53/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[53/100] training loss 0.00319, training accuracy 0.92578\n",
      "epoch[53/100] training loss 0.00320, training accuracy 0.95312\n",
      "epoch[53/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[53/100] training loss 0.00308, training accuracy 0.05469\n",
      "[val] acc : 0.90847, loss : 0.84194\n",
      "best acc : 0.91190, best loss : 0.83890\n",
      "epoch[54/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[54/100] training loss 0.00310, training accuracy 0.93359\n",
      "epoch[54/100] training loss 0.00314, training accuracy 0.93750\n",
      "epoch[54/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[54/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[54/100] training loss 0.00331, training accuracy 0.92969\n",
      "epoch[54/100] training loss 0.00314, training accuracy 0.96094\n",
      "epoch[54/100] training loss 0.00316, training accuracy 0.94922\n",
      "epoch[54/100] training loss 0.00325, training accuracy 0.93359\n",
      "epoch[54/100] training loss 0.00318, training accuracy 0.94531\n",
      "epoch[54/100] training loss 0.00322, training accuracy 0.91797\n",
      "epoch[54/100] training loss 0.00321, training accuracy 0.93359\n",
      "epoch[54/100] training loss 0.00308, training accuracy 0.93750\n",
      "epoch[54/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[54/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[54/100] training loss 0.00333, training accuracy 0.92188\n",
      "epoch[54/100] training loss 0.00320, training accuracy 0.93359\n",
      "epoch[54/100] training loss 0.00319, training accuracy 0.94531\n",
      "epoch[54/100] training loss 0.00312, training accuracy 0.95703\n",
      "epoch[54/100] training loss 0.00316, training accuracy 0.96094\n",
      "epoch[54/100] training loss 0.00303, training accuracy 0.97656\n",
      "epoch[54/100] training loss 0.00325, training accuracy 0.93750\n",
      "epoch[54/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[54/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[54/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[54/100] training loss 0.00321, training accuracy 0.94531\n",
      "epoch[54/100] training loss 0.00310, training accuracy 0.93750\n",
      "epoch[54/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[54/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[54/100] training loss 0.00326, training accuracy 0.92969\n",
      "epoch[54/100] training loss 0.00319, training accuracy 0.94922\n",
      "epoch[54/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[54/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[54/100] training loss 0.00322, training accuracy 0.92578\n",
      "epoch[54/100] training loss 0.00318, training accuracy 0.92969\n",
      "epoch[54/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[54/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[54/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[54/100] training loss 0.00305, training accuracy 0.96484\n",
      "epoch[54/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[54/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[54/100] training loss 0.00322, training accuracy 0.93359\n",
      "epoch[54/100] training loss 0.00319, training accuracy 0.94922\n",
      "epoch[54/100] training loss 0.00314, training accuracy 0.96094\n",
      "epoch[54/100] training loss 0.00312, training accuracy 0.93750\n",
      "epoch[54/100] training loss 0.00314, training accuracy 0.94922\n",
      "epoch[54/100] training loss 0.00317, training accuracy 0.95312\n",
      "epoch[54/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[54/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[54/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[54/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[54/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[54/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[54/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[54/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[54/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[54/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[54/100] training loss 0.00315, training accuracy 0.94922\n",
      "epoch[54/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[54/100] training loss 0.00306, training accuracy 0.06250\n",
      "[val] acc : 0.90847, loss : 0.83414\n",
      "best acc : 0.91190, best loss : 0.83414\n",
      "epoch[55/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[55/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[55/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[55/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[55/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[55/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[55/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[55/100] training loss 0.00324, training accuracy 0.91406\n",
      "epoch[55/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[55/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[55/100] training loss 0.00314, training accuracy 0.95703\n",
      "epoch[55/100] training loss 0.00317, training accuracy 0.95703\n",
      "epoch[55/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[55/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[55/100] training loss 0.00314, training accuracy 0.93750\n",
      "epoch[55/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[55/100] training loss 0.00316, training accuracy 0.94922\n",
      "epoch[55/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[55/100] training loss 0.00318, training accuracy 0.96094\n",
      "epoch[55/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[55/100] training loss 0.00325, training accuracy 0.92969\n",
      "epoch[55/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[55/100] training loss 0.00308, training accuracy 0.94531\n",
      "epoch[55/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[55/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[55/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[55/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[55/100] training loss 0.00301, training accuracy 0.97266\n",
      "epoch[55/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[55/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[55/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[55/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[55/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[55/100] training loss 0.00304, training accuracy 0.97656\n",
      "epoch[55/100] training loss 0.00323, training accuracy 0.93750\n",
      "epoch[55/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[55/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[55/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[55/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[55/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[55/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[55/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[55/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[55/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[55/100] training loss 0.00328, training accuracy 0.92578\n",
      "epoch[55/100] training loss 0.00306, training accuracy 0.97266\n",
      "epoch[55/100] training loss 0.00304, training accuracy 0.96875\n",
      "epoch[55/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[55/100] training loss 0.00322, training accuracy 0.94141\n",
      "epoch[55/100] training loss 0.00322, training accuracy 0.94141\n",
      "epoch[55/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[55/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[55/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[55/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[55/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[55/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[55/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[55/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[55/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[55/100] training loss 0.00269, training accuracy 0.06250\n",
      "[val] acc : 0.91085, loss : 0.83162\n",
      "best acc : 0.91190, best loss : 0.83162\n",
      "epoch[56/100] training loss 0.00322, training accuracy 0.93359\n",
      "epoch[56/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[56/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[56/100] training loss 0.00318, training accuracy 0.92969\n",
      "epoch[56/100] training loss 0.00311, training accuracy 0.95703\n",
      "epoch[56/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[56/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[56/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[56/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[56/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[56/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[56/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[56/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[56/100] training loss 0.00295, training accuracy 0.98047\n",
      "epoch[56/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[56/100] training loss 0.00315, training accuracy 0.94922\n",
      "epoch[56/100] training loss 0.00316, training accuracy 0.94922\n",
      "epoch[56/100] training loss 0.00323, training accuracy 0.92969\n",
      "epoch[56/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[56/100] training loss 0.00323, training accuracy 0.94141\n",
      "epoch[56/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[56/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[56/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[56/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[56/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[56/100] training loss 0.00321, training accuracy 0.92578\n",
      "epoch[56/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[56/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[56/100] training loss 0.00301, training accuracy 0.97266\n",
      "epoch[56/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[56/100] training loss 0.00318, training accuracy 0.93359\n",
      "epoch[56/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[56/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[56/100] training loss 0.00310, training accuracy 0.96094\n",
      "epoch[56/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[56/100] training loss 0.00313, training accuracy 0.96094\n",
      "epoch[56/100] training loss 0.00291, training accuracy 0.99219\n",
      "epoch[56/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[56/100] training loss 0.00302, training accuracy 0.96484\n",
      "epoch[56/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[56/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[56/100] training loss 0.00306, training accuracy 0.93359\n",
      "epoch[56/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[56/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[56/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[56/100] training loss 0.00328, training accuracy 0.93750\n",
      "epoch[56/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[56/100] training loss 0.00313, training accuracy 0.92578\n",
      "epoch[56/100] training loss 0.00318, training accuracy 0.93359\n",
      "epoch[56/100] training loss 0.00310, training accuracy 0.92969\n",
      "epoch[56/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[56/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[56/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[56/100] training loss 0.00304, training accuracy 0.96875\n",
      "epoch[56/100] training loss 0.00297, training accuracy 0.97656\n",
      "epoch[56/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[56/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[56/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[56/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[56/100] training loss 0.00285, training accuracy 0.06250\n",
      "[val] acc : 0.91481, loss : 0.83576\n",
      "best acc : 0.91481, best loss : 0.83162\n",
      "epoch[57/100] training loss 0.00317, training accuracy 0.92578\n",
      "epoch[57/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[57/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[57/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[57/100] training loss 0.00322, training accuracy 0.92578\n",
      "epoch[57/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[57/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[57/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[57/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[57/100] training loss 0.00318, training accuracy 0.92578\n",
      "epoch[57/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[57/100] training loss 0.00318, training accuracy 0.92969\n",
      "epoch[57/100] training loss 0.00314, training accuracy 0.94922\n",
      "epoch[57/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[57/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[57/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[57/100] training loss 0.00311, training accuracy 0.95703\n",
      "epoch[57/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[57/100] training loss 0.00325, training accuracy 0.94141\n",
      "epoch[57/100] training loss 0.00322, training accuracy 0.92188\n",
      "epoch[57/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[57/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[57/100] training loss 0.00308, training accuracy 0.92969\n",
      "epoch[57/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[57/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[57/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[57/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[57/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[57/100] training loss 0.00301, training accuracy 0.95312\n",
      "epoch[57/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[57/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[57/100] training loss 0.00322, training accuracy 0.93750\n",
      "epoch[57/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[57/100] training loss 0.00323, training accuracy 0.91016\n",
      "epoch[57/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[57/100] training loss 0.00317, training accuracy 0.95312\n",
      "epoch[57/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[57/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[57/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[57/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[57/100] training loss 0.00337, training accuracy 0.90234\n",
      "epoch[57/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[57/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[57/100] training loss 0.00300, training accuracy 0.94531\n",
      "epoch[57/100] training loss 0.00327, training accuracy 0.93359\n",
      "epoch[57/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[57/100] training loss 0.00313, training accuracy 0.95703\n",
      "epoch[57/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[57/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[57/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[57/100] training loss 0.00319, training accuracy 0.94922\n",
      "epoch[57/100] training loss 0.00307, training accuracy 0.94141\n",
      "epoch[57/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[57/100] training loss 0.00315, training accuracy 0.96484\n",
      "epoch[57/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[57/100] training loss 0.00314, training accuracy 0.93750\n",
      "epoch[57/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[57/100] training loss 0.00311, training accuracy 0.96094\n",
      "epoch[57/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[57/100] training loss 0.00312, training accuracy 0.06250\n",
      "[val] acc : 0.91508, loss : 0.83006\n",
      "best acc : 0.91508, best loss : 0.83006\n",
      "epoch[58/100] training loss 0.00310, training accuracy 0.93750\n",
      "epoch[58/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[58/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[58/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[58/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[58/100] training loss 0.00317, training accuracy 0.94922\n",
      "epoch[58/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[58/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[58/100] training loss 0.00320, training accuracy 0.94531\n",
      "epoch[58/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[58/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[58/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[58/100] training loss 0.00311, training accuracy 0.95703\n",
      "epoch[58/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[58/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[58/100] training loss 0.00313, training accuracy 0.95312\n",
      "epoch[58/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[58/100] training loss 0.00314, training accuracy 0.94922\n",
      "epoch[58/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[58/100] training loss 0.00328, training accuracy 0.92969\n",
      "epoch[58/100] training loss 0.00305, training accuracy 0.94922\n",
      "epoch[58/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[58/100] training loss 0.00319, training accuracy 0.94531\n",
      "epoch[58/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[58/100] training loss 0.00300, training accuracy 0.94922\n",
      "epoch[58/100] training loss 0.00313, training accuracy 0.95312\n",
      "epoch[58/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[58/100] training loss 0.00321, training accuracy 0.93359\n",
      "epoch[58/100] training loss 0.00310, training accuracy 0.96875\n",
      "epoch[58/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[58/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[58/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[58/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[58/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[58/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[58/100] training loss 0.00297, training accuracy 0.97656\n",
      "epoch[58/100] training loss 0.00321, training accuracy 0.93359\n",
      "epoch[58/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[58/100] training loss 0.00296, training accuracy 0.97656\n",
      "epoch[58/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[58/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[58/100] training loss 0.00325, training accuracy 0.94922\n",
      "epoch[58/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[58/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[58/100] training loss 0.00305, training accuracy 0.96484\n",
      "epoch[58/100] training loss 0.00302, training accuracy 0.94531\n",
      "epoch[58/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[58/100] training loss 0.00320, training accuracy 0.94141\n",
      "epoch[58/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[58/100] training loss 0.00304, training accuracy 0.94922\n",
      "epoch[58/100] training loss 0.00305, training accuracy 0.94922\n",
      "epoch[58/100] training loss 0.00328, training accuracy 0.91016\n",
      "epoch[58/100] training loss 0.00324, training accuracy 0.91797\n",
      "epoch[58/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[58/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[58/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[58/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[58/100] training loss 0.00318, training accuracy 0.94922\n",
      "epoch[58/100] training loss 0.00309, training accuracy 0.92969\n",
      "epoch[58/100] training loss 0.00321, training accuracy 0.05859\n",
      "[val] acc : 0.91720, loss : 0.82887\n",
      "best acc : 0.91720, best loss : 0.82887\n",
      "epoch[59/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[59/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[59/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[59/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[59/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[59/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[59/100] training loss 0.00320, training accuracy 0.92969\n",
      "epoch[59/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[59/100] training loss 0.00309, training accuracy 0.94141\n",
      "epoch[59/100] training loss 0.00325, training accuracy 0.93359\n",
      "epoch[59/100] training loss 0.00304, training accuracy 0.94922\n",
      "epoch[59/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[59/100] training loss 0.00299, training accuracy 0.97656\n",
      "epoch[59/100] training loss 0.00320, training accuracy 0.93359\n",
      "epoch[59/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[59/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[59/100] training loss 0.00322, training accuracy 0.92188\n",
      "epoch[59/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[59/100] training loss 0.00323, training accuracy 0.92969\n",
      "epoch[59/100] training loss 0.00315, training accuracy 0.94922\n",
      "epoch[59/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[59/100] training loss 0.00335, training accuracy 0.92578\n",
      "epoch[59/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[59/100] training loss 0.00309, training accuracy 0.96094\n",
      "epoch[59/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[59/100] training loss 0.00303, training accuracy 0.93750\n",
      "epoch[59/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[59/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[59/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[59/100] training loss 0.00307, training accuracy 0.96875\n",
      "epoch[59/100] training loss 0.00303, training accuracy 0.97266\n",
      "epoch[59/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[59/100] training loss 0.00310, training accuracy 0.96875\n",
      "epoch[59/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[59/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[59/100] training loss 0.00309, training accuracy 0.94141\n",
      "epoch[59/100] training loss 0.00314, training accuracy 0.93750\n",
      "epoch[59/100] training loss 0.00338, training accuracy 0.89844\n",
      "epoch[59/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[59/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[59/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[59/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[59/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[59/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[59/100] training loss 0.00327, training accuracy 0.92188\n",
      "epoch[59/100] training loss 0.00317, training accuracy 0.95312\n",
      "epoch[59/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[59/100] training loss 0.00302, training accuracy 0.97656\n",
      "epoch[59/100] training loss 0.00303, training accuracy 0.97266\n",
      "epoch[59/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[59/100] training loss 0.00326, training accuracy 0.92578\n",
      "epoch[59/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[59/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[59/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[59/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[59/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[59/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[59/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[59/100] training loss 0.00296, training accuracy 0.98047\n",
      "epoch[59/100] training loss 0.00308, training accuracy 0.06250\n",
      "[val] acc : 0.90847, loss : 0.83888\n",
      "best acc : 0.91720, best loss : 0.82887\n",
      "epoch[60/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[60/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[60/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[60/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[60/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[60/100] training loss 0.00308, training accuracy 0.94531\n",
      "epoch[60/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[60/100] training loss 0.00309, training accuracy 0.94141\n",
      "epoch[60/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[60/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[60/100] training loss 0.00306, training accuracy 0.96875\n",
      "epoch[60/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[60/100] training loss 0.00317, training accuracy 0.94922\n",
      "epoch[60/100] training loss 0.00302, training accuracy 0.96484\n",
      "epoch[60/100] training loss 0.00304, training accuracy 0.97266\n",
      "epoch[60/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[60/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[60/100] training loss 0.00309, training accuracy 0.93750\n",
      "epoch[60/100] training loss 0.00311, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[60/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[60/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[60/100] training loss 0.00325, training accuracy 0.92188\n",
      "epoch[60/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[60/100] training loss 0.00316, training accuracy 0.92969\n",
      "epoch[60/100] training loss 0.00322, training accuracy 0.93359\n",
      "epoch[60/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00305, training accuracy 0.98047\n",
      "epoch[60/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[60/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00309, training accuracy 0.93359\n",
      "epoch[60/100] training loss 0.00316, training accuracy 0.96094\n",
      "epoch[60/100] training loss 0.00319, training accuracy 0.94531\n",
      "epoch[60/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[60/100] training loss 0.00315, training accuracy 0.93359\n",
      "epoch[60/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[60/100] training loss 0.00307, training accuracy 0.94531\n",
      "epoch[60/100] training loss 0.00309, training accuracy 0.96484\n",
      "epoch[60/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00313, training accuracy 0.95312\n",
      "epoch[60/100] training loss 0.00314, training accuracy 0.94922\n",
      "epoch[60/100] training loss 0.00314, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[60/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[60/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[60/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[60/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[60/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[60/100] training loss 0.00327, training accuracy 0.92578\n",
      "epoch[60/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[60/100] training loss 0.00308, training accuracy 0.96484\n",
      "epoch[60/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[60/100] training loss 0.00314, training accuracy 0.93750\n",
      "epoch[60/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[60/100] training loss 0.00326, training accuracy 0.05859\n",
      "[val] acc : 0.91587, loss : 0.83018\n",
      "best acc : 0.91720, best loss : 0.82887\n",
      "epoch[61/100] training loss 0.00320, training accuracy 0.93359\n",
      "epoch[61/100] training loss 0.00306, training accuracy 0.96875\n",
      "epoch[61/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[61/100] training loss 0.00311, training accuracy 0.95703\n",
      "epoch[61/100] training loss 0.00315, training accuracy 0.95312\n",
      "epoch[61/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[61/100] training loss 0.00309, training accuracy 0.94141\n",
      "epoch[61/100] training loss 0.00320, training accuracy 0.92188\n",
      "epoch[61/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[61/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[61/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[61/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[61/100] training loss 0.00314, training accuracy 0.96094\n",
      "epoch[61/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[61/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[61/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[61/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[61/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[61/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[61/100] training loss 0.00298, training accuracy 0.97656\n",
      "epoch[61/100] training loss 0.00318, training accuracy 0.94922\n",
      "epoch[61/100] training loss 0.00316, training accuracy 0.94922\n",
      "epoch[61/100] training loss 0.00307, training accuracy 0.94531\n",
      "epoch[61/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[61/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[61/100] training loss 0.00292, training accuracy 0.97656\n",
      "epoch[61/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[61/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[61/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[61/100] training loss 0.00315, training accuracy 0.92578\n",
      "epoch[61/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[61/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[61/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[61/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[61/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[61/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[61/100] training loss 0.00321, training accuracy 0.92578\n",
      "epoch[61/100] training loss 0.00301, training accuracy 0.95312\n",
      "epoch[61/100] training loss 0.00316, training accuracy 0.94531\n",
      "epoch[61/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[61/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[61/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[61/100] training loss 0.00322, training accuracy 0.94922\n",
      "epoch[61/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[61/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[61/100] training loss 0.00325, training accuracy 0.92578\n",
      "epoch[61/100] training loss 0.00320, training accuracy 0.94531\n",
      "epoch[61/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[61/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[61/100] training loss 0.00318, training accuracy 0.93359\n",
      "epoch[61/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[61/100] training loss 0.00310, training accuracy 0.96094\n",
      "epoch[61/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[61/100] training loss 0.00328, training accuracy 0.94531\n",
      "epoch[61/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[61/100] training loss 0.00296, training accuracy 0.96875\n",
      "epoch[61/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[61/100] training loss 0.00305, training accuracy 0.96875\n",
      "epoch[61/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[61/100] training loss 0.00278, training accuracy 0.06250\n",
      "[val] acc : 0.91376, loss : 0.82662\n",
      "best acc : 0.91720, best loss : 0.82662\n",
      "epoch[62/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[62/100] training loss 0.00322, training accuracy 0.94141\n",
      "epoch[62/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[62/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[62/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[62/100] training loss 0.00316, training accuracy 0.92578\n",
      "epoch[62/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[62/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[62/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[62/100] training loss 0.00328, training accuracy 0.91797\n",
      "epoch[62/100] training loss 0.00306, training accuracy 0.94531\n",
      "epoch[62/100] training loss 0.00306, training accuracy 0.94141\n",
      "epoch[62/100] training loss 0.00313, training accuracy 0.95703\n",
      "epoch[62/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[62/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[62/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[62/100] training loss 0.00314, training accuracy 0.94922\n",
      "epoch[62/100] training loss 0.00321, training accuracy 0.92969\n",
      "epoch[62/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[62/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[62/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[62/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[62/100] training loss 0.00316, training accuracy 0.92969\n",
      "epoch[62/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[62/100] training loss 0.00301, training accuracy 0.96875\n",
      "epoch[62/100] training loss 0.00319, training accuracy 0.96484\n",
      "epoch[62/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[62/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[62/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[62/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[62/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[62/100] training loss 0.00308, training accuracy 0.96484\n",
      "epoch[62/100] training loss 0.00303, training accuracy 0.96875\n",
      "epoch[62/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[62/100] training loss 0.00305, training accuracy 0.96484\n",
      "epoch[62/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[62/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[62/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[62/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[62/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[62/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[62/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[62/100] training loss 0.00307, training accuracy 0.96875\n",
      "epoch[62/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[62/100] training loss 0.00315, training accuracy 0.92969\n",
      "epoch[62/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[62/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[62/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[62/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[62/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[62/100] training loss 0.00302, training accuracy 0.94922\n",
      "epoch[62/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[62/100] training loss 0.00324, training accuracy 0.92188\n",
      "epoch[62/100] training loss 0.00313, training accuracy 0.95312\n",
      "epoch[62/100] training loss 0.00299, training accuracy 0.94141\n",
      "epoch[62/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[62/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[62/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[62/100] training loss 0.00312, training accuracy 0.95703\n",
      "epoch[62/100] training loss 0.00294, training accuracy 0.06250\n",
      "[val] acc : 0.90688, loss : 0.83362\n",
      "best acc : 0.91720, best loss : 0.82662\n",
      "epoch[63/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[63/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[63/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[63/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[63/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[63/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[63/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[63/100] training loss 0.00308, training accuracy 0.93359\n",
      "epoch[63/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[63/100] training loss 0.00307, training accuracy 0.94531\n",
      "epoch[63/100] training loss 0.00300, training accuracy 0.97266\n",
      "epoch[63/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[63/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[63/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[63/100] training loss 0.00305, training accuracy 0.94922\n",
      "epoch[63/100] training loss 0.00300, training accuracy 0.98047\n",
      "epoch[63/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[63/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[63/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[63/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[63/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[63/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[63/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[63/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[63/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[63/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[63/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[63/100] training loss 0.00320, training accuracy 0.93359\n",
      "epoch[63/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[63/100] training loss 0.00316, training accuracy 0.94531\n",
      "epoch[63/100] training loss 0.00315, training accuracy 0.92969\n",
      "epoch[63/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[63/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[63/100] training loss 0.00314, training accuracy 0.96484\n",
      "epoch[63/100] training loss 0.00306, training accuracy 0.94141\n",
      "epoch[63/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[63/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[63/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[63/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[63/100] training loss 0.00321, training accuracy 0.91406\n",
      "epoch[63/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[63/100] training loss 0.00307, training accuracy 0.94141\n",
      "epoch[63/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[63/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[63/100] training loss 0.00307, training accuracy 0.96484\n",
      "epoch[63/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[63/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[63/100] training loss 0.00294, training accuracy 0.96094\n",
      "epoch[63/100] training loss 0.00296, training accuracy 0.96484\n",
      "epoch[63/100] training loss 0.00309, training accuracy 0.96094\n",
      "epoch[63/100] training loss 0.00295, training accuracy 0.96875\n",
      "epoch[63/100] training loss 0.00307, training accuracy 0.94141\n",
      "epoch[63/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[63/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[63/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[63/100] training loss 0.00307, training accuracy 0.93750\n",
      "epoch[63/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[63/100] training loss 0.00307, training accuracy 0.93750\n",
      "epoch[63/100] training loss 0.00314, training accuracy 0.93359\n",
      "epoch[63/100] training loss 0.00276, training accuracy 0.06250\n",
      "[val] acc : 0.91402, loss : 0.83243\n",
      "best acc : 0.91720, best loss : 0.82662\n",
      "epoch[64/100] training loss 0.00295, training accuracy 0.98047\n",
      "epoch[64/100] training loss 0.00295, training accuracy 0.98047\n",
      "epoch[64/100] training loss 0.00320, training accuracy 0.92969\n",
      "epoch[64/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[64/100] training loss 0.00306, training accuracy 0.97266\n",
      "epoch[64/100] training loss 0.00304, training accuracy 0.94531\n",
      "epoch[64/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[64/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[64/100] training loss 0.00313, training accuracy 0.95703\n",
      "epoch[64/100] training loss 0.00317, training accuracy 0.92969\n",
      "epoch[64/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[64/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[64/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[64/100] training loss 0.00298, training accuracy 0.98438\n",
      "epoch[64/100] training loss 0.00310, training accuracy 0.93750\n",
      "epoch[64/100] training loss 0.00312, training accuracy 0.95703\n",
      "epoch[64/100] training loss 0.00291, training accuracy 0.98438\n",
      "epoch[64/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[64/100] training loss 0.00309, training accuracy 0.93750\n",
      "epoch[64/100] training loss 0.00312, training accuracy 0.93750\n",
      "epoch[64/100] training loss 0.00313, training accuracy 0.95312\n",
      "epoch[64/100] training loss 0.00305, training accuracy 0.93750\n",
      "epoch[64/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[64/100] training loss 0.00313, training accuracy 0.95312\n",
      "epoch[64/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[64/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[64/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[64/100] training loss 0.00326, training accuracy 0.93359\n",
      "epoch[64/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[64/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[64/100] training loss 0.00314, training accuracy 0.92578\n",
      "epoch[64/100] training loss 0.00296, training accuracy 0.98047\n",
      "epoch[64/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[64/100] training loss 0.00319, training accuracy 0.94531\n",
      "epoch[64/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[64/100] training loss 0.00320, training accuracy 0.92578\n",
      "epoch[64/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[64/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[64/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[64/100] training loss 0.00311, training accuracy 0.96094\n",
      "epoch[64/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[64/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[64/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[64/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[64/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[64/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[64/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[64/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[64/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[64/100] training loss 0.00306, training accuracy 0.94531\n",
      "epoch[64/100] training loss 0.00299, training accuracy 0.95703\n",
      "epoch[64/100] training loss 0.00310, training accuracy 0.93750\n",
      "epoch[64/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[64/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[64/100] training loss 0.00306, training accuracy 0.94141\n",
      "epoch[64/100] training loss 0.00298, training accuracy 0.97656\n",
      "epoch[64/100] training loss 0.00305, training accuracy 0.94922\n",
      "epoch[64/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[64/100] training loss 0.00291, training accuracy 0.98047\n",
      "epoch[64/100] training loss 0.00307, training accuracy 0.06250\n",
      "[val] acc : 0.91693, loss : 0.82396\n",
      "best acc : 0.91720, best loss : 0.82396\n",
      "epoch[65/100] training loss 0.00308, training accuracy 0.94531\n",
      "epoch[65/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[65/100] training loss 0.00310, training accuracy 0.94141\n",
      "epoch[65/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[65/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[65/100] training loss 0.00313, training accuracy 0.92969\n",
      "epoch[65/100] training loss 0.00294, training accuracy 0.97266\n",
      "epoch[65/100] training loss 0.00310, training accuracy 0.93750\n",
      "epoch[65/100] training loss 0.00299, training accuracy 0.95312\n",
      "epoch[65/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[65/100] training loss 0.00323, training accuracy 0.93359\n",
      "epoch[65/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[65/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[65/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[65/100] training loss 0.00299, training accuracy 0.94922\n",
      "epoch[65/100] training loss 0.00309, training accuracy 0.96094\n",
      "epoch[65/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00320, training accuracy 0.94531\n",
      "epoch[65/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[65/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[65/100] training loss 0.00290, training accuracy 0.98438\n",
      "epoch[65/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[65/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[65/100] training loss 0.00317, training accuracy 0.91406\n",
      "epoch[65/100] training loss 0.00311, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[65/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00307, training accuracy 0.94141\n",
      "epoch[65/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[65/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[65/100] training loss 0.00318, training accuracy 0.91797\n",
      "epoch[65/100] training loss 0.00319, training accuracy 0.94922\n",
      "epoch[65/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[65/100] training loss 0.00313, training accuracy 0.92969\n",
      "epoch[65/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00296, training accuracy 0.96875\n",
      "epoch[65/100] training loss 0.00308, training accuracy 0.94531\n",
      "epoch[65/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[65/100] training loss 0.00299, training accuracy 0.97656\n",
      "epoch[65/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00293, training accuracy 0.96875\n",
      "epoch[65/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[65/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[65/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[65/100] training loss 0.00309, training accuracy 0.92969\n",
      "epoch[65/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[65/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[65/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[65/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[65/100] training loss 0.00300, training accuracy 0.97656\n",
      "epoch[65/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[65/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[65/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[65/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[65/100] training loss 0.00294, training accuracy 0.06250\n",
      "[val] acc : 0.91693, loss : 0.82373\n",
      "best acc : 0.91720, best loss : 0.82373\n",
      "epoch[66/100] training loss 0.00293, training accuracy 0.96484\n",
      "epoch[66/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[66/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[66/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00299, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00309, training accuracy 0.94141\n",
      "epoch[66/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[66/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[66/100] training loss 0.00302, training accuracy 0.96484\n",
      "epoch[66/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[66/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[66/100] training loss 0.00306, training accuracy 0.93359\n",
      "epoch[66/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[66/100] training loss 0.00321, training accuracy 0.92578\n",
      "epoch[66/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[66/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[66/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[66/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[66/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[66/100] training loss 0.00313, training accuracy 0.96094\n",
      "epoch[66/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[66/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00290, training accuracy 0.96484\n",
      "epoch[66/100] training loss 0.00294, training accuracy 0.97266\n",
      "epoch[66/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[66/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[66/100] training loss 0.00310, training accuracy 0.96094\n",
      "epoch[66/100] training loss 0.00312, training accuracy 0.93750\n",
      "epoch[66/100] training loss 0.00293, training accuracy 0.97266\n",
      "epoch[66/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00313, training accuracy 0.93750\n",
      "epoch[66/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[66/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[66/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[66/100] training loss 0.00295, training accuracy 0.97656\n",
      "epoch[66/100] training loss 0.00296, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[66/100] training loss 0.00292, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00318, training accuracy 0.93359\n",
      "epoch[66/100] training loss 0.00303, training accuracy 0.96875\n",
      "epoch[66/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[66/100] training loss 0.00310, training accuracy 0.94141\n",
      "epoch[66/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[66/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[66/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00307, training accuracy 0.94141\n",
      "epoch[66/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[66/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[66/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[66/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[66/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[66/100] training loss 0.00291, training accuracy 0.98438\n",
      "epoch[66/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[66/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[66/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[66/100] training loss 0.00316, training accuracy 0.95703\n",
      "epoch[66/100] training loss 0.00262, training accuracy 0.06250\n",
      "[val] acc : 0.91746, loss : 0.82209\n",
      "best acc : 0.91746, best loss : 0.82209\n",
      "epoch[67/100] training loss 0.00292, training accuracy 0.96875\n",
      "epoch[67/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[67/100] training loss 0.00314, training accuracy 0.93750\n",
      "epoch[67/100] training loss 0.00286, training accuracy 0.98047\n",
      "epoch[67/100] training loss 0.00302, training accuracy 0.97266\n",
      "epoch[67/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[67/100] training loss 0.00315, training accuracy 0.95703\n",
      "epoch[67/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[67/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[67/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[67/100] training loss 0.00323, training accuracy 0.93750\n",
      "epoch[67/100] training loss 0.00305, training accuracy 0.94922\n",
      "epoch[67/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[67/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[67/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[67/100] training loss 0.00304, training accuracy 0.94531\n",
      "epoch[67/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[67/100] training loss 0.00313, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[67/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[67/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[67/100] training loss 0.00294, training accuracy 0.95703\n",
      "epoch[67/100] training loss 0.00302, training accuracy 0.94531\n",
      "epoch[67/100] training loss 0.00297, training accuracy 0.97656\n",
      "epoch[67/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[67/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[67/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00302, training accuracy 0.94531\n",
      "epoch[67/100] training loss 0.00310, training accuracy 0.94141\n",
      "epoch[67/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[67/100] training loss 0.00316, training accuracy 0.92188\n",
      "epoch[67/100] training loss 0.00312, training accuracy 0.97266\n",
      "epoch[67/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[67/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[67/100] training loss 0.00296, training accuracy 0.97656\n",
      "epoch[67/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[67/100] training loss 0.00306, training accuracy 0.96875\n",
      "epoch[67/100] training loss 0.00312, training accuracy 0.95703\n",
      "epoch[67/100] training loss 0.00308, training accuracy 0.96484\n",
      "epoch[67/100] training loss 0.00314, training accuracy 0.95312\n",
      "epoch[67/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00301, training accuracy 0.95312\n",
      "epoch[67/100] training loss 0.00330, training accuracy 0.91797\n",
      "epoch[67/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[67/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[67/100] training loss 0.00301, training accuracy 0.97656\n",
      "epoch[67/100] training loss 0.00307, training accuracy 0.93750\n",
      "epoch[67/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[67/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[67/100] training loss 0.00304, training accuracy 0.96875\n",
      "epoch[67/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[67/100] training loss 0.00373, training accuracy 0.05078\n",
      "[val] acc : 0.91720, loss : 0.82070\n",
      "best acc : 0.91746, best loss : 0.82070\n",
      "epoch[68/100] training loss 0.00322, training accuracy 0.93359\n",
      "epoch[68/100] training loss 0.00309, training accuracy 0.96875\n",
      "epoch[68/100] training loss 0.00308, training accuracy 0.96484\n",
      "epoch[68/100] training loss 0.00317, training accuracy 0.94531\n",
      "epoch[68/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[68/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[68/100] training loss 0.00315, training accuracy 0.96094\n",
      "epoch[68/100] training loss 0.00306, training accuracy 0.94141\n",
      "epoch[68/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[68/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[68/100] training loss 0.00301, training accuracy 0.97266\n",
      "epoch[68/100] training loss 0.00309, training accuracy 0.94141\n",
      "epoch[68/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[68/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[68/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[68/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[68/100] training loss 0.00300, training accuracy 0.98047\n",
      "epoch[68/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[68/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[68/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[68/100] training loss 0.00318, training accuracy 0.93359\n",
      "epoch[68/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[68/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[68/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[68/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[68/100] training loss 0.00302, training accuracy 0.97266\n",
      "epoch[68/100] training loss 0.00315, training accuracy 0.94922\n",
      "epoch[68/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[68/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[68/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[68/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[68/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[68/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[68/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[68/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[68/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[68/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[68/100] training loss 0.00316, training accuracy 0.94922\n",
      "epoch[68/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[68/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[68/100] training loss 0.00296, training accuracy 0.96875\n",
      "epoch[68/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[68/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[68/100] training loss 0.00313, training accuracy 0.92969\n",
      "epoch[68/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[68/100] training loss 0.00318, training accuracy 0.94531\n",
      "epoch[68/100] training loss 0.00310, training accuracy 0.96484\n",
      "epoch[68/100] training loss 0.00307, training accuracy 0.96484\n",
      "epoch[68/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[68/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[68/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[68/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[68/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[68/100] training loss 0.00314, training accuracy 0.95312\n",
      "epoch[68/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[68/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[68/100] training loss 0.00321, training accuracy 0.91406\n",
      "epoch[68/100] training loss 0.00314, training accuracy 0.93359\n",
      "epoch[68/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[68/100] training loss 0.00277, training accuracy 0.06250\n",
      "[val] acc : 0.91958, loss : 0.82236\n",
      "best acc : 0.91958, best loss : 0.82070\n",
      "epoch[69/100] training loss 0.00311, training accuracy 0.92969\n",
      "epoch[69/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[69/100] training loss 0.00310, training accuracy 0.93359\n",
      "epoch[69/100] training loss 0.00318, training accuracy 0.93750\n",
      "epoch[69/100] training loss 0.00322, training accuracy 0.92578\n",
      "epoch[69/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[69/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[69/100] training loss 0.00310, training accuracy 0.96094\n",
      "epoch[69/100] training loss 0.00307, training accuracy 0.94141\n",
      "epoch[69/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[69/100] training loss 0.00305, training accuracy 0.94922\n",
      "epoch[69/100] training loss 0.00305, training accuracy 0.96484\n",
      "epoch[69/100] training loss 0.00322, training accuracy 0.92969\n",
      "epoch[69/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[69/100] training loss 0.00316, training accuracy 0.94531\n",
      "epoch[69/100] training loss 0.00293, training accuracy 0.96484\n",
      "epoch[69/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[69/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[69/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[69/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[69/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[69/100] training loss 0.00309, training accuracy 0.94141\n",
      "epoch[69/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[69/100] training loss 0.00301, training accuracy 0.94922\n",
      "epoch[69/100] training loss 0.00298, training accuracy 0.97266\n",
      "epoch[69/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[69/100] training loss 0.00303, training accuracy 0.94141\n",
      "epoch[69/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[69/100] training loss 0.00295, training accuracy 0.97656\n",
      "epoch[69/100] training loss 0.00295, training accuracy 0.95312\n",
      "epoch[69/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[69/100] training loss 0.00303, training accuracy 0.94141\n",
      "epoch[69/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[69/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[69/100] training loss 0.00297, training accuracy 0.98047\n",
      "epoch[69/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[69/100] training loss 0.00312, training accuracy 0.96094\n",
      "epoch[69/100] training loss 0.00310, training accuracy 0.93359\n",
      "epoch[69/100] training loss 0.00303, training accuracy 0.97656\n",
      "epoch[69/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[69/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[69/100] training loss 0.00314, training accuracy 0.95703\n",
      "epoch[69/100] training loss 0.00321, training accuracy 0.94141\n",
      "epoch[69/100] training loss 0.00310, training accuracy 0.93359\n",
      "epoch[69/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[69/100] training loss 0.00293, training accuracy 0.96875\n",
      "epoch[69/100] training loss 0.00316, training accuracy 0.92969\n",
      "epoch[69/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[69/100] training loss 0.00301, training accuracy 0.94922\n",
      "epoch[69/100] training loss 0.00296, training accuracy 0.97656\n",
      "epoch[69/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[69/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[69/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[69/100] training loss 0.00321, training accuracy 0.92969\n",
      "epoch[69/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[69/100] training loss 0.00303, training accuracy 0.94141\n",
      "epoch[69/100] training loss 0.00293, training accuracy 0.96875\n",
      "epoch[69/100] training loss 0.00319, training accuracy 0.94922\n",
      "epoch[69/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[69/100] training loss 0.00321, training accuracy 0.05469\n",
      "[val] acc : 0.91587, loss : 0.82089\n",
      "best acc : 0.91958, best loss : 0.82070\n",
      "epoch[70/100] training loss 0.00294, training accuracy 0.97656\n",
      "epoch[70/100] training loss 0.00312, training accuracy 0.93750\n",
      "epoch[70/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[70/100] training loss 0.00307, training accuracy 0.94531\n",
      "epoch[70/100] training loss 0.00326, training accuracy 0.91406\n",
      "epoch[70/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[70/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[70/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[70/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[70/100] training loss 0.00318, training accuracy 0.93359\n",
      "epoch[70/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[70/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[70/100] training loss 0.00298, training accuracy 0.97266\n",
      "epoch[70/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[70/100] training loss 0.00314, training accuracy 0.93359\n",
      "epoch[70/100] training loss 0.00302, training accuracy 0.97266\n",
      "epoch[70/100] training loss 0.00321, training accuracy 0.93750\n",
      "epoch[70/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[70/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[70/100] training loss 0.00316, training accuracy 0.94922\n",
      "epoch[70/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[70/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[70/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[70/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[70/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[70/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[70/100] training loss 0.00299, training accuracy 0.97656\n",
      "epoch[70/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[70/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[70/100] training loss 0.00296, training accuracy 0.96875\n",
      "epoch[70/100] training loss 0.00291, training accuracy 0.99219\n",
      "epoch[70/100] training loss 0.00295, training accuracy 0.97266\n",
      "epoch[70/100] training loss 0.00319, training accuracy 0.93359\n",
      "epoch[70/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[70/100] training loss 0.00314, training accuracy 0.92969\n",
      "epoch[70/100] training loss 0.00304, training accuracy 0.96875\n",
      "epoch[70/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[70/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[70/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[70/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[70/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[70/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[70/100] training loss 0.00304, training accuracy 0.96875\n",
      "epoch[70/100] training loss 0.00332, training accuracy 0.91406\n",
      "epoch[70/100] training loss 0.00284, training accuracy 0.98828\n",
      "epoch[70/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[70/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[70/100] training loss 0.00324, training accuracy 0.92969\n",
      "epoch[70/100] training loss 0.00316, training accuracy 0.94922\n",
      "epoch[70/100] training loss 0.00288, training accuracy 0.97656\n",
      "epoch[70/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[70/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[70/100] training loss 0.00317, training accuracy 0.94922\n",
      "epoch[70/100] training loss 0.00301, training accuracy 0.96875\n",
      "epoch[70/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[70/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[70/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[70/100] training loss 0.00322, training accuracy 0.93750\n",
      "epoch[70/100] training loss 0.00300, training accuracy 0.97266\n",
      "epoch[70/100] training loss 0.00291, training accuracy 0.06250\n",
      "[val] acc : 0.92143, loss : 0.82487\n",
      "best acc : 0.92143, best loss : 0.82070\n",
      "epoch[71/100] training loss 0.00300, training accuracy 0.97266\n",
      "epoch[71/100] training loss 0.00309, training accuracy 0.96094\n",
      "epoch[71/100] training loss 0.00303, training accuracy 0.97266\n",
      "epoch[71/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[71/100] training loss 0.00304, training accuracy 0.97266\n",
      "epoch[71/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[71/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[71/100] training loss 0.00298, training accuracy 0.97656\n",
      "epoch[71/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[71/100] training loss 0.00316, training accuracy 0.93750\n",
      "epoch[71/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[71/100] training loss 0.00311, training accuracy 0.95703\n",
      "epoch[71/100] training loss 0.00309, training accuracy 0.93359\n",
      "epoch[71/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[71/100] training loss 0.00312, training accuracy 0.96094\n",
      "epoch[71/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[71/100] training loss 0.00308, training accuracy 0.94531\n",
      "epoch[71/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[71/100] training loss 0.00314, training accuracy 0.95312\n",
      "epoch[71/100] training loss 0.00306, training accuracy 0.94141\n",
      "epoch[71/100] training loss 0.00300, training accuracy 0.98438\n",
      "epoch[71/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[71/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[71/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[71/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[71/100] training loss 0.00318, training accuracy 0.94141\n",
      "epoch[71/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[71/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[71/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[71/100] training loss 0.00299, training accuracy 0.95312\n",
      "epoch[71/100] training loss 0.00307, training accuracy 0.96484\n",
      "epoch[71/100] training loss 0.00309, training accuracy 0.93750\n",
      "epoch[71/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[71/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[71/100] training loss 0.00298, training accuracy 0.98047\n",
      "epoch[71/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[71/100] training loss 0.00301, training accuracy 0.97266\n",
      "epoch[71/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[71/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[71/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[71/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[71/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[71/100] training loss 0.00292, training accuracy 0.98047\n",
      "epoch[71/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[71/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[71/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[71/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[71/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[71/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[71/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[71/100] training loss 0.00302, training accuracy 0.96484\n",
      "epoch[71/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[71/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[71/100] training loss 0.00301, training accuracy 0.96875\n",
      "epoch[71/100] training loss 0.00312, training accuracy 0.93750\n",
      "epoch[71/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[71/100] training loss 0.00309, training accuracy 0.92969\n",
      "epoch[71/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[71/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[71/100] training loss 0.00380, training accuracy 0.05078\n",
      "[val] acc : 0.92328, loss : 0.82058\n",
      "best acc : 0.92328, best loss : 0.82058\n",
      "epoch[72/100] training loss 0.00295, training accuracy 0.96875\n",
      "epoch[72/100] training loss 0.00298, training accuracy 0.97656\n",
      "epoch[72/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[72/100] training loss 0.00312, training accuracy 0.96094\n",
      "epoch[72/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[72/100] training loss 0.00320, training accuracy 0.95312\n",
      "epoch[72/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[72/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[72/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[72/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[72/100] training loss 0.00312, training accuracy 0.92969\n",
      "epoch[72/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[72/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[72/100] training loss 0.00309, training accuracy 0.94141\n",
      "epoch[72/100] training loss 0.00322, training accuracy 0.93359\n",
      "epoch[72/100] training loss 0.00304, training accuracy 0.94141\n",
      "epoch[72/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[72/100] training loss 0.00331, training accuracy 0.92578\n",
      "epoch[72/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[72/100] training loss 0.00313, training accuracy 0.96875\n",
      "epoch[72/100] training loss 0.00319, training accuracy 0.94141\n",
      "epoch[72/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[72/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[72/100] training loss 0.00288, training accuracy 0.96484\n",
      "epoch[72/100] training loss 0.00307, training accuracy 0.93359\n",
      "epoch[72/100] training loss 0.00299, training accuracy 0.95703\n",
      "epoch[72/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[72/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[72/100] training loss 0.00313, training accuracy 0.93359\n",
      "epoch[72/100] training loss 0.00305, training accuracy 0.96484\n",
      "epoch[72/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[72/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[72/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[72/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[72/100] training loss 0.00294, training accuracy 0.97266\n",
      "epoch[72/100] training loss 0.00320, training accuracy 0.92188\n",
      "epoch[72/100] training loss 0.00318, training accuracy 0.93359\n",
      "epoch[72/100] training loss 0.00315, training accuracy 0.94922\n",
      "epoch[72/100] training loss 0.00299, training accuracy 0.95703\n",
      "epoch[72/100] training loss 0.00307, training accuracy 0.94141\n",
      "epoch[72/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[72/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[72/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[72/100] training loss 0.00304, training accuracy 0.94141\n",
      "epoch[72/100] training loss 0.00314, training accuracy 0.95312\n",
      "epoch[72/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[72/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[72/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[72/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[72/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[72/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[72/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[72/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[72/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[72/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[72/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[72/100] training loss 0.00305, training accuracy 0.92969\n",
      "epoch[72/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[72/100] training loss 0.00306, training accuracy 0.94141\n",
      "epoch[72/100] training loss 0.00326, training accuracy 0.05859\n",
      "[val] acc : 0.91534, loss : 0.82060\n",
      "best acc : 0.92328, best loss : 0.82058\n",
      "epoch[73/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[73/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[73/100] training loss 0.00297, training accuracy 0.94922\n",
      "epoch[73/100] training loss 0.00298, training accuracy 0.97266\n",
      "epoch[73/100] training loss 0.00309, training accuracy 0.94141\n",
      "epoch[73/100] training loss 0.00302, training accuracy 0.94922\n",
      "epoch[73/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[73/100] training loss 0.00302, training accuracy 0.97266\n",
      "epoch[73/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[73/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[73/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[73/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[73/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[73/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[73/100] training loss 0.00305, training accuracy 0.94922\n",
      "epoch[73/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[73/100] training loss 0.00298, training accuracy 0.97656\n",
      "epoch[73/100] training loss 0.00300, training accuracy 0.94531\n",
      "epoch[73/100] training loss 0.00299, training accuracy 0.95703\n",
      "epoch[73/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[73/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[73/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[73/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[73/100] training loss 0.00305, training accuracy 0.94922\n",
      "epoch[73/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[73/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[73/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[73/100] training loss 0.00310, training accuracy 0.95312\n",
      "epoch[73/100] training loss 0.00294, training accuracy 0.97266\n",
      "epoch[73/100] training loss 0.00296, training accuracy 0.98047\n",
      "epoch[73/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[73/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[73/100] training loss 0.00291, training accuracy 0.97266\n",
      "epoch[73/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[73/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[73/100] training loss 0.00308, training accuracy 0.96484\n",
      "epoch[73/100] training loss 0.00305, training accuracy 0.96875\n",
      "epoch[73/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[73/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[73/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[73/100] training loss 0.00299, training accuracy 0.95312\n",
      "epoch[73/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[73/100] training loss 0.00304, training accuracy 0.96875\n",
      "epoch[73/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[73/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[73/100] training loss 0.00314, training accuracy 0.93750\n",
      "epoch[73/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[73/100] training loss 0.00290, training accuracy 0.97656\n",
      "epoch[73/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[73/100] training loss 0.00288, training accuracy 0.98828\n",
      "epoch[73/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[73/100] training loss 0.00324, training accuracy 0.93359\n",
      "epoch[73/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[73/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[73/100] training loss 0.00310, training accuracy 0.94141\n",
      "epoch[73/100] training loss 0.00300, training accuracy 0.97266\n",
      "epoch[73/100] training loss 0.00319, training accuracy 0.95312\n",
      "epoch[73/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[73/100] training loss 0.00307, training accuracy 0.94531\n",
      "epoch[73/100] training loss 0.00309, training accuracy 0.06250\n",
      "[val] acc : 0.92354, loss : 0.81412\n",
      "best acc : 0.92354, best loss : 0.81412\n",
      "epoch[74/100] training loss 0.00309, training accuracy 0.96094\n",
      "epoch[74/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[74/100] training loss 0.00299, training accuracy 0.97656\n",
      "epoch[74/100] training loss 0.00313, training accuracy 0.94922\n",
      "epoch[74/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[74/100] training loss 0.00299, training accuracy 0.94922\n",
      "epoch[74/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[74/100] training loss 0.00293, training accuracy 0.98047\n",
      "epoch[74/100] training loss 0.00309, training accuracy 0.96484\n",
      "epoch[74/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[74/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[74/100] training loss 0.00326, training accuracy 0.92188\n",
      "epoch[74/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[74/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[74/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[74/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[74/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[74/100] training loss 0.00289, training accuracy 0.98438\n",
      "epoch[74/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[74/100] training loss 0.00308, training accuracy 0.93359\n",
      "epoch[74/100] training loss 0.00306, training accuracy 0.94531\n",
      "epoch[74/100] training loss 0.00296, training accuracy 0.97656\n",
      "epoch[74/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[74/100] training loss 0.00312, training accuracy 0.93750\n",
      "epoch[74/100] training loss 0.00290, training accuracy 0.98047\n",
      "epoch[74/100] training loss 0.00296, training accuracy 0.96094\n",
      "epoch[74/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[74/100] training loss 0.00316, training accuracy 0.94531\n",
      "epoch[74/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[74/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[74/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[74/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[74/100] training loss 0.00310, training accuracy 0.94141\n",
      "epoch[74/100] training loss 0.00292, training accuracy 0.97266\n",
      "epoch[74/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[74/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[74/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[74/100] training loss 0.00318, training accuracy 0.94531\n",
      "epoch[74/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[74/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[74/100] training loss 0.00307, training accuracy 0.96484\n",
      "epoch[74/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[74/100] training loss 0.00303, training accuracy 0.96875\n",
      "epoch[74/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[74/100] training loss 0.00313, training accuracy 0.93359\n",
      "epoch[74/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[74/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[74/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[74/100] training loss 0.00299, training accuracy 0.98047\n",
      "epoch[74/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[74/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[74/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[74/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[74/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[74/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[74/100] training loss 0.00305, training accuracy 0.94141\n",
      "epoch[74/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[74/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[74/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[74/100] training loss 0.00280, training accuracy 0.06250\n",
      "[val] acc : 0.92063, loss : 0.81289\n",
      "best acc : 0.92354, best loss : 0.81289\n",
      "epoch[75/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[75/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[75/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[75/100] training loss 0.00312, training accuracy 0.92969\n",
      "epoch[75/100] training loss 0.00308, training accuracy 0.96484\n",
      "epoch[75/100] training loss 0.00287, training accuracy 0.97266\n",
      "epoch[75/100] training loss 0.00313, training accuracy 0.95312\n",
      "epoch[75/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[75/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[75/100] training loss 0.00308, training accuracy 0.94531\n",
      "epoch[75/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[75/100] training loss 0.00294, training accuracy 0.96094\n",
      "epoch[75/100] training loss 0.00301, training accuracy 0.95312\n",
      "epoch[75/100] training loss 0.00297, training accuracy 0.97656\n",
      "epoch[75/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[75/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[75/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[75/100] training loss 0.00310, training accuracy 0.94922\n",
      "epoch[75/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[75/100] training loss 0.00301, training accuracy 0.94922\n",
      "epoch[75/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[75/100] training loss 0.00286, training accuracy 0.97266\n",
      "epoch[75/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[75/100] training loss 0.00292, training accuracy 0.96484\n",
      "epoch[75/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[75/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[75/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[75/100] training loss 0.00296, training accuracy 0.95312\n",
      "epoch[75/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[75/100] training loss 0.00304, training accuracy 0.94922\n",
      "epoch[75/100] training loss 0.00307, training accuracy 0.94141\n",
      "epoch[75/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[75/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[75/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[75/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[75/100] training loss 0.00308, training accuracy 0.93750\n",
      "epoch[75/100] training loss 0.00306, training accuracy 0.93359\n",
      "epoch[75/100] training loss 0.00293, training accuracy 0.97266\n",
      "epoch[75/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[75/100] training loss 0.00296, training accuracy 0.98047\n",
      "epoch[75/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[75/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[75/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[75/100] training loss 0.00315, training accuracy 0.92969\n",
      "epoch[75/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[75/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[75/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[75/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[75/100] training loss 0.00303, training accuracy 0.94531\n",
      "epoch[75/100] training loss 0.00310, training accuracy 0.94141\n",
      "epoch[75/100] training loss 0.00294, training accuracy 0.96875\n",
      "epoch[75/100] training loss 0.00308, training accuracy 0.96484\n",
      "epoch[75/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[75/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[75/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[75/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[75/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[75/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[75/100] training loss 0.00291, training accuracy 0.98438\n",
      "epoch[75/100] training loss 0.00307, training accuracy 0.05859\n",
      "[val] acc : 0.91455, loss : 0.82018\n",
      "best acc : 0.92354, best loss : 0.81289\n",
      "epoch[76/100] training loss 0.00286, training accuracy 0.98047\n",
      "epoch[76/100] training loss 0.00307, training accuracy 0.93750\n",
      "epoch[76/100] training loss 0.00304, training accuracy 0.94922\n",
      "epoch[76/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[76/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[76/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[76/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[76/100] training loss 0.00317, training accuracy 0.93750\n",
      "epoch[76/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[76/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[76/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[76/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[76/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[76/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[76/100] training loss 0.00296, training accuracy 0.96875\n",
      "epoch[76/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[76/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[76/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[76/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[76/100] training loss 0.00292, training accuracy 0.97266\n",
      "epoch[76/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[76/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[76/100] training loss 0.00314, training accuracy 0.93359\n",
      "epoch[76/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[76/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[76/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[76/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[76/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[76/100] training loss 0.00304, training accuracy 0.94141\n",
      "epoch[76/100] training loss 0.00303, training accuracy 0.94141\n",
      "epoch[76/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[76/100] training loss 0.00281, training accuracy 0.98828\n",
      "epoch[76/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[76/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[76/100] training loss 0.00295, training accuracy 0.97266\n",
      "epoch[76/100] training loss 0.00283, training accuracy 0.98438\n",
      "epoch[76/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[76/100] training loss 0.00310, training accuracy 0.96484\n",
      "epoch[76/100] training loss 0.00311, training accuracy 0.94141\n",
      "epoch[76/100] training loss 0.00307, training accuracy 0.93750\n",
      "epoch[76/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[76/100] training loss 0.00298, training accuracy 0.97266\n",
      "epoch[76/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[76/100] training loss 0.00296, training accuracy 0.97656\n",
      "epoch[76/100] training loss 0.00303, training accuracy 0.97266\n",
      "epoch[76/100] training loss 0.00299, training accuracy 0.98047\n",
      "epoch[76/100] training loss 0.00311, training accuracy 0.93359\n",
      "epoch[76/100] training loss 0.00289, training accuracy 0.98047\n",
      "epoch[76/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[76/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[76/100] training loss 0.00321, training accuracy 0.92578\n",
      "epoch[76/100] training loss 0.00307, training accuracy 0.94141\n",
      "epoch[76/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[76/100] training loss 0.00296, training accuracy 0.96484\n",
      "epoch[76/100] training loss 0.00291, training accuracy 0.96875\n",
      "epoch[76/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[76/100] training loss 0.00293, training accuracy 0.97656\n",
      "epoch[76/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[76/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[76/100] training loss 0.00323, training accuracy 0.06250\n",
      "[val] acc : 0.91799, loss : 0.82456\n",
      "best acc : 0.92354, best loss : 0.81289\n",
      "epoch[77/100] training loss 0.00307, training accuracy 0.96484\n",
      "epoch[77/100] training loss 0.00292, training accuracy 0.98438\n",
      "epoch[77/100] training loss 0.00320, training accuracy 0.92578\n",
      "epoch[77/100] training loss 0.00311, training accuracy 0.92578\n",
      "epoch[77/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[77/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[77/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[77/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[77/100] training loss 0.00311, training accuracy 0.96484\n",
      "epoch[77/100] training loss 0.00316, training accuracy 0.94531\n",
      "epoch[77/100] training loss 0.00305, training accuracy 0.94141\n",
      "epoch[77/100] training loss 0.00315, training accuracy 0.93750\n",
      "epoch[77/100] training loss 0.00319, training accuracy 0.93750\n",
      "epoch[77/100] training loss 0.00310, training accuracy 0.94141\n",
      "epoch[77/100] training loss 0.00305, training accuracy 0.96875\n",
      "epoch[77/100] training loss 0.00301, training accuracy 0.97656\n",
      "epoch[77/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[77/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[77/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[77/100] training loss 0.00310, training accuracy 0.96484\n",
      "epoch[77/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[77/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[77/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[77/100] training loss 0.00317, training accuracy 0.94141\n",
      "epoch[77/100] training loss 0.00292, training accuracy 0.96094\n",
      "epoch[77/100] training loss 0.00293, training accuracy 0.96484\n",
      "epoch[77/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[77/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[77/100] training loss 0.00287, training accuracy 0.96875\n",
      "epoch[77/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[77/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[77/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[77/100] training loss 0.00312, training accuracy 0.95703\n",
      "epoch[77/100] training loss 0.00315, training accuracy 0.93359\n",
      "epoch[77/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[77/100] training loss 0.00295, training accuracy 0.96875\n",
      "epoch[77/100] training loss 0.00303, training accuracy 0.96875\n",
      "epoch[77/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[77/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[77/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[77/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[77/100] training loss 0.00293, training accuracy 0.97656\n",
      "epoch[77/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[77/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[77/100] training loss 0.00301, training accuracy 0.94922\n",
      "epoch[77/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[77/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[77/100] training loss 0.00292, training accuracy 0.96875\n",
      "epoch[77/100] training loss 0.00314, training accuracy 0.95703\n",
      "epoch[77/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[77/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[77/100] training loss 0.00312, training accuracy 0.93359\n",
      "epoch[77/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[77/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[77/100] training loss 0.00304, training accuracy 0.94922\n",
      "epoch[77/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[77/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[77/100] training loss 0.00326, training accuracy 0.92578\n",
      "epoch[77/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[77/100] training loss 0.00342, training accuracy 0.05469\n",
      "[val] acc : 0.91852, loss : 0.81818\n",
      "best acc : 0.92354, best loss : 0.81289\n",
      "epoch[78/100] training loss 0.00307, training accuracy 0.94531\n",
      "epoch[78/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[78/100] training loss 0.00307, training accuracy 0.94531\n",
      "epoch[78/100] training loss 0.00309, training accuracy 0.94531\n",
      "epoch[78/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[78/100] training loss 0.00315, training accuracy 0.94531\n",
      "epoch[78/100] training loss 0.00319, training accuracy 0.92188\n",
      "epoch[78/100] training loss 0.00330, training accuracy 0.92578\n",
      "epoch[78/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[78/100] training loss 0.00305, training accuracy 0.96484\n",
      "epoch[78/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[78/100] training loss 0.00318, training accuracy 0.94922\n",
      "epoch[78/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[78/100] training loss 0.00309, training accuracy 0.95312\n",
      "epoch[78/100] training loss 0.00316, training accuracy 0.93359\n",
      "epoch[78/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[78/100] training loss 0.00301, training accuracy 0.96875\n",
      "epoch[78/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[78/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[78/100] training loss 0.00321, training accuracy 0.92578\n",
      "epoch[78/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[78/100] training loss 0.00312, training accuracy 0.95703\n",
      "epoch[78/100] training loss 0.00314, training accuracy 0.93750\n",
      "epoch[78/100] training loss 0.00295, training accuracy 0.97656\n",
      "epoch[78/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[78/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[78/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[78/100] training loss 0.00293, training accuracy 0.98047\n",
      "epoch[78/100] training loss 0.00293, training accuracy 0.98047\n",
      "epoch[78/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[78/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[78/100] training loss 0.00317, training accuracy 0.92969\n",
      "epoch[78/100] training loss 0.00300, training accuracy 0.94922\n",
      "epoch[78/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[78/100] training loss 0.00299, training accuracy 0.94922\n",
      "epoch[78/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[78/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[78/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[78/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[78/100] training loss 0.00314, training accuracy 0.93750\n",
      "epoch[78/100] training loss 0.00306, training accuracy 0.94531\n",
      "epoch[78/100] training loss 0.00296, training accuracy 0.96094\n",
      "epoch[78/100] training loss 0.00311, training accuracy 0.96094\n",
      "epoch[78/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[78/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[78/100] training loss 0.00299, training accuracy 0.98047\n",
      "epoch[78/100] training loss 0.00285, training accuracy 0.98828\n",
      "epoch[78/100] training loss 0.00307, training accuracy 0.96484\n",
      "epoch[78/100] training loss 0.00302, training accuracy 0.96484\n",
      "epoch[78/100] training loss 0.00308, training accuracy 0.92969\n",
      "epoch[78/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[78/100] training loss 0.00289, training accuracy 0.98047\n",
      "epoch[78/100] training loss 0.00297, training accuracy 0.97656\n",
      "epoch[78/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[78/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[78/100] training loss 0.00305, training accuracy 0.96484\n",
      "epoch[78/100] training loss 0.00293, training accuracy 0.96875\n",
      "epoch[78/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[78/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[78/100] training loss 0.00271, training accuracy 0.06250\n",
      "[val] acc : 0.92090, loss : 0.81944\n",
      "best acc : 0.92354, best loss : 0.81289\n",
      "epoch[79/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[79/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[79/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[79/100] training loss 0.00291, training accuracy 0.97656\n",
      "epoch[79/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[79/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[79/100] training loss 0.00301, training accuracy 0.95312\n",
      "epoch[79/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[79/100] training loss 0.00293, training accuracy 0.98047\n",
      "epoch[79/100] training loss 0.00296, training accuracy 0.96875\n",
      "epoch[79/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[79/100] training loss 0.00295, training accuracy 0.97266\n",
      "epoch[79/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[79/100] training loss 0.00289, training accuracy 0.98438\n",
      "epoch[79/100] training loss 0.00295, training accuracy 0.97656\n",
      "epoch[79/100] training loss 0.00297, training accuracy 0.94922\n",
      "epoch[79/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[79/100] training loss 0.00313, training accuracy 0.94141\n",
      "epoch[79/100] training loss 0.00295, training accuracy 0.98047\n",
      "epoch[79/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[79/100] training loss 0.00299, training accuracy 0.94922\n",
      "epoch[79/100] training loss 0.00291, training accuracy 0.96484\n",
      "epoch[79/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[79/100] training loss 0.00288, training accuracy 0.97656\n",
      "epoch[79/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[79/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[79/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[79/100] training loss 0.00297, training accuracy 0.98047\n",
      "epoch[79/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[79/100] training loss 0.00291, training accuracy 0.96484\n",
      "epoch[79/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[79/100] training loss 0.00299, training accuracy 0.94141\n",
      "epoch[79/100] training loss 0.00316, training accuracy 0.94141\n",
      "epoch[79/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[79/100] training loss 0.00289, training accuracy 0.98047\n",
      "epoch[79/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[79/100] training loss 0.00299, training accuracy 0.95703\n",
      "epoch[79/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[79/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[79/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[79/100] training loss 0.00314, training accuracy 0.94531\n",
      "epoch[79/100] training loss 0.00295, training accuracy 0.97656\n",
      "epoch[79/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[79/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[79/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[79/100] training loss 0.00294, training accuracy 0.96875\n",
      "epoch[79/100] training loss 0.00295, training accuracy 0.97266\n",
      "epoch[79/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[79/100] training loss 0.00292, training accuracy 0.98047\n",
      "epoch[79/100] training loss 0.00306, training accuracy 0.96875\n",
      "epoch[79/100] training loss 0.00285, training accuracy 0.98047\n",
      "epoch[79/100] training loss 0.00307, training accuracy 0.94141\n",
      "epoch[79/100] training loss 0.00297, training accuracy 0.95312\n",
      "epoch[79/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[79/100] training loss 0.00294, training accuracy 0.96094\n",
      "epoch[79/100] training loss 0.00293, training accuracy 0.96484\n",
      "epoch[79/100] training loss 0.00298, training accuracy 0.94922\n",
      "epoch[79/100] training loss 0.00304, training accuracy 0.97266\n",
      "epoch[79/100] training loss 0.00285, training accuracy 0.98438\n",
      "epoch[79/100] training loss 0.00270, training accuracy 0.06250\n",
      "[val] acc : 0.92302, loss : 0.80821\n",
      "best acc : 0.92354, best loss : 0.80821\n",
      "epoch[80/100] training loss 0.00295, training accuracy 0.96094\n",
      "epoch[80/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[80/100] training loss 0.00294, training accuracy 0.96875\n",
      "epoch[80/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[80/100] training loss 0.00302, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00284, training accuracy 0.98828\n",
      "epoch[80/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[80/100] training loss 0.00299, training accuracy 0.95312\n",
      "epoch[80/100] training loss 0.00325, training accuracy 0.92578\n",
      "epoch[80/100] training loss 0.00296, training accuracy 0.96875\n",
      "epoch[80/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[80/100] training loss 0.00292, training accuracy 0.96875\n",
      "epoch[80/100] training loss 0.00300, training accuracy 0.94531\n",
      "epoch[80/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[80/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[80/100] training loss 0.00298, training accuracy 0.94531\n",
      "epoch[80/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[80/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[80/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[80/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00301, training accuracy 0.95312\n",
      "epoch[80/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[80/100] training loss 0.00288, training accuracy 0.96875\n",
      "epoch[80/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[80/100] training loss 0.00289, training accuracy 0.97656\n",
      "epoch[80/100] training loss 0.00302, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00293, training accuracy 0.98047\n",
      "epoch[80/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[80/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[80/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[80/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[80/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[80/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[80/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[80/100] training loss 0.00301, training accuracy 0.95312\n",
      "epoch[80/100] training loss 0.00299, training accuracy 0.95703\n",
      "epoch[80/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[80/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00287, training accuracy 0.99609\n",
      "epoch[80/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[80/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[80/100] training loss 0.00295, training accuracy 0.97656\n",
      "epoch[80/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[80/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[80/100] training loss 0.00294, training accuracy 0.97266\n",
      "epoch[80/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[80/100] training loss 0.00290, training accuracy 0.97266\n",
      "epoch[80/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[80/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[80/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[80/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[80/100] training loss 0.00292, training accuracy 0.96484\n",
      "epoch[80/100] training loss 0.00255, training accuracy 0.06250\n",
      "[val] acc : 0.92249, loss : 0.81169\n",
      "best acc : 0.92354, best loss : 0.80821\n",
      "epoch[81/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[81/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[81/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[81/100] training loss 0.00294, training accuracy 0.97266\n",
      "epoch[81/100] training loss 0.00290, training accuracy 0.97266\n",
      "epoch[81/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[81/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[81/100] training loss 0.00307, training accuracy 0.94531\n",
      "epoch[81/100] training loss 0.00307, training accuracy 0.93750\n",
      "epoch[81/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[81/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[81/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[81/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[81/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[81/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[81/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[81/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[81/100] training loss 0.00301, training accuracy 0.96484\n",
      "epoch[81/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[81/100] training loss 0.00312, training accuracy 0.94922\n",
      "epoch[81/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[81/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[81/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[81/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[81/100] training loss 0.00304, training accuracy 0.94922\n",
      "epoch[81/100] training loss 0.00289, training accuracy 0.97266\n",
      "epoch[81/100] training loss 0.00291, training accuracy 0.97266\n",
      "epoch[81/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[81/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[81/100] training loss 0.00304, training accuracy 0.94922\n",
      "epoch[81/100] training loss 0.00293, training accuracy 0.97656\n",
      "epoch[81/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[81/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[81/100] training loss 0.00304, training accuracy 0.94141\n",
      "epoch[81/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[81/100] training loss 0.00291, training accuracy 0.98047\n",
      "epoch[81/100] training loss 0.00295, training accuracy 0.96875\n",
      "epoch[81/100] training loss 0.00287, training accuracy 0.97656\n",
      "epoch[81/100] training loss 0.00303, training accuracy 0.97266\n",
      "epoch[81/100] training loss 0.00295, training accuracy 0.97266\n",
      "epoch[81/100] training loss 0.00295, training accuracy 0.97266\n",
      "epoch[81/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[81/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[81/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[81/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[81/100] training loss 0.00301, training accuracy 0.96875\n",
      "epoch[81/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[81/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[81/100] training loss 0.00290, training accuracy 0.96875\n",
      "epoch[81/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[81/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[81/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[81/100] training loss 0.00294, training accuracy 0.96094\n",
      "epoch[81/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[81/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[81/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[81/100] training loss 0.00311, training accuracy 0.94531\n",
      "epoch[81/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[81/100] training loss 0.00293, training accuracy 0.98047\n",
      "epoch[81/100] training loss 0.00259, training accuracy 0.06250\n",
      "[val] acc : 0.92540, loss : 0.80950\n",
      "best acc : 0.92540, best loss : 0.80821\n",
      "epoch[82/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[82/100] training loss 0.00291, training accuracy 0.98047\n",
      "epoch[82/100] training loss 0.00292, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[82/100] training loss 0.00296, training accuracy 0.97656\n",
      "epoch[82/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[82/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[82/100] training loss 0.00291, training accuracy 0.96875\n",
      "epoch[82/100] training loss 0.00302, training accuracy 0.95703\n",
      "epoch[82/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00294, training accuracy 0.95703\n",
      "epoch[82/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[82/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00288, training accuracy 0.98047\n",
      "epoch[82/100] training loss 0.00299, training accuracy 0.95312\n",
      "epoch[82/100] training loss 0.00288, training accuracy 0.98438\n",
      "epoch[82/100] training loss 0.00287, training accuracy 0.97656\n",
      "epoch[82/100] training loss 0.00308, training accuracy 0.94141\n",
      "epoch[82/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[82/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[82/100] training loss 0.00290, training accuracy 0.97656\n",
      "epoch[82/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[82/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[82/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[82/100] training loss 0.00290, training accuracy 0.98047\n",
      "epoch[82/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[82/100] training loss 0.00302, training accuracy 0.97266\n",
      "epoch[82/100] training loss 0.00311, training accuracy 0.93750\n",
      "epoch[82/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00295, training accuracy 0.98828\n",
      "epoch[82/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[82/100] training loss 0.00307, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00310, training accuracy 0.95703\n",
      "epoch[82/100] training loss 0.00289, training accuracy 0.97266\n",
      "epoch[82/100] training loss 0.00290, training accuracy 0.97266\n",
      "epoch[82/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00299, training accuracy 0.94922\n",
      "epoch[82/100] training loss 0.00285, training accuracy 0.97656\n",
      "epoch[82/100] training loss 0.00314, training accuracy 0.94141\n",
      "epoch[82/100] training loss 0.00291, training accuracy 0.98047\n",
      "epoch[82/100] training loss 0.00308, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00293, training accuracy 0.96094\n",
      "epoch[82/100] training loss 0.00311, training accuracy 0.94922\n",
      "epoch[82/100] training loss 0.00291, training accuracy 0.98047\n",
      "epoch[82/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[82/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[82/100] training loss 0.00294, training accuracy 0.98047\n",
      "epoch[82/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[82/100] training loss 0.00293, training accuracy 0.96875\n",
      "epoch[82/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[82/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[82/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[82/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[82/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00312, training accuracy 0.94531\n",
      "epoch[82/100] training loss 0.00302, training accuracy 0.96484\n",
      "epoch[82/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[82/100] training loss 0.00262, training accuracy 0.06250\n",
      "[val] acc : 0.92566, loss : 0.80824\n",
      "best acc : 0.92566, best loss : 0.80821\n",
      "epoch[83/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[83/100] training loss 0.00304, training accuracy 0.96875\n",
      "epoch[83/100] training loss 0.00287, training accuracy 0.97266\n",
      "epoch[83/100] training loss 0.00288, training accuracy 0.97656\n",
      "epoch[83/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[83/100] training loss 0.00303, training accuracy 0.94531\n",
      "epoch[83/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[83/100] training loss 0.00307, training accuracy 0.94922\n",
      "epoch[83/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[83/100] training loss 0.00294, training accuracy 0.96875\n",
      "epoch[83/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00288, training accuracy 0.97656\n",
      "epoch[83/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[83/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[83/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[83/100] training loss 0.00304, training accuracy 0.94141\n",
      "epoch[83/100] training loss 0.00298, training accuracy 0.97656\n",
      "epoch[83/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[83/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[83/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[83/100] training loss 0.00290, training accuracy 0.98047\n",
      "epoch[83/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[83/100] training loss 0.00296, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[83/100] training loss 0.00293, training accuracy 0.96875\n",
      "epoch[83/100] training loss 0.00286, training accuracy 0.99219\n",
      "epoch[83/100] training loss 0.00300, training accuracy 0.96875\n",
      "epoch[83/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[83/100] training loss 0.00291, training accuracy 0.96875\n",
      "epoch[83/100] training loss 0.00296, training accuracy 0.98438\n",
      "epoch[83/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[83/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[83/100] training loss 0.00295, training accuracy 0.97266\n",
      "epoch[83/100] training loss 0.00295, training accuracy 0.97656\n",
      "epoch[83/100] training loss 0.00292, training accuracy 0.96875\n",
      "epoch[83/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[83/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[83/100] training loss 0.00311, training accuracy 0.95312\n",
      "epoch[83/100] training loss 0.00288, training accuracy 0.98047\n",
      "epoch[83/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[83/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00289, training accuracy 0.98047\n",
      "epoch[83/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[83/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[83/100] training loss 0.00295, training accuracy 0.95703\n",
      "epoch[83/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[83/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[83/100] training loss 0.00302, training accuracy 0.94922\n",
      "epoch[83/100] training loss 0.00304, training accuracy 0.94922\n",
      "epoch[83/100] training loss 0.00293, training accuracy 0.96875\n",
      "epoch[83/100] training loss 0.00301, training accuracy 0.97266\n",
      "epoch[83/100] training loss 0.00302, training accuracy 0.94922\n",
      "epoch[83/100] training loss 0.00361, training accuracy 0.05078\n",
      "[val] acc : 0.92063, loss : 0.80995\n",
      "best acc : 0.92566, best loss : 0.80821\n",
      "epoch[84/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[84/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[84/100] training loss 0.00304, training accuracy 0.97266\n",
      "epoch[84/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[84/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[84/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[84/100] training loss 0.00295, training accuracy 0.97266\n",
      "epoch[84/100] training loss 0.00303, training accuracy 0.96875\n",
      "epoch[84/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[84/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[84/100] training loss 0.00305, training accuracy 0.94531\n",
      "epoch[84/100] training loss 0.00287, training accuracy 0.98828\n",
      "epoch[84/100] training loss 0.00291, training accuracy 0.97266\n",
      "epoch[84/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[84/100] training loss 0.00298, training accuracy 0.96484\n",
      "epoch[84/100] training loss 0.00289, training accuracy 0.98828\n",
      "epoch[84/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[84/100] training loss 0.00316, training accuracy 0.94531\n",
      "epoch[84/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[84/100] training loss 0.00309, training accuracy 0.94922\n",
      "epoch[84/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[84/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[84/100] training loss 0.00297, training accuracy 0.95312\n",
      "epoch[84/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[84/100] training loss 0.00291, training accuracy 0.97266\n",
      "epoch[84/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[84/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[84/100] training loss 0.00299, training accuracy 0.97656\n",
      "epoch[84/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[84/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[84/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[84/100] training loss 0.00298, training accuracy 0.97266\n",
      "epoch[84/100] training loss 0.00325, training accuracy 0.92578\n",
      "epoch[84/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[84/100] training loss 0.00317, training accuracy 0.93359\n",
      "epoch[84/100] training loss 0.00291, training accuracy 0.98438\n",
      "epoch[84/100] training loss 0.00293, training accuracy 0.97266\n",
      "epoch[84/100] training loss 0.00300, training accuracy 0.94922\n",
      "epoch[84/100] training loss 0.00294, training accuracy 0.96875\n",
      "epoch[84/100] training loss 0.00288, training accuracy 0.98438\n",
      "epoch[84/100] training loss 0.00287, training accuracy 0.98047\n",
      "epoch[84/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[84/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[84/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[84/100] training loss 0.00304, training accuracy 0.94922\n",
      "epoch[84/100] training loss 0.00293, training accuracy 0.97266\n",
      "epoch[84/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[84/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[84/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[84/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[84/100] training loss 0.00287, training accuracy 0.98828\n",
      "epoch[84/100] training loss 0.00298, training accuracy 0.95312\n",
      "epoch[84/100] training loss 0.00305, training accuracy 0.95312\n",
      "epoch[84/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[84/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[84/100] training loss 0.00296, training accuracy 0.96875\n",
      "epoch[84/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[84/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[84/100] training loss 0.00292, training accuracy 0.97656\n",
      "epoch[84/100] training loss 0.00308, training accuracy 0.06250\n",
      "[val] acc : 0.92751, loss : 0.80589\n",
      "best acc : 0.92751, best loss : 0.80589\n",
      "epoch[85/100] training loss 0.00294, training accuracy 0.97656\n",
      "epoch[85/100] training loss 0.00283, training accuracy 0.98047\n",
      "epoch[85/100] training loss 0.00299, training accuracy 0.95312\n",
      "epoch[85/100] training loss 0.00305, training accuracy 0.96484\n",
      "epoch[85/100] training loss 0.00313, training accuracy 0.94531\n",
      "epoch[85/100] training loss 0.00306, training accuracy 0.96484\n",
      "epoch[85/100] training loss 0.00312, training accuracy 0.93359\n",
      "epoch[85/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[85/100] training loss 0.00311, training accuracy 0.96484\n",
      "epoch[85/100] training loss 0.00290, training accuracy 0.97266\n",
      "epoch[85/100] training loss 0.00308, training accuracy 0.95703\n",
      "epoch[85/100] training loss 0.00301, training accuracy 0.94531\n",
      "epoch[85/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[85/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[85/100] training loss 0.00320, training accuracy 0.93750\n",
      "epoch[85/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[85/100] training loss 0.00304, training accuracy 0.95312\n",
      "epoch[85/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[85/100] training loss 0.00292, training accuracy 0.98828\n",
      "epoch[85/100] training loss 0.00290, training accuracy 0.97656\n",
      "epoch[85/100] training loss 0.00292, training accuracy 0.96875\n",
      "epoch[85/100] training loss 0.00312, training accuracy 0.93750\n",
      "epoch[85/100] training loss 0.00289, training accuracy 0.98438\n",
      "epoch[85/100] training loss 0.00291, training accuracy 0.98047\n",
      "epoch[85/100] training loss 0.00307, training accuracy 0.95703\n",
      "epoch[85/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[85/100] training loss 0.00294, training accuracy 0.97266\n",
      "epoch[85/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[85/100] training loss 0.00292, training accuracy 0.96875\n",
      "epoch[85/100] training loss 0.00307, training accuracy 0.96094\n",
      "epoch[85/100] training loss 0.00298, training accuracy 0.97266\n",
      "epoch[85/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[85/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[85/100] training loss 0.00299, training accuracy 0.95312\n",
      "epoch[85/100] training loss 0.00290, training accuracy 0.96484\n",
      "epoch[85/100] training loss 0.00290, training accuracy 0.97266\n",
      "epoch[85/100] training loss 0.00306, training accuracy 0.94531\n",
      "epoch[85/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[85/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[85/100] training loss 0.00298, training accuracy 0.95312\n",
      "epoch[85/100] training loss 0.00292, training accuracy 0.97266\n",
      "epoch[85/100] training loss 0.00302, training accuracy 0.94922\n",
      "epoch[85/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[85/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[85/100] training loss 0.00299, training accuracy 0.94922\n",
      "epoch[85/100] training loss 0.00294, training accuracy 0.97266\n",
      "epoch[85/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[85/100] training loss 0.00301, training accuracy 0.96875\n",
      "epoch[85/100] training loss 0.00306, training accuracy 0.94531\n",
      "epoch[85/100] training loss 0.00293, training accuracy 0.97266\n",
      "epoch[85/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[85/100] training loss 0.00291, training accuracy 0.97656\n",
      "epoch[85/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[85/100] training loss 0.00306, training accuracy 0.94141\n",
      "epoch[85/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[85/100] training loss 0.00301, training accuracy 0.96094\n",
      "epoch[85/100] training loss 0.00292, training accuracy 0.97266\n",
      "epoch[85/100] training loss 0.00309, training accuracy 0.96484\n",
      "epoch[85/100] training loss 0.00292, training accuracy 0.96875\n",
      "epoch[85/100] training loss 0.00321, training accuracy 0.05859\n",
      "[val] acc : 0.92249, loss : 0.80726\n",
      "best acc : 0.92751, best loss : 0.80589\n",
      "epoch[86/100] training loss 0.00300, training accuracy 0.94922\n",
      "epoch[86/100] training loss 0.00305, training accuracy 0.94141\n",
      "epoch[86/100] training loss 0.00301, training accuracy 0.94922\n",
      "epoch[86/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[86/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00293, training accuracy 0.97656\n",
      "epoch[86/100] training loss 0.00312, training accuracy 0.95312\n",
      "epoch[86/100] training loss 0.00311, training accuracy 0.95703\n",
      "epoch[86/100] training loss 0.00312, training accuracy 0.93359\n",
      "epoch[86/100] training loss 0.00301, training accuracy 0.97266\n",
      "epoch[86/100] training loss 0.00308, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00305, training accuracy 0.94141\n",
      "epoch[86/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[86/100] training loss 0.00313, training accuracy 0.95703\n",
      "epoch[86/100] training loss 0.00307, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00297, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00298, training accuracy 0.97266\n",
      "epoch[86/100] training loss 0.00296, training accuracy 0.97656\n",
      "epoch[86/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[86/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[86/100] training loss 0.00315, training accuracy 0.95312\n",
      "epoch[86/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[86/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[86/100] training loss 0.00294, training accuracy 0.96875\n",
      "epoch[86/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00308, training accuracy 0.93359\n",
      "epoch[86/100] training loss 0.00293, training accuracy 0.97266\n",
      "epoch[86/100] training loss 0.00291, training accuracy 0.98047\n",
      "epoch[86/100] training loss 0.00299, training accuracy 0.95312\n",
      "epoch[86/100] training loss 0.00289, training accuracy 0.97266\n",
      "epoch[86/100] training loss 0.00296, training accuracy 0.96094\n",
      "epoch[86/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[86/100] training loss 0.00294, training accuracy 0.98438\n",
      "epoch[86/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[86/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[86/100] training loss 0.00289, training accuracy 0.97656\n",
      "epoch[86/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[86/100] training loss 0.00299, training accuracy 0.94922\n",
      "epoch[86/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00296, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00291, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00304, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00296, training accuracy 0.98438\n",
      "epoch[86/100] training loss 0.00305, training accuracy 0.94141\n",
      "epoch[86/100] training loss 0.00295, training accuracy 0.98047\n",
      "epoch[86/100] training loss 0.00291, training accuracy 0.95703\n",
      "epoch[86/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[86/100] training loss 0.00285, training accuracy 0.98828\n",
      "epoch[86/100] training loss 0.00307, training accuracy 0.93359\n",
      "epoch[86/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[86/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[86/100] training loss 0.00302, training accuracy 0.94922\n",
      "epoch[86/100] training loss 0.00308, training accuracy 0.94531\n",
      "epoch[86/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[86/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[86/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[86/100] training loss 0.00292, training accuracy 0.97656\n",
      "epoch[86/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[86/100] training loss 0.00324, training accuracy 0.05469\n",
      "[val] acc : 0.92646, loss : 0.80943\n",
      "best acc : 0.92751, best loss : 0.80589\n",
      "epoch[87/100] training loss 0.00293, training accuracy 0.97266\n",
      "epoch[87/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00314, training accuracy 0.96484\n",
      "epoch[87/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00292, training accuracy 0.98828\n",
      "epoch[87/100] training loss 0.00313, training accuracy 0.93359\n",
      "epoch[87/100] training loss 0.00309, training accuracy 0.95703\n",
      "epoch[87/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[87/100] training loss 0.00316, training accuracy 0.95312\n",
      "epoch[87/100] training loss 0.00315, training accuracy 0.93359\n",
      "epoch[87/100] training loss 0.00306, training accuracy 0.95703\n",
      "epoch[87/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[87/100] training loss 0.00294, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00308, training accuracy 0.95312\n",
      "epoch[87/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[87/100] training loss 0.00291, training accuracy 0.97656\n",
      "epoch[87/100] training loss 0.00306, training accuracy 0.94141\n",
      "epoch[87/100] training loss 0.00297, training accuracy 0.95703\n",
      "epoch[87/100] training loss 0.00296, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00303, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00305, training accuracy 0.95703\n",
      "epoch[87/100] training loss 0.00300, training accuracy 0.97266\n",
      "epoch[87/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[87/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[87/100] training loss 0.00294, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00303, training accuracy 0.94531\n",
      "epoch[87/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[87/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[87/100] training loss 0.00293, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00311, training accuracy 0.92188\n",
      "epoch[87/100] training loss 0.00302, training accuracy 0.94922\n",
      "epoch[87/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[87/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[87/100] training loss 0.00299, training accuracy 0.95703\n",
      "epoch[87/100] training loss 0.00310, training accuracy 0.94141\n",
      "epoch[87/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[87/100] training loss 0.00301, training accuracy 0.95703\n",
      "epoch[87/100] training loss 0.00310, training accuracy 0.94531\n",
      "epoch[87/100] training loss 0.00290, training accuracy 0.98438\n",
      "epoch[87/100] training loss 0.00286, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00292, training accuracy 0.96484\n",
      "epoch[87/100] training loss 0.00307, training accuracy 0.94531\n",
      "epoch[87/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[87/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[87/100] training loss 0.00296, training accuracy 0.96094\n",
      "epoch[87/100] training loss 0.00305, training accuracy 0.96094\n",
      "epoch[87/100] training loss 0.00305, training accuracy 0.94141\n",
      "epoch[87/100] training loss 0.00298, training accuracy 0.96094\n",
      "epoch[87/100] training loss 0.00291, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00294, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00296, training accuracy 0.98438\n",
      "epoch[87/100] training loss 0.00293, training accuracy 0.98438\n",
      "epoch[87/100] training loss 0.00303, training accuracy 0.94922\n",
      "epoch[87/100] training loss 0.00294, training accuracy 0.97656\n",
      "epoch[87/100] training loss 0.00312, training accuracy 0.94141\n",
      "epoch[87/100] training loss 0.00295, training accuracy 0.96875\n",
      "epoch[87/100] training loss 0.00289, training accuracy 0.96484\n",
      "epoch[87/100] training loss 0.00300, training accuracy 0.96484\n",
      "epoch[87/100] training loss 0.00295, training accuracy 0.97266\n",
      "epoch[87/100] training loss 0.00301, training accuracy 0.06250\n",
      "[val] acc : 0.92222, loss : 0.81542\n",
      "best acc : 0.92751, best loss : 0.80589\n",
      "epoch[88/100] training loss 0.00303, training accuracy 0.95312\n",
      "epoch[88/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[88/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00303, training accuracy 0.96484\n",
      "epoch[88/100] training loss 0.00287, training accuracy 0.98047\n",
      "epoch[88/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[88/100] training loss 0.00306, training accuracy 0.94922\n",
      "epoch[88/100] training loss 0.00293, training accuracy 0.95703\n",
      "epoch[88/100] training loss 0.00304, training accuracy 0.95703\n",
      "epoch[88/100] training loss 0.00292, training accuracy 0.97656\n",
      "epoch[88/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[88/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[88/100] training loss 0.00289, training accuracy 0.97266\n",
      "epoch[88/100] training loss 0.00293, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00302, training accuracy 0.94141\n",
      "epoch[88/100] training loss 0.00304, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[88/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00297, training accuracy 0.97656\n",
      "epoch[88/100] training loss 0.00300, training accuracy 0.95703\n",
      "epoch[88/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[88/100] training loss 0.00294, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00291, training accuracy 0.98438\n",
      "epoch[88/100] training loss 0.00292, training accuracy 0.97656\n",
      "epoch[88/100] training loss 0.00287, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00289, training accuracy 0.96875\n",
      "epoch[88/100] training loss 0.00285, training accuracy 0.97266\n",
      "epoch[88/100] training loss 0.00293, training accuracy 0.97656\n",
      "epoch[88/100] training loss 0.00293, training accuracy 0.96875\n",
      "epoch[88/100] training loss 0.00296, training accuracy 0.96484\n",
      "epoch[88/100] training loss 0.00298, training accuracy 0.97266\n",
      "epoch[88/100] training loss 0.00298, training accuracy 0.96875\n",
      "epoch[88/100] training loss 0.00302, training accuracy 0.96484\n",
      "epoch[88/100] training loss 0.00306, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00285, training accuracy 0.98828\n",
      "epoch[88/100] training loss 0.00311, training accuracy 0.93359\n",
      "epoch[88/100] training loss 0.00294, training accuracy 0.97266\n",
      "epoch[88/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00299, training accuracy 0.94922\n",
      "epoch[88/100] training loss 0.00315, training accuracy 0.94141\n",
      "epoch[88/100] training loss 0.00288, training accuracy 0.98438\n",
      "epoch[88/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[88/100] training loss 0.00303, training accuracy 0.94531\n",
      "epoch[88/100] training loss 0.00290, training accuracy 0.98438\n",
      "epoch[88/100] training loss 0.00302, training accuracy 0.96484\n",
      "epoch[88/100] training loss 0.00292, training accuracy 0.96094\n",
      "epoch[88/100] training loss 0.00308, training accuracy 0.94922\n",
      "epoch[88/100] training loss 0.00293, training accuracy 0.97656\n",
      "epoch[88/100] training loss 0.00288, training accuracy 0.97656\n",
      "epoch[88/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[88/100] training loss 0.00299, training accuracy 0.96484\n",
      "epoch[88/100] training loss 0.00290, training accuracy 0.97656\n",
      "epoch[88/100] training loss 0.00305, training accuracy 0.93750\n",
      "epoch[88/100] training loss 0.00291, training accuracy 0.97656\n",
      "epoch[88/100] training loss 0.00296, training accuracy 0.96484\n",
      "epoch[88/100] training loss 0.00299, training accuracy 0.96875\n",
      "epoch[88/100] training loss 0.00277, training accuracy 0.06250\n",
      "[val] acc : 0.92116, loss : 0.80631\n",
      "best acc : 0.92751, best loss : 0.80589\n",
      "epoch[89/100] training loss 0.00295, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00291, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00293, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00289, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00292, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00297, training accuracy 0.95312\n",
      "epoch[89/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[89/100] training loss 0.00292, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00298, training accuracy 0.95703\n",
      "epoch[89/100] training loss 0.00309, training accuracy 0.92969\n",
      "epoch[89/100] training loss 0.00296, training accuracy 0.95312\n",
      "epoch[89/100] training loss 0.00295, training accuracy 0.96094\n",
      "epoch[89/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[89/100] training loss 0.00294, training accuracy 0.95703\n",
      "epoch[89/100] training loss 0.00297, training accuracy 0.97266\n",
      "epoch[89/100] training loss 0.00305, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00292, training accuracy 0.97266\n",
      "epoch[89/100] training loss 0.00284, training accuracy 0.97266\n",
      "epoch[89/100] training loss 0.00293, training accuracy 0.98047\n",
      "epoch[89/100] training loss 0.00296, training accuracy 0.97266\n",
      "epoch[89/100] training loss 0.00286, training accuracy 0.98047\n",
      "epoch[89/100] training loss 0.00310, training accuracy 0.94141\n",
      "epoch[89/100] training loss 0.00302, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00294, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00307, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00303, training accuracy 0.95703\n",
      "epoch[89/100] training loss 0.00308, training accuracy 0.96094\n",
      "epoch[89/100] training loss 0.00293, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00297, training accuracy 0.96094\n",
      "epoch[89/100] training loss 0.00294, training accuracy 0.97656\n",
      "epoch[89/100] training loss 0.00302, training accuracy 0.94141\n",
      "epoch[89/100] training loss 0.00306, training accuracy 0.95312\n",
      "epoch[89/100] training loss 0.00291, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00291, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00307, training accuracy 0.95312\n",
      "epoch[89/100] training loss 0.00300, training accuracy 0.96094\n",
      "epoch[89/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00296, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00303, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00296, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00286, training accuracy 0.97266\n",
      "epoch[89/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00292, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00299, training accuracy 0.96094\n",
      "epoch[89/100] training loss 0.00299, training accuracy 0.97266\n",
      "epoch[89/100] training loss 0.00293, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00300, training accuracy 0.95312\n",
      "epoch[89/100] training loss 0.00297, training accuracy 0.96875\n",
      "epoch[89/100] training loss 0.00302, training accuracy 0.96094\n",
      "epoch[89/100] training loss 0.00302, training accuracy 0.95312\n",
      "epoch[89/100] training loss 0.00289, training accuracy 0.97266\n",
      "epoch[89/100] training loss 0.00298, training accuracy 0.97266\n",
      "epoch[89/100] training loss 0.00292, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00294, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00315, training accuracy 0.94922\n",
      "epoch[89/100] training loss 0.00296, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00303, training accuracy 0.96094\n",
      "epoch[89/100] training loss 0.00295, training accuracy 0.97266\n",
      "epoch[89/100] training loss 0.00296, training accuracy 0.96484\n",
      "epoch[89/100] training loss 0.00296, training accuracy 0.05859\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "patience = 5\n",
    "cur_count = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for train_batch in train_dataloader_mask:\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            torch.save(model, '/opt/ml/checkpoint/swin_transfrmer_t_2/checkpoint_ep_%d.pt'% epoch)\n",
    "        \n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        \n",
    "        train_loss = loss_value / batch_size\n",
    "        train_acc = matches / batch_size\n",
    "        print(f\"epoch[{epoch}/{NUM_EPOCH}] training loss {train_loss:.5f}, training accuracy {train_acc:.5f}\")\n",
    "        \n",
    "        loss_value = 0\n",
    "        matches = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        for val_batch in val_dataloader_mask:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            \n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels==preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "            \n",
    "        val_loss = np.sum(val_loss_items) / len(val_dataloader_mask)\n",
    "        val_acc = np.sum(val_acc_items) / len(mask_val_set)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            cur_count = 0\n",
    "            torch.save(model, '/opt/ml/checkpoint/swin_transfrmer_t_2/checkpoint_best.pt')\n",
    "        else:\n",
    "            cur_count += 1\n",
    "            if cur_count >= patience:\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            \n",
    "        print(f\"[val] acc : {val_acc:.5f}, loss : {val_loss:.5f}\")\n",
    "        print(f\"best acc : {best_val_acc:.5f}, best loss : {best_val_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afda23d0-6ad9-408b-99c9-705ae5fd8347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ImageID  ans\n",
       "0  cbc5c6e168e63498590db46022617123f1fe1268.jpg    0\n",
       "1  0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    0\n",
       "2  b549040c49190cedc41327748aeb197c1670f14d.jpg    0\n",
       "3  4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    0\n",
       "4  248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir_path = '/opt/ml/input/data/eval/'\n",
    "test_image_path = '/opt/ml/input/data/eval/images/'\n",
    "\n",
    "best_model = torch.load('/opt/ml/checkpoint/swin_transfrmer_t_2/checkpoint_best.pt')\n",
    "submission = pd.read_csv(test_dir_path+'info.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "566c2df1-a083-4e27-a655-f2c73d15f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [os.path.join(test_image_path, img_id) for img_id in submission.ImageID]\n",
    "test_image = pd.Series(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9c14322-45a8-40a5-aded-f335204484b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Dataset(Dataset):\n",
    "    def __init__(self, midcrop=True, transform=None):\n",
    "        self.midcrop = midcrop\n",
    "        self.data = test_image\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(test_image)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.midcrop:\n",
    "            img = img[64:448]\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "138db932-cc09-4f85-89d8-e7485659f7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Test_Dataset(transform = transforms.Compose([\n",
    "                            transforms.ToPILImage(),\n",
    "                            transforms.Resize(224),\n",
    "                            transforms.ToTensor()\n",
    "                        ]))\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = best_model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir_path, 'submission_swin_transformer_t_100.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd05b0a-17a2-47b4-b10d-de6e4344e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/ml/checkpoint/swin_transfrmer_t_2/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
