{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1d65a3-78de-4b01-a862-e6bd4c7ef135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15beaba-39cc-48da-8165-9f2abc16322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('input/data')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b3beb99-f9c7-4026-989a-cbaa8de1f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -regex \".*\\.\\_[a-zA-Z0-9._]+\" -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8d19de-5a8e-454f-a22b-129e94792395",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 12\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f69f93c-5675-433f-8a88-7bf8e411d51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>006954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>006955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>006956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>006957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                    path\n",
       "0     000001  female  Asian   45  000001_female_Asian_45\n",
       "1     000002  female  Asian   52  000002_female_Asian_52\n",
       "2     000004    male  Asian   54    000004_male_Asian_54\n",
       "3     000005  female  Asian   58  000005_female_Asian_58\n",
       "4     000006  female  Asian   59  000006_female_Asian_59\n",
       "...      ...     ...    ...  ...                     ...\n",
       "2695  006954    male  Asian   19    006954_male_Asian_19\n",
       "2696  006955    male  Asian   19    006955_male_Asian_19\n",
       "2697  006956    male  Asian   19    006956_male_Asian_19\n",
       "2698  006957    male  Asian   20    006957_male_Asian_20\n",
       "2699  006959    male  Asian   19    006959_male_Asian_19\n",
       "\n",
       "[2700 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir_path = '/opt/ml/input/data/train/'\n",
    "train_image_path = '/opt/ml/input/data/train/images/'\n",
    "\n",
    "dt_train = pd.read_csv(train_dir_path+'train.csv')\n",
    "dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "304c6a61-ff17-4777-8132-18def61c8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_image_path = []\n",
    "whole_target_label = []\n",
    "\n",
    "for path in dt_train['path']:\n",
    "    for file_name in [i for i in os.listdir(train_image_path+path) if './' not in i]:\n",
    "        whole_image_path.append(train_image_path+path+'/'+file_name)\n",
    "        whole_target_label.append((path.split('_')[1], path.split('_')[3], file_name.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98de1eb4-55d4-41ba-8541-70fff9bb011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_enc(x):\n",
    "    def gender(i):\n",
    "        if i == 'male':\n",
    "            return 0\n",
    "        elif i == 'female':\n",
    "            return 3\n",
    "    def age(j):\n",
    "        j = int(j)\n",
    "        if j < 30:\n",
    "            return 0\n",
    "        elif j >= 30 and j < 60:\n",
    "            return 1\n",
    "        elif j >= 60:\n",
    "            return 2\n",
    "    def mask(k):\n",
    "        if k == 'normal':\n",
    "            return 12\n",
    "        elif 'incorrect' in k:\n",
    "            return 6\n",
    "        else:\n",
    "            return 0\n",
    "    return gender(x[0]) + age(x[1]) + mask(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "id": "af245588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_genmsk(x):\n",
    "    # x 입력형식 : (성별, 나이, 마스크) 튜플\n",
    "    # 출력형식 : (나이, 성별-마스크 인코딩) 튜플\n",
    "    def gender(i):\n",
    "        if i == 'male':\n",
    "            return 0\n",
    "        elif i == 'female':\n",
    "            return 3\n",
    "    def mask(k):\n",
    "        if k == 'normal':\n",
    "            return 12\n",
    "        elif 'incorrect' in k:\n",
    "            return 6\n",
    "        else:\n",
    "            return 0\n",
    "    if int(x[1]) == 60:\n",
    "        return 70, (gender(x[0])+mask(x[2]))//3\n",
    "    return int(x[1]), (gender(x[0])+mask(x[2]))//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0013779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_sepclass(x):\n",
    "    # x 입력형식 : (성별, 나이, 마스크) 튜플\n",
    "    # 출력형식 : (성별인코딩, 나이인코딩, 마스크인코딩)\n",
    "    def gender(i):\n",
    "        if i == 'male':\n",
    "            return 0\n",
    "        elif i == 'female':\n",
    "            return 1\n",
    "    def age(j):\n",
    "        j = int(j)\n",
    "        if j < 30:\n",
    "            return 0\n",
    "        elif j >= 30 and j < 60:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    def mask(k):\n",
    "        if k == 'normal':\n",
    "            return 2\n",
    "        elif 'incorrect' in k:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    return gender(x[0]), age(x[1]), mask(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
=======
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "id": "694474c7-7175-40e6-b071-e50218629f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_data = pd.Series(whole_image_path)\n",
    "sr_label = pd.Series(whole_target_label)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "execution_count": 7,
=======
   "execution_count": 8,
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "id": "e2cd7b29-5f03-444e-b781-902ca74f2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Mask(Dataset):\n",
    "    def __init__(self, encoding=True, midcrop=True, transform=None):\n",
    "        self.encoding = encoding\n",
    "        self.midcrop = midcrop\n",
    "        self.data = sr_data\n",
    "        self.label = sr_label\n",
    "        self.transform = transform\n",
    "        \n",
    "        if encoding:\n",
    "            self.label = self.label.apply(enc_sepclass)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(sr_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        y = self.label[idx]\n",
    "        \n",
    "        if self.midcrop:\n",
    "            X = X[98:422, 30:354]\n",
    "        \n",
    "        if self.transform:\n",
    "            return self.transform(X), y\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "execution_count": 8,
=======
   "execution_count": 9,
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "id": "e2a22aff-e634-4f15-877c-752d450d01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mask = Dataset_Mask(transform = transforms.Compose([\n",
    "                                transforms.ToTensor()\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "execution_count": 9,
=======
   "execution_count": 10,
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "id": "5788c44b-07ac-4820-a22d-b6ffa3fc81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset_mask) * 0.8)\n",
    "val_size = int(len(dataset_mask) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "execution_count": 10,
=======
   "execution_count": 11,
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "id": "0e285cb6-ee37-4a0c-a804-7506dcfebc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size : 15120\n",
      "validation data size : 3780\n"
     ]
    }
   ],
   "source": [
    "mask_train_set, mask_val_set = torch.utils.data.random_split(dataset_mask, [train_size, val_size])\n",
    "print(f'training data size : {len(mask_train_set)}')\n",
    "print(f'validation data size : {len(mask_val_set)}')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "execution_count": 11,
=======
   "execution_count": 12,
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "id": "37b1ced0-1e34-4d50-b2b2-dcdff8fd33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dataloader_mask = DataLoader(dataset = mask_train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_dataloader_mask = DataLoader(dataset = mask_val_set, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "execution_count": 12,
   "id": "7dc2e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class R34_RegCls(torchvision.models.ResNet):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.out1 = nn.Linear(512, 2, bias=True)\n",
    "        self.out2 = nn.Linear(512, 3, bias=True)\n",
    "        self.out3 = nn.Linear(512, 3, bias=True)\n",
    "        \n",
    "    def _forward_impl(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # out1 : gender class\n",
    "        # out2 : age class\n",
    "        # out3 : mask class\n",
    "        out1 = self.out1(x)\n",
    "        out2 = self.out2(x)\n",
    "        out3 = self.out3(x)\n",
    "        \n",
    "        return out1, out2, out3"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "execution_count": 13,
   "id": "af71a4ef-a137-47b0-af94-eebedaa36014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필요 입력 채널 개수 3\n",
      "네트워크 출력 채널 개수_gen/msk 2\n",
      "네트워크 출력 채널 개수_age 3\n",
      "R34_RegCls(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  (out1): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (out2): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (out3): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = torchvision.models.resnet.BasicBlock\n",
    "layers = [3, 4, 6, 3]\n",
    "\n",
    "basemodel_resnet34 = R34_RegCls(block = block, layers = layers)\n",
    "print('필요 입력 채널 개수', basemodel_resnet34.conv1.weight.shape[1])\n",
    "print('네트워크 출력 채널 개수_gen/msk', basemodel_resnet34.out1.weight.shape[0])\n",
    "print('네트워크 출력 채널 개수_age', basemodel_resnet34.out2.weight.shape[0])\n",
    "print(basemodel_resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11357fc4-548b-452e-bbd8-e60ef6261308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0264, -0.0118,  0.0335])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "nn.init.xavier_uniform_(basemodel_resnet34.out1.weight)\n",
    "stdv = 1. / math.sqrt(basemodel_resnet34.out1.weight.size(1))\n",
    "basemodel_resnet34.out1.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "nn.init.xavier_uniform_(basemodel_resnet34.out2.weight)\n",
    "stdv = 1. / math.sqrt(basemodel_resnet34.out2.weight.size(1))\n",
    "basemodel_resnet34.out2.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "nn.init.xavier_uniform_(basemodel_resnet34.out3.weight)\n",
    "stdv = 1. / math.sqrt(basemodel_resnet34.out3.weight.size(1))\n",
    "basemodel_resnet34.out3.bias.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a1a2262-f820-4294-8086-3a48a5e5d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device}\")\n",
    "\n",
    "basemodel_resnet34.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCH = 30\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(basemodel_resnet34.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64a36f92-aad5-4bbb-a920-29d50f0f058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] name:[conv1.weight] shape:[(64, 3, 7, 7)].\n",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
      "    val:[ 0.004  0.025 -0.02  -0.018 -0.03 ]\n",
      "[1] name:[bn1.weight] shape:[(64,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[2] name:[bn1.bias] shape:[(64,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[3] name:[layer1.0.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[ 0.044 -0.094  0.078 -0.065 -0.008]\n",
      "[4] name:[layer1.0.bn1.weight] shape:[(64,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[5] name:[layer1.0.bn1.bias] shape:[(64,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[6] name:[layer1.0.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.023  0.043 -0.038 -0.07  -0.1  ]\n",
      "[7] name:[layer1.0.bn2.weight] shape:[(64,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[8] name:[layer1.0.bn2.bias] shape:[(64,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[9] name:[layer1.1.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[ 0.008 -0.065  0.001  0.023 -0.004]\n",
      "[10] name:[layer1.1.bn1.weight] shape:[(64,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[11] name:[layer1.1.bn1.bias] shape:[(64,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[12] name:[layer1.1.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[ 0.002  0.018 -0.04   0.061  0.018]\n",
      "[13] name:[layer1.1.bn2.weight] shape:[(64,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[14] name:[layer1.1.bn2.bias] shape:[(64,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[15] name:[layer1.2.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.001  0.039 -0.022  0.076 -0.021]\n",
      "[16] name:[layer1.2.bn1.weight] shape:[(64,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[17] name:[layer1.2.bn1.bias] shape:[(64,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[18] name:[layer1.2.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.031 -0.023  0.046 -0.033  0.009]\n",
      "[19] name:[layer1.2.bn2.weight] shape:[(64,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[20] name:[layer1.2.bn2.bias] shape:[(64,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
=======
      "    val:[ 0.005 -0.007  0.008  0.038  0.049]\n",
      "[1] name:[bn1.weight] shape:[(64,)].\n",
      "    val:[0.302 0.268 0.26  0.311 0.238]\n",
      "[2] name:[bn1.bias] shape:[(64,)].\n",
      "    val:[0.481 0.207 0.331 0.38  0.094]\n",
      "[3] name:[layer1.0.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.005  0.015 -0.006 -0.06  -0.024]\n",
      "[4] name:[layer1.0.bn1.weight] shape:[(64,)].\n",
      "    val:[0.24  0.185 0.216 0.165 0.181]\n",
      "[5] name:[layer1.0.bn1.bias] shape:[(64,)].\n",
      "    val:[0.025 0.088 0.082 0.142 0.066]\n",
      "[6] name:[layer1.0.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[ 0.066 -0.01   0.041  0.033 -0.055]\n",
      "[7] name:[layer1.0.bn2.weight] shape:[(64,)].\n",
      "    val:[0.34  0.187 0.252 0.307 0.259]\n",
      "[8] name:[layer1.0.bn2.bias] shape:[(64,)].\n",
      "    val:[-0.251  0.196  0.23  -0.114  0.07 ]\n",
      "[9] name:[layer1.1.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.008 -0.04  -0.054 -0.019  0.011]\n",
      "[10] name:[layer1.1.bn1.weight] shape:[(64,)].\n",
      "    val:[0.178 0.373 0.18  0.26  0.246]\n",
      "[11] name:[layer1.1.bn1.bias] shape:[(64,)].\n",
      "    val:[ 0.073 -0.222  0.177 -0.063 -0.051]\n",
      "[12] name:[layer1.1.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.002 -0.04  -0.012  0.008  0.088]\n",
      "[13] name:[layer1.1.bn2.weight] shape:[(64,)].\n",
      "    val:[0.417 0.209 0.224 0.179 0.402]\n",
      "[14] name:[layer1.1.bn2.bias] shape:[(64,)].\n",
      "    val:[-0.033 -0.08   0.174 -0.102  0.176]\n",
      "[15] name:[layer1.2.conv1.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[ 0.021 -0.101 -0.024  0.013  0.111]\n",
      "[16] name:[layer1.2.bn1.weight] shape:[(64,)].\n",
      "    val:[0.335 0.203 0.192 0.247 0.248]\n",
      "[17] name:[layer1.2.bn1.bias] shape:[(64,)].\n",
      "    val:[-0.266 -0.041 -0.11  -0.246  0.017]\n",
      "[18] name:[layer1.2.conv2.weight] shape:[(64, 64, 3, 3)].\n",
      "    val:[-0.017  0.023 -0.021 -0.04   0.042]\n",
      "[19] name:[layer1.2.bn2.weight] shape:[(64,)].\n",
      "    val:[0.554 0.169 0.286 0.193 0.248]\n",
      "[20] name:[layer1.2.bn2.bias] shape:[(64,)].\n",
      "    val:[-0.093 -0.217  0.121  0.058  0.072]\n",
>>>>>>> T4136/SwinT:base_resnet34.ipynb
      "[21] name:[layer2.0.conv1.weight] shape:[(128, 64, 3, 3)].\n",
      "    val:[ 0.023  0.011  0.005 -0.058 -0.042]\n",
      "[22] name:[layer2.0.bn1.weight] shape:[(128,)].\n",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
      "    val:[1. 1. 1. 1. 1.]\n",
      "[23] name:[layer2.0.bn1.bias] shape:[(128,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[24] name:[layer2.0.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.007  0.03  -0.025  0.03  -0.007]\n",
      "[25] name:[layer2.0.bn2.weight] shape:[(128,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[26] name:[layer2.0.bn2.bias] shape:[(128,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[27] name:[layer2.0.downsample.0.weight] shape:[(128, 64, 1, 1)].\n",
      "    val:[-0.108 -0.013  0.018  0.022  0.12 ]\n",
      "[28] name:[layer2.0.downsample.1.weight] shape:[(128,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[29] name:[layer2.0.downsample.1.bias] shape:[(128,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[30] name:[layer2.1.conv1.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[ 0.059 -0.072  0.     0.053  0.042]\n",
      "[31] name:[layer2.1.bn1.weight] shape:[(128,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[32] name:[layer2.1.bn1.bias] shape:[(128,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[33] name:[layer2.1.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.078 -0.041 -0.005  0.017  0.024]\n",
      "[34] name:[layer2.1.bn2.weight] shape:[(128,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[35] name:[layer2.1.bn2.bias] shape:[(128,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[36] name:[layer2.2.conv1.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[ 0.036  0.059  0.043 -0.001  0.11 ]\n",
      "[37] name:[layer2.2.bn1.weight] shape:[(128,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
=======
      "    val:[0.261 0.288 0.174 0.238 0.274]\n",
      "[23] name:[layer2.0.bn1.bias] shape:[(128,)].\n",
      "    val:[-0.083 -0.094  0.286 -0.043 -0.101]\n",
      "[24] name:[layer2.0.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.005 -0.025  0.025  0.007 -0.021]\n",
      "[25] name:[layer2.0.bn2.weight] shape:[(128,)].\n",
      "    val:[0.376 0.01  0.186 0.269 0.344]\n",
      "[26] name:[layer2.0.bn2.bias] shape:[(128,)].\n",
      "    val:[-0.068  0.218  0.066  0.078  0.135]\n",
      "[27] name:[layer2.0.downsample.0.weight] shape:[(128, 64, 1, 1)].\n",
      "    val:[-0.008 -0.109  0.045 -0.033 -0.003]\n",
      "[28] name:[layer2.0.downsample.1.weight] shape:[(128,)].\n",
      "    val:[0.169 0.36  0.406 0.076 0.207]\n",
      "[29] name:[layer2.0.downsample.1.bias] shape:[(128,)].\n",
      "    val:[-0.068  0.218  0.066  0.078  0.135]\n",
      "[30] name:[layer2.1.conv1.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.011 -0.004  0.012 -0.015 -0.011]\n",
      "[31] name:[layer2.1.bn1.weight] shape:[(128,)].\n",
      "    val:[0.157 0.302 0.154 0.311 0.211]\n",
      "[32] name:[layer2.1.bn1.bias] shape:[(128,)].\n",
      "    val:[ 0.063 -0.199  0.054 -0.259 -0.036]\n",
      "[33] name:[layer2.1.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[ 0.022 -0.006  0.029  0.001 -0.023]\n",
      "[34] name:[layer2.1.bn2.weight] shape:[(128,)].\n",
      "    val:[0.146 0.271 0.169 0.162 0.091]\n",
      "[35] name:[layer2.1.bn2.bias] shape:[(128,)].\n",
      "    val:[-0.064 -0.481 -0.127 -0.03  -0.03 ]\n",
      "[36] name:[layer2.2.conv1.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[ 0.039  0.004 -0.007  0.008  0.01 ]\n",
      "[37] name:[layer2.2.bn1.weight] shape:[(128,)].\n",
      "    val:[0.28  0.303 0.248 0.216 0.235]\n",
>>>>>>> T4136/SwinT:base_resnet34.ipynb
      "[38] name:[layer2.2.bn1.bias] shape:[(128,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[39] name:[layer2.2.conv2.weight] shape:[(128, 128, 3, 3)].\n",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
      "    val:[-0.047 -0.013 -0.047  0.066 -0.052]\n",
      "[40] name:[layer2.2.bn2.weight] shape:[(128,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[41] name:[layer2.2.bn2.bias] shape:[(128,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[42] name:[layer2.3.conv1.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.006  0.002  0.067  0.024 -0.005]\n",
      "[43] name:[layer2.3.bn1.weight] shape:[(128,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[44] name:[layer2.3.bn1.bias] shape:[(128,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[45] name:[layer2.3.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.012  0.015 -0.057  0.024  0.042]\n",
      "[46] name:[layer2.3.bn2.weight] shape:[(128,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[47] name:[layer2.3.bn2.bias] shape:[(128,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[48] name:[layer3.0.conv1.weight] shape:[(256, 128, 3, 3)].\n",
      "    val:[-0.003  0.01  -0.027 -0.004  0.019]\n",
      "[49] name:[layer3.0.bn1.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[50] name:[layer3.0.bn1.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[51] name:[layer3.0.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.036  0.001  0.018  0.025 -0.038]\n",
      "[52] name:[layer3.0.bn2.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[53] name:[layer3.0.bn2.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[54] name:[layer3.0.downsample.0.weight] shape:[(256, 128, 1, 1)].\n",
      "    val:[ 0.063 -0.062 -0.091 -0.023  0.078]\n",
      "[55] name:[layer3.0.downsample.1.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[56] name:[layer3.0.downsample.1.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[57] name:[layer3.1.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.04  -0.028 -0.049  0.014  0.03 ]\n",
      "[58] name:[layer3.1.bn1.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[59] name:[layer3.1.bn1.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[60] name:[layer3.1.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.004  0.005 -0.043  0.026 -0.061]\n",
      "[61] name:[layer3.1.bn2.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[62] name:[layer3.1.bn2.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[63] name:[layer3.2.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.03   0.029  0.01  -0.028 -0.038]\n",
      "[64] name:[layer3.2.bn1.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[65] name:[layer3.2.bn1.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[66] name:[layer3.2.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.014 -0.008  0.045 -0.006 -0.016]\n",
      "[67] name:[layer3.2.bn2.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[68] name:[layer3.2.bn2.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[69] name:[layer3.3.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.007  0.012 -0.023 -0.006  0.042]\n",
      "[70] name:[layer3.3.bn1.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[71] name:[layer3.3.bn1.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[72] name:[layer3.3.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.042 -0.075  0.062  0.022 -0.036]\n",
      "[73] name:[layer3.3.bn2.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[74] name:[layer3.3.bn2.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[75] name:[layer3.4.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.017 -0.029 -0.042 -0.031  0.026]\n",
      "[76] name:[layer3.4.bn1.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[77] name:[layer3.4.bn1.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[78] name:[layer3.4.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.012  0.016 -0.    -0.001  0.003]\n",
      "[79] name:[layer3.4.bn2.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[80] name:[layer3.4.bn2.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[81] name:[layer3.5.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.031 -0.014  0.001  0.02   0.037]\n",
      "[82] name:[layer3.5.bn1.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[83] name:[layer3.5.bn1.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[84] name:[layer3.5.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.005  0.006  0.044  0.011 -0.007]\n",
      "[85] name:[layer3.5.bn2.weight] shape:[(256,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[86] name:[layer3.5.bn2.bias] shape:[(256,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[87] name:[layer4.0.conv1.weight] shape:[(512, 256, 3, 3)].\n",
      "    val:[ 0.033 -0.017  0.003  0.011  0.023]\n",
      "[88] name:[layer4.0.bn1.weight] shape:[(512,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[89] name:[layer4.0.bn1.bias] shape:[(512,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[90] name:[layer4.0.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[ 0.005  0.    -0.001 -0.004  0.004]\n",
      "[91] name:[layer4.0.bn2.weight] shape:[(512,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[92] name:[layer4.0.bn2.bias] shape:[(512,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[93] name:[layer4.0.downsample.0.weight] shape:[(512, 256, 1, 1)].\n",
      "    val:[-0.055 -0.028 -0.116 -0.006  0.063]\n",
      "[94] name:[layer4.0.downsample.1.weight] shape:[(512,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[95] name:[layer4.0.downsample.1.bias] shape:[(512,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[96] name:[layer4.1.conv1.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[-0.014  0.002  0.021 -0.027 -0.023]\n",
      "[97] name:[layer4.1.bn1.weight] shape:[(512,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[98] name:[layer4.1.bn1.bias] shape:[(512,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[99] name:[layer4.1.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[-0.006 -0.03  -0.014 -0.013 -0.002]\n",
      "[100] name:[layer4.1.bn2.weight] shape:[(512,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[101] name:[layer4.1.bn2.bias] shape:[(512,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[102] name:[layer4.2.conv1.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[ 0.007  0.009  0.029  0.009 -0.032]\n",
      "[103] name:[layer4.2.bn1.weight] shape:[(512,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[104] name:[layer4.2.bn1.bias] shape:[(512,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[105] name:[layer4.2.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[ 0.036 -0.01   0.029  0.023 -0.001]\n",
      "[106] name:[layer4.2.bn2.weight] shape:[(512,)].\n",
      "    val:[1. 1. 1. 1. 1.]\n",
      "[107] name:[layer4.2.bn2.bias] shape:[(512,)].\n",
      "    val:[0. 0. 0. 0. 0.]\n",
      "[108] name:[fc.weight] shape:[(1000, 512)].\n",
      "    val:[ 0.038  0.029  0.026 -0.038  0.009]\n",
      "[109] name:[fc.bias] shape:[(1000,)].\n",
      "    val:[-0.03   0.005  0.015 -0.037 -0.002]\n",
      "[110] name:[out1.weight] shape:[(2, 512)].\n",
      "    val:[ 0.048 -0.056 -0.011  0.063 -0.031]\n",
      "[111] name:[out1.bias] shape:[(2,)].\n",
      "    val:[ 0.031 -0.021]\n",
      "[112] name:[out2.weight] shape:[(3, 512)].\n",
      "    val:[-0.058  0.096 -0.097 -0.006  0.041]\n",
      "[113] name:[out2.bias] shape:[(3,)].\n",
      "    val:[-0.001  0.026 -0.022]\n",
      "[114] name:[out3.weight] shape:[(3, 512)].\n",
      "    val:[ 0.062 -0.048  0.06  -0.092  0.025]\n",
      "[115] name:[out3.bias] shape:[(3,)].\n",
      "    val:[-0.026 -0.012  0.033]\n",
      "Total number of parameters:[21,801,776].\n"
=======
      "    val:[-0.04  -0.046 -0.016 -0.017  0.006]\n",
      "[40] name:[layer2.2.bn2.weight] shape:[(128,)].\n",
      "    val:[0.25  0.102 0.138 0.317 0.144]\n",
      "[41] name:[layer2.2.bn2.bias] shape:[(128,)].\n",
      "    val:[-0.051  0.006  0.007 -0.147  0.035]\n",
      "[42] name:[layer2.3.conv1.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[-0.016 -0.033  0.011 -0.001 -0.038]\n",
      "[43] name:[layer2.3.bn1.weight] shape:[(128,)].\n",
      "    val:[0.216 0.181 0.23  0.205 0.245]\n",
      "[44] name:[layer2.3.bn1.bias] shape:[(128,)].\n",
      "    val:[-0.179 -0.142 -0.17  -0.189 -0.196]\n",
      "[45] name:[layer2.3.conv2.weight] shape:[(128, 128, 3, 3)].\n",
      "    val:[ 0.012 -0.026 -0.027 -0.002 -0.029]\n",
      "[46] name:[layer2.3.bn2.weight] shape:[(128,)].\n",
      "    val:[ 0.194 -0.018  0.164  0.281  0.151]\n",
      "[47] name:[layer2.3.bn2.bias] shape:[(128,)].\n",
      "    val:[ 0.117  0.032 -0.26  -0.127 -0.086]\n",
      "[48] name:[layer3.0.conv1.weight] shape:[(256, 128, 3, 3)].\n",
      "    val:[ 0.007 -0.013  0.008 -0.018 -0.007]\n",
      "[49] name:[layer3.0.bn1.weight] shape:[(256,)].\n",
      "    val:[0.274 0.267 0.268 0.232 0.234]\n",
      "[50] name:[layer3.0.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.06  -0.081 -0.092  0.066  0.037]\n",
      "[51] name:[layer3.0.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.007  0.005 -0.012 -0.008 -0.003]\n",
      "[52] name:[layer3.0.bn2.weight] shape:[(256,)].\n",
      "    val:[0.349 0.329 0.257 0.217 0.355]\n",
      "[53] name:[layer3.0.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.097 -0.09   0.072  0.154 -0.044]\n",
      "[54] name:[layer3.0.downsample.0.weight] shape:[(256, 128, 1, 1)].\n",
      "    val:[-0.022  0.023  0.002 -0.014 -0.019]\n",
      "[55] name:[layer3.0.downsample.1.weight] shape:[(256,)].\n",
      "    val:[0.143 0.159 0.071 0.082 0.114]\n",
      "[56] name:[layer3.0.downsample.1.bias] shape:[(256,)].\n",
      "    val:[-0.097 -0.09   0.072  0.154 -0.044]\n",
      "[57] name:[layer3.1.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.001 -0.01  -0.013  0.001 -0.002]\n",
      "[58] name:[layer3.1.bn1.weight] shape:[(256,)].\n",
      "    val:[0.22  0.208 0.202 0.218 0.215]\n",
      "[59] name:[layer3.1.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.185 -0.167 -0.168 -0.18  -0.068]\n",
      "[60] name:[layer3.1.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.004  0.004  0.016 -0.006 -0.01 ]\n",
      "[61] name:[layer3.1.bn2.weight] shape:[(256,)].\n",
      "    val:[0.25  0.2   0.122 0.093 0.191]\n",
      "[62] name:[layer3.1.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.137 -0.085 -0.053 -0.143 -0.108]\n",
      "[63] name:[layer3.2.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.039 -0.005  0.003  0.02   0.02 ]\n",
      "[64] name:[layer3.2.bn1.weight] shape:[(256,)].\n",
      "    val:[0.234 0.232 0.264 0.187 0.217]\n",
      "[65] name:[layer3.2.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.25  -0.252 -0.323 -0.165 -0.182]\n",
      "[66] name:[layer3.2.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.009 -0.025  0.01   0.021 -0.024]\n",
      "[67] name:[layer3.2.bn2.weight] shape:[(256,)].\n",
      "    val:[0.304 0.184 0.146 0.06  0.261]\n",
      "[68] name:[layer3.2.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.163 -0.158 -0.014 -0.    -0.137]\n",
      "[69] name:[layer3.3.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.038 -0.003  0.034 -0.018 -0.012]\n",
      "[70] name:[layer3.3.bn1.weight] shape:[(256,)].\n",
      "    val:[0.212 0.206 0.159 0.265 0.208]\n",
      "[71] name:[layer3.3.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.225 -0.162 -0.17  -0.415 -0.243]\n",
      "[72] name:[layer3.3.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.01  -0.014  0.006 -0.005  0.017]\n",
      "[73] name:[layer3.3.bn2.weight] shape:[(256,)].\n",
      "    val:[0.399 0.206 0.196 0.065 0.27 ]\n",
      "[74] name:[layer3.3.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.316 -0.16  -0.087  0.015 -0.196]\n",
      "[75] name:[layer3.4.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[-0.002 -0.023 -0.029  0.015 -0.   ]\n",
      "[76] name:[layer3.4.bn1.weight] shape:[(256,)].\n",
      "    val:[0.196 0.196 0.241 0.226 0.21 ]\n",
      "[77] name:[layer3.4.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.207 -0.197 -0.268 -0.29  -0.261]\n",
      "[78] name:[layer3.4.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.005  0.001 -0.005  0.028  0.014]\n",
      "[79] name:[layer3.4.bn2.weight] shape:[(256,)].\n",
      "    val:[0.322 0.201 0.109 0.01  0.282]\n",
      "[80] name:[layer3.4.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.196 -0.123 -0.071 -0.001 -0.24 ]\n",
      "[81] name:[layer3.5.conv1.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.016  0.005 -0.004  0.028  0.03 ]\n",
      "[82] name:[layer3.5.bn1.weight] shape:[(256,)].\n",
      "    val:[0.287 0.194 0.268 0.239 0.229]\n",
      "[83] name:[layer3.5.bn1.bias] shape:[(256,)].\n",
      "    val:[-0.274 -0.299 -0.355 -0.27  -0.238]\n",
      "[84] name:[layer3.5.conv2.weight] shape:[(256, 256, 3, 3)].\n",
      "    val:[ 0.002  0.012  0.006 -0.007 -0.005]\n",
      "[85] name:[layer3.5.bn2.weight] shape:[(256,)].\n",
      "    val:[ 0.358  0.252  0.161 -0.03   0.292]\n",
      "[86] name:[layer3.5.bn2.bias] shape:[(256,)].\n",
      "    val:[-0.317 -0.187  0.042 -0.006 -0.33 ]\n",
      "[87] name:[layer4.0.conv1.weight] shape:[(512, 256, 3, 3)].\n",
      "    val:[0.023 0.048 0.058 0.017 0.017]\n",
      "[88] name:[layer4.0.bn1.weight] shape:[(512,)].\n",
      "    val:[0.275 0.262 0.282 0.279 0.251]\n",
      "[89] name:[layer4.0.bn1.bias] shape:[(512,)].\n",
      "    val:[-0.271 -0.201 -0.171 -0.224 -0.2  ]\n",
      "[90] name:[layer4.0.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[ 0.001  0.001 -0.002 -0.013 -0.018]\n",
      "[91] name:[layer4.0.bn2.weight] shape:[(512,)].\n",
      "    val:[0.7   0.664 0.803 0.695 0.743]\n",
      "[92] name:[layer4.0.bn2.bias] shape:[(512,)].\n",
      "    val:[-0.072 -0.131 -0.151 -0.076 -0.066]\n",
      "[93] name:[layer4.0.downsample.0.weight] shape:[(512, 256, 1, 1)].\n",
      "    val:[-0.004 -0.033  0.005  0.037 -0.014]\n",
      "[94] name:[layer4.0.downsample.1.weight] shape:[(512,)].\n",
      "    val:[0.325 0.38  0.501 0.42  0.451]\n",
      "[95] name:[layer4.0.downsample.1.bias] shape:[(512,)].\n",
      "    val:[-0.072 -0.131 -0.151 -0.076 -0.066]\n",
      "[96] name:[layer4.1.conv1.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[ 0.005 -0.005  0.007  0.003  0.003]\n",
      "[97] name:[layer4.1.bn1.weight] shape:[(512,)].\n",
      "    val:[0.247 0.23  0.21  0.258 0.288]\n",
      "[98] name:[layer4.1.bn1.bias] shape:[(512,)].\n",
      "    val:[-0.269 -0.243 -0.198 -0.25  -0.327]\n",
      "[99] name:[layer4.1.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[0.002 0.009 0.004 0.002 0.008]\n",
      "[100] name:[layer4.1.bn2.weight] shape:[(512,)].\n",
      "    val:[0.592 0.595 0.524 0.572 0.548]\n",
      "[101] name:[layer4.1.bn2.bias] shape:[(512,)].\n",
      "    val:[-0.142 -0.179 -0.186 -0.113 -0.115]\n",
      "[102] name:[layer4.2.conv1.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[0.021 0.028 0.021 0.049 0.059]\n",
      "[103] name:[layer4.2.bn1.weight] shape:[(512,)].\n",
      "    val:[0.26  0.228 0.275 0.229 0.224]\n",
      "[104] name:[layer4.2.bn1.bias] shape:[(512,)].\n",
      "    val:[-0.215 -0.164 -0.275 -0.147 -0.161]\n",
      "[105] name:[layer4.2.conv2.weight] shape:[(512, 512, 3, 3)].\n",
      "    val:[0.042 0.035 0.04  0.032 0.017]\n",
      "[106] name:[layer4.2.bn2.weight] shape:[(512,)].\n",
      "    val:[1.436 1.512 1.565 1.291 1.287]\n",
      "[107] name:[layer4.2.bn2.bias] shape:[(512,)].\n",
      "    val:[0.122 0.129 0.193 0.133 0.098]\n",
      "[108] name:[fc.weight] shape:[(18, 512)].\n",
      "    val:[ 0.072 -0.057  0.056 -0.099 -0.003]\n",
      "[109] name:[fc.bias] shape:[(18,)].\n",
      "    val:[-0.035  0.008  0.029 -0.013  0.   ]\n",
      "Total number of parameters:[21,293,906].\n"
>>>>>>> T4136/SwinT:base_resnet34.ipynb
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "n_param = 0\n",
    "for p_idx, (param_name, param) in enumerate(basemodel_resnet34.named_parameters()):\n",
    "    if param.requires_grad:\n",
    "        param_numpy = param.detach().cpu().numpy()\n",
    "        n_param += len(param_numpy.reshape(-1))\n",
    "        print (\"[%d] name:[%s] shape:[%s].\"%(p_idx,param_name,param_numpy.shape))\n",
    "        print (\"    val:%s\"%(param_numpy.reshape(-1)[:5]))\n",
    "print (\"Total number of parameters:[%s].\"%(format(n_param,',d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c067d0e-38c9-4ab8-baba-88cf8dcb8c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10466/3501907160.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p_gen, p_age, p_msk = F.softmax(p_gen), F.softmax(p_age), F.softmax(p_msk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
      "> train_loss : 0.11433611810207367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10466/3501907160.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p_gen, p_age, p_msk = F.softmax(p_gen), F.softmax(p_age), F.softmax(p_msk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> valid_loss : 0.010540408082306385\n",
      "valid acc : 0.7789115646258503\n",
      "epoch[1/30] completed\n",
      "> train_loss : 0.10401048511266708\n",
      "> valid_loss : 0.010556266643106937\n",
      "valid acc : 0.7806122448979592\n",
      "epoch[2/30] completed\n",
      "> train_loss : 0.11068312078714371\n",
      "> valid_loss : 0.008887164294719696\n",
      "valid acc : 0.8928571428571429\n",
      "epoch[3/30] completed\n",
      "> train_loss : 0.1003379374742508\n",
      "> valid_loss : 0.01029300782829523\n",
      "valid acc : 0.7959183673469388\n",
      "epoch[4/30] completed\n",
      "> train_loss : 0.08876042068004608\n",
      "> valid_loss : 0.00896081980317831\n",
      "valid acc : 0.8877551020408163\n",
      "epoch[5/30] completed\n",
      "> train_loss : 0.10144273936748505\n",
      "> valid_loss : 0.009222377091646194\n",
      "valid acc : 0.8673469387755102\n",
      "epoch[6/30] completed\n",
      "> train_loss : 0.10932314395904541\n",
      "> valid_loss : 0.008682835847139359\n",
      "valid acc : 0.9047619047619048\n",
      "epoch[7/30] completed\n",
      "> train_loss : 0.09647645056247711\n",
      "> valid_loss : 0.008630017749965191\n",
      "valid acc : 0.9013605442176871\n",
      "epoch[8/30] completed\n",
      "> train_loss : 0.10906515270471573\n",
      "> valid_loss : 0.008281538262963295\n",
      "valid acc : 0.9302721088435374\n",
      "epoch[9/30] completed\n",
      "> train_loss : 0.11707085371017456\n",
      "> valid_loss : 0.009869278408586979\n",
      "valid acc : 0.8299319727891157\n",
      "epoch[10/30] completed\n",
      "> train_loss : 0.10157978534698486\n",
      "> valid_loss : 0.008849252946674824\n",
      "valid acc : 0.8894557823129252\n",
      "epoch[11/30] completed\n",
      "> train_loss : 0.09329372644424438\n",
      "> valid_loss : 0.008368986658751965\n",
      "valid acc : 0.923469387755102\n",
      "epoch[12/30] completed\n",
      "> train_loss : 0.09244208037853241\n",
      "> valid_loss : 0.008191856555640697\n",
      "valid acc : 0.9387755102040817\n",
      "epoch[13/30] completed\n",
      "> train_loss : 0.10578352212905884\n",
      "> valid_loss : 0.008620219305157661\n",
      "valid acc : 0.9098639455782312\n",
      "epoch[14/30] completed\n",
      "> train_loss : 0.08863282203674316\n",
      "> valid_loss : 0.008021737448871136\n",
      "valid acc : 0.9472789115646258\n",
      "epoch[15/30] completed\n",
      "> train_loss : 0.0925593450665474\n",
      "> valid_loss : 0.007867841050028801\n",
      "valid acc : 0.95578231292517\n",
      "epoch[16/30] completed\n",
      "> train_loss : 0.09147484600543976\n",
      "> valid_loss : 0.00799868069589138\n",
      "valid acc : 0.9489795918367347\n",
      "epoch[17/30] completed\n",
      "> train_loss : 0.09883655607700348\n",
      "> valid_loss : 0.009417491033673286\n",
      "valid acc : 0.8520408163265306\n",
      "epoch[18/30] completed\n",
      "> train_loss : 0.08890804648399353\n",
      "> valid_loss : 0.00814039632678032\n",
      "valid acc : 0.9370748299319728\n",
      "epoch[19/30] completed\n",
      "> train_loss : 0.09547184407711029\n",
      "> valid_loss : 0.00834820419549942\n",
      "valid acc : 0.9200680272108843\n",
      "epoch[20/30] completed\n",
      "> train_loss : 0.09246863424777985\n",
      "> valid_loss : 0.008129911497235298\n",
      "valid acc : 0.9404761904761905\n",
      "epoch[21/30] completed\n",
      "> train_loss : 0.11556576192378998\n",
      "> valid_loss : 0.00830849539488554\n",
      "valid acc : 0.9302721088435374\n",
      "epoch[22/30] completed\n",
      "> train_loss : 0.09271303564310074\n",
      "> valid_loss : 0.00808575190603733\n",
      "valid acc : 0.9387755102040817\n",
      "epoch[23/30] completed\n",
      "> train_loss : 0.08851948380470276\n",
      "> valid_loss : 0.007907357066869736\n",
      "valid acc : 0.9540816326530612\n",
      "epoch[24/30] completed\n",
      "> train_loss : 0.10242341458797455\n",
      "> valid_loss : 0.007873774506151676\n",
      "valid acc : 0.95578231292517\n",
      "epoch[25/30] completed\n",
      "> train_loss : 0.10438024252653122\n",
      "> valid_loss : 0.007940459996461868\n",
      "valid acc : 0.9540816326530612\n",
      "epoch[26/30] completed\n",
      "> train_loss : 0.11028653383255005\n",
      "> valid_loss : 0.008150397799909115\n",
      "valid acc : 0.9438775510204082\n",
      "epoch[27/30] completed\n",
      "> train_loss : 0.10181999206542969\n",
      "> valid_loss : 0.008049221709370613\n",
      "valid acc : 0.9455782312925171\n",
      "epoch[28/30] completed\n",
      "> train_loss : 0.09669055044651031\n",
      "> valid_loss : 0.008920526131987572\n",
      "valid acc : 0.8877551020408163\n",
      "epoch[29/30] completed\n",
      "> train_loss : 0.0968829095363617\n",
      "> valid_loss : 0.007961098104715347\n",
      "valid acc : 0.9506802721088435\n",
      "epoch[30/30] completed\n"
=======
      "epoch[0/30] training loss 0.015, training accuracy 0.035\n",
      "epoch[0/30] training loss 0.012, training accuracy 0.156\n",
      "epoch[0/30] training loss 0.009, training accuracy 0.312\n",
      "epoch[0/30] training loss 0.008, training accuracy 0.449\n",
      "epoch[0/30] training loss 0.006, training accuracy 0.551\n",
      "epoch[0/30] training loss 0.006, training accuracy 0.648\n",
      "epoch[0/30] training loss 0.005, training accuracy 0.652\n",
      "epoch[0/30] training loss 0.004, training accuracy 0.746\n",
      "epoch[0/30] training loss 0.004, training accuracy 0.754\n",
      "epoch[0/30] training loss 0.004, training accuracy 0.758\n",
      "epoch[0/30] training loss 0.003, training accuracy 0.812\n",
      "epoch[0/30] training loss 0.004, training accuracy 0.762\n",
      "epoch[0/30] training loss 0.003, training accuracy 0.785\n",
      "epoch[0/30] training loss 0.003, training accuracy 0.836\n",
      "epoch[0/30] training loss 0.003, training accuracy 0.805\n",
      "epoch[0/30] training loss 0.002, training accuracy 0.828\n",
      "epoch[0/30] training loss 0.002, training accuracy 0.887\n",
      "epoch[0/30] training loss 0.002, training accuracy 0.852\n",
      "epoch[0/30] training loss 0.002, training accuracy 0.840\n",
      "epoch[0/30] training loss 0.002, training accuracy 0.879\n",
      "epoch[0/30] training loss 0.002, training accuracy 0.883\n",
      "epoch[0/30] training loss 0.002, training accuracy 0.863\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.902\n",
      "epoch[0/30] training loss 0.002, training accuracy 0.895\n",
      "epoch[0/30] training loss 0.002, training accuracy 0.914\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.895\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.883\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.875\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.895\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.895\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.887\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.918\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.914\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.891\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.941\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.883\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.891\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.895\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.953\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.898\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.949\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.934\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.910\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.934\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.914\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.922\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.914\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.949\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.910\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.945\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.898\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.902\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.930\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.953\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.941\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.918\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.934\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.934\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.949\n",
      "epoch[0/30] training loss 0.001, training accuracy 0.055\n",
      "[val] acc : 0.927, loss : 0.227\n",
      "best acc : 0.927, best loss : 0.227\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.961\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.902\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.945\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.910\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.930\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.965\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.953\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.953\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.934\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.938\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.949\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.945\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.953\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.938\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.969\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.953\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.969\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.957\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.965\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.965\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.969\n",
      "epoch[1/30] training loss 0.001, training accuracy 0.961\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.973\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.965\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.969\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.957\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[1/30] training loss 0.000, training accuracy 0.059\n",
      "[val] acc : 0.960, loss : 0.122\n",
      "best acc : 0.960, best loss : 0.122\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[2/30] training loss 0.000, training accuracy 0.059\n",
      "[val] acc : 0.977, loss : 0.072\n",
      "best acc : 0.977, best loss : 0.072\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[3/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[3/30] training loss 0.000, training accuracy 0.059\n",
      "[val] acc : 0.981, loss : 0.062\n",
      "best acc : 0.981, best loss : 0.062\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[4/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[4/30] training loss 0.001, training accuracy 0.059\n",
      "[val] acc : 0.977, loss : 0.068\n",
      "best acc : 0.981, best loss : 0.062\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[5/30] training loss 0.001, training accuracy 0.949\n",
      "epoch[5/30] training loss 0.001, training accuracy 0.945\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.973\n",
      "epoch[5/30] training loss 0.001, training accuracy 0.957\n",
      "epoch[5/30] training loss 0.001, training accuracy 0.977\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.969\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.969\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.973\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.977\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.980\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.984\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[5/30] training loss 0.000, training accuracy 0.059\n",
      "[val] acc : 0.981, loss : 0.065\n",
      "best acc : 0.981, best loss : 0.062\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.988\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.992\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[6/30] training loss 0.000, training accuracy 0.062\n",
      "[val] acc : 0.982, loss : 0.059\n",
      "best acc : 0.982, best loss : 0.059\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[7/30] training loss 0.000, training accuracy 0.062\n",
      "[val] acc : 0.987, loss : 0.038\n",
      "best acc : 0.987, best loss : 0.038\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[8/30] training loss 0.000, training accuracy 0.062\n",
      "[val] acc : 0.989, loss : 0.035\n",
      "best acc : 0.989, best loss : 0.035\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[9/30] training loss 0.000, training accuracy 0.062\n",
      "[val] acc : 0.988, loss : 0.036\n",
      "best acc : 0.989, best loss : 0.035\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[10/30] training loss 0.000, training accuracy 0.062\n",
      "[val] acc : 0.983, loss : 0.051\n",
      "best acc : 0.989, best loss : 0.035\n",
      "epoch[11/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[11/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[11/30] training loss 0.000, training accuracy 1.000\n",
      "epoch[11/30] training loss 0.000, training accuracy 0.996\n",
      "epoch[11/30] training loss 0.000, training accuracy 1.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f171e76eb9bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> T4136/SwinT:base_resnet34.ipynb
     ]
    }
   ],
   "source": [
    "# print되는 값들은 정확하지 않을 수도 있습니다 (진행상황 보려고 대강 확인안하고 만들었어요)\n",
    "\n",
    "total_sum = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    loss_value = 0\n",
    "    basemodel_resnet34.train()\n",
    "\n",
    "    for inputs, labels in train_dataloader_mask:\n",
    "        inputs = inputs.to(device)\n",
    "        gen, age, msk = labels\n",
    "        gen = gen.to(device)\n",
    "        age = age.to(device)\n",
    "        msk = msk.to(device)\n",
    "        \n",
    "        p_gen, p_age, p_msk = basemodel_resnet34(inputs)\n",
    "        p_gen, p_age, p_msk = F.softmax(p_gen), F.softmax(p_age), F.softmax(p_msk)\n",
    "        loss = criterion(p_gen, gen) + criterion(p_age, age) + criterion(p_msk, msk)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = loss.item() / len(inputs)\n",
    "    print('> train_loss : {}'.format(train_loss))     \n",
    "    \n",
    "    \n",
    "    basemodel_resnet34.eval()\n",
    "    for idx, (inputs, labels) in enumerate(val_dataloader_mask):\n",
    "        inputs = inputs.to(device)\n",
    "        gen, age, msk = labels\n",
    "        gen = gen.to(device)\n",
    "        age = age.to(device)\n",
    "        msk = msk.to(device)\n",
    "        \n",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
    "        with torch.no_grad():\n",
    "            p_gen, p_age, p_msk = basemodel_resnet34(inputs)\n",
    "            p_gen, p_age, p_msk = F.softmax(p_gen), F.softmax(p_age), F.softmax(p_msk)\n",
    "        loss = criterion(p_gen, gen) + criterion(p_age, age) + criterion(p_msk, msk)\n",
    "        \n",
    "        acc_1 = (gen == torch.argmax(p_gen, -1)).sum().item()\n",
    "        acc_2 = (age == torch.argmax(p_age, -1)).sum().item()\n",
    "        acc_3 = (msk == torch.argmax(p_msk, -1)).sum().item()\n",
    "    \n",
    "    valid_loss = loss / len(inputs)\n",
    "    print('> valid_loss : {}'.format(valid_loss))    \n",
    "    print(f'valid acc : {(acc_1 + acc_2 + acc_3) / (3 * len(inputs))}')        \n",
=======
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        \n",
    "        train_loss = loss_value / batch_size\n",
    "        train_acc = matches / batch_size\n",
    "        print(f\"epoch[{epoch}/{NUM_EPOCH}] training loss {train_loss:.3f}, training accuracy {train_acc:.3f}\")\n",
    "        \n",
    "        loss_value = 0\n",
    "        matches = 0\n",
>>>>>>> T4136/SwinT:base_resnet34.ipynb
    "        \n",
    "    print(f\"epoch[{epoch+1}/{NUM_EPOCH}] completed\")        "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "execution_count": 18,
=======
   "execution_count": 19,
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "id": "afda23d0-6ad9-408b-99c9-705ae5fd8347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ImageID  ans\n",
       "0  cbc5c6e168e63498590db46022617123f1fe1268.jpg    0\n",
       "1  0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    0\n",
       "2  b549040c49190cedc41327748aeb197c1670f14d.jpg    0\n",
       "3  4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    0\n",
       "4  248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0"
      ]
     },
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
     "execution_count": 18,
=======
     "execution_count": 19,
>>>>>>> T4136/SwinT:base_resnet34.ipynb
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir_path = '/opt/ml/input/data/eval/'\n",
    "test_image_path = '/opt/ml/input/data/eval/images/'\n",
    "\n",
    "submission = pd.read_csv(test_dir_path+'info.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "execution_count": 19,
=======
   "execution_count": 20,
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "id": "566c2df1-a083-4e27-a655-f2c73d15f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [os.path.join(test_image_path, img_id) for img_id in submission.ImageID]\n",
    "test_image = pd.Series(image_paths)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "execution_count": 20,
=======
   "execution_count": 21,
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "id": "a9c14322-45a8-40a5-aded-f335204484b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Dataset(Dataset):\n",
    "    def __init__(self, midcrop=True, transform=None):\n",
    "        self.midcrop = midcrop\n",
    "        self.data = test_image\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(test_image)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.cvtColor(cv2.imread(self.data[idx]), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.midcrop:\n",
    "            img = img[98:422, 30:354]\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Rough_MultiClass/Res34_MultiClass.ipynb
   "execution_count": 21,
=======
   "execution_count": 22,
>>>>>>> T4136/SwinT:base_resnet34.ipynb
   "id": "138db932-cc09-4f85-89d8-e7485659f7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Test_Dataset(transform = transforms.Compose([\n",
    "                            transforms.ToTensor()\n",
    "                        ]))\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = basemodel_resnet34.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        p_gen, p_age, p_msk = model(images)\n",
    "        \n",
    "        ar_gen = p_gen.argmax(dim=-1)\n",
    "        ar_age = p_age.argmax(dim=-1)\n",
    "        ar_msk = p_msk.argmax(dim=-1)\n",
    "        \n",
    "        total = ar_gen * 3 + ar_age + ar_msk * 6\n",
    "        \n",
    "        all_predictions.extend(total.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir_path, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ddc8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9bf9802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.22222222222223"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과비교 (자체, 현재 제출된 것 중 가장 결과가 좋은 것과 비교)\n",
    "# 기준결과의 accuracy가 a%, 비교결과가 b%인 경우\n",
    "#  -> 현재 결과의 accuracy 범위 : a+b-100(%) ~ a-b+100(%)\n",
    "standard = pd.read_csv('./log/standard_1028.csv')['ans']\n",
    "100 * sum(standard == submission['ans']) / len(standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b77d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419fa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "24179ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18780 17423 18869\n"
     ]
    }
   ],
   "source": [
    "# (자체) 각 class별로 정답개수 확인\n",
    "g_sum = 0\n",
    "a_sum = 0\n",
    "m_sum = 0\n",
    "device = torch.device('cuda')\n",
    "model = basemodel_resnet34.to(device)\n",
    "model.eval()\n",
    "\n",
    "for i in range(18900):\n",
    "    image, label = dataset_mask[i]\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    \n",
    "    result = model(image)\n",
    "    if torch.argmax(result[0]) == label[0]:\n",
    "        g_sum += 1\n",
    "    if torch.argmax(result[1]) == label[1]:\n",
    "        a_sum += 1\n",
    "    if torch.argmax(result[2]) == label[2]:\n",
    "        m_sum += 1\n",
    "\n",
    "print(g_sum, a_sum , m_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "36588613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제로 확인(in train set : idx = 0~18900)\n",
    "image, label = dataset_mask[3333]\n",
    "image = image.unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = basemodel_resnet34.to(device)\n",
    "model.eval()\n",
    "\n",
    "result = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "04649d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- (Gender , Age, Mask) <--Pred  //  Real--> (Gender, Age, Mask) ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0')),\n",
       " (0, 0, 0))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('---- (Gender , Age, Mask) <--Pred  //  Real--> (Gender, Age, Mask) ----')\n",
    "(torch.argmax(result[0]), torch.argmax(result[1]), torch.argmax(result[2])), (label[0], label[1], label[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 예측라벨, 실제라벨 확인\n",
    "print(torch.argmax(result[0]) * 3 + torch.argmax(result[1]) + torch.argmax(result[2]) * 6, label[0]*3 + label[1] + label[2]*6)\n",
    "transforms.ToPILImage()(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6bcc42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdaa03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
